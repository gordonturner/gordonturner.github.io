<!DOCTYPE html>
<html lang="en-US">
<head>
  <title> PyTorch 1.3 adds mobile, privacy, quantization, and named tensors</title>
	<!-- Google Tag Manager -->
	<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
	new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
	j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
	'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
	})(window,document,'script','dataLayer','GTM-52DXT37');</script>
	<!-- End Google Tag Manager -->
	<!-- Docsearch -->
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css">
	<script src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script>
	<!-- End Docsearch -->

	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta name="robots" content="max-image-preview:large">
<link rel="dns-prefetch" href="//s.w.org">
<link rel="alternate" type="application/rss+xml" title="pytorch-org-preprod.go-vip.net &raquo; PyTorch 1.3 adds mobile, privacy, quantization, and named tensors Comments Feed" href="/pytorch-1-3-adds-mobile-privacy-quantization-and-named-tensors/feed/">
		<script type="text/javascript">
			window._wpemojiSettings = {"baseUrl":"https:\/\/s.w.org\/images\/core\/emoji\/13.0.1\/72x72\/","ext":".png","svgUrl":"https:\/\/s.w.org\/images\/core\/emoji\/13.0.1\/svg\/","svgExt":".svg","source":{"concatemoji":"\/wp-includes\/js\/wp-emoji-release.min.js?ver=5.7.5"}};
			!function(e,a,t){var n,r,o,i=a.createElement("canvas"),p=i.getContext&&i.getContext("2d");function s(e,t){var a=String.fromCharCode;p.clearRect(0,0,i.width,i.height),p.fillText(a.apply(this,e),0,0);e=i.toDataURL();return p.clearRect(0,0,i.width,i.height),p.fillText(a.apply(this,t),0,0),e===i.toDataURL()}function c(e){var t=a.createElement("script");t.src=e,t.defer=t.type="text/javascript",a.getElementsByTagName("head")[0].appendChild(t)}for(o=Array("flag","emoji"),t.supports={everything:!0,everythingExceptFlag:!0},r=0;r<o.length;r++)t.supports[o[r]]=function(e){if(!p||!p.fillText)return!1;switch(p.textBaseline="top",p.font="600 32px Arial",e){case"flag":return s([127987,65039,8205,9895,65039],[127987,65039,8203,9895,65039])?!1:!s([55356,56826,55356,56819],[55356,56826,8203,55356,56819])&&!s([55356,57332,56128,56423,56128,56418,56128,56421,56128,56430,56128,56423,56128,56447],[55356,57332,8203,56128,56423,8203,56128,56418,8203,56128,56421,8203,56128,56430,8203,56128,56423,8203,56128,56447]);case"emoji":return!s([55357,56424,8205,55356,57212],[55357,56424,8203,55356,57212])}return!1}(o[r]),t.supports.everything=t.supports.everything&&t.supports[o[r]],"flag"!==o[r]&&(t.supports.everythingExceptFlag=t.supports.everythingExceptFlag&&t.supports[o[r]]);t.supports.everythingExceptFlag=t.supports.everythingExceptFlag&&!t.supports.flag,t.DOMReady=!1,t.readyCallback=function(){t.DOMReady=!0},t.supports.everything||(n=function(){t.readyCallback()},a.addEventListener?(a.addEventListener("DOMContentLoaded",n,!1),e.addEventListener("load",n,!1)):(e.attachEvent("onload",n),a.attachEvent("onreadystatechange",function(){"complete"===a.readyState&&t.readyCallback()})),(n=t.source||{}).concatemoji?c(n.concatemoji):n.wpemoji&&n.twemoji&&(c(n.twemoji),c(n.wpemoji)))}(window,document,window._wpemojiSettings);
		</script>
		<style type="text/css">img.wp-smiley,
img.emoji {
	display: inline !important;
	border: none !important;
	box-shadow: none !important;
	height: 1em !important;
	width: 1em !important;
	margin: 0 .07em !important;
	vertical-align: -0.1em !important;
	background: none !important;
	padding: 0 !important;
}</style>
	<link rel="stylesheet" id="pytorch-classic-style-css" href="/wp-content/themes/pytorch/assets/css/index.css?ver=1" media="all">
<link rel="stylesheet" id="pytorch-blog-header-css" href="/wp-content/themes/pytorch/assets/css/blog-header.css?ver=1" media="all">
<link rel="stylesheet" id="pytorch-blog-text-css" href="/wp-content/themes/pytorch/assets/css/blog-text.css?ver=1" media="all">
<link rel="stylesheet" id="pytorch-heading-css" href="/wp-content/themes/pytorch/assets/css/heading.css?ver=1" media="all">
<link rel="stylesheet" id="pytorch-blog-list-css" href="/wp-content/themes/pytorch/assets/css/blog-list.css?ver=1" media="all">
<link rel="stylesheet" id="pytorch-blog-image-css" href="/wp-content/themes/pytorch/assets/css/blog-image.css?ver=1" media="all">
<link rel="stylesheet" id="mediaelement-css" href="/wp-includes/js/mediaelement/mediaelementplayer-legacy.min.css?ver=4.2.16" media="all">
<link rel="stylesheet" id="wp-mediaelement-css" href="/wp-includes/js/mediaelement/wp-mediaelement.min.css?ver=5.7.5" media="all">
<link rel="stylesheet" id="mkaz-code-syntax-prism-css-css" href="/wp-content/plugins/code-syntax-block/assets/prism-ghcolors.css?ver=1641826791" media="all">
<link rel="stylesheet" id="ssp-search-css" href="/wp-content/plugins/simply-static-pro/assets/ssp-search.css?ver=1.1" media="all">
<link rel="https://api.w.org/" href="/wp-json/">
<link rel="alternate" type="application/json" href="/wp-json/wp/v2/posts/1323">
<link rel="EditURI" type="application/rsd+xml" title="RSD" href="/xmlrpc.php?rsd">
<link rel="wlwmanifest" type="application/wlwmanifest+xml" href="/wp-includes/wlwmanifest.xml"> 
<meta name="generator" content="WordPress 5.7.5">
<link rel="canonical" href="/pytorch-1-3-adds-mobile-privacy-quantization-and-named-tensors/">
<link rel="shortlink" href="/?p=1323">
		<meta name="ssp-url" content="">
		<meta name="ssp-config-url" content="/wp-content/plugins/simply-static-pro/configs/">
		<style type="text/css">img#wpstats{display:none}</style>
		</head>

<body class="post-template-default single single-post postid-1323 single-format-standard">
    <a id="skip" href="#main" tabindex="0">Skip to content</a>
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-52DXT37" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
<div>
	<header class="mainHeader">
		<div class="container">
			<div class="logo">
				<a href="/" aria-label="PyTorch Logo" tabindex="0">
					<svg role="img" width="109" height="27" viewbox="0 0 109 27" fill="none" xmlns="http://www.w3.org/2000/svg">
<path d="M14.6172 5.92839L13.1892 7.32839C15.5692 9.66172 15.5692 13.4617 13.1892 15.7951C10.8092 18.1284 6.93316 18.1284 4.55316 15.7951C2.17316 13.4617 2.17316 9.66172 4.55316 7.32839L8.36116 3.59505L8.83716 3.06172V0.261719L3.05716 5.92839C-0.138844 9.06172 -0.138844 14.0617 3.05716 17.1951C6.25316 20.3284 11.3532 20.3284 14.5492 17.1951C17.8132 14.0617 17.8132 8.99505 14.6172 5.92839Z" fill="#DE3412"></path>
<ellipse cx="11.7618" cy="4.4612" rx="1.088" ry="1.06667" fill="#DE3412"></ellipse>
<path fill-rule="evenodd" clip-rule="evenodd" d="M26.5048 13.23H28.9435C33.3467 13.1625 36.1242 11.205 36.1242 7.29C36.1242 3.9825 33.8887 1.6875 29.1467 1.6875H24.6758V19.5075H26.5048V13.23ZM26.4371 3.375H29.079C32.4661 3.375 34.2274 4.7925 34.2274 7.29C34.2274 10.0575 32.3984 11.4075 29.0113 11.475L26.4371 11.5425V3.375Z" fill="#262626"></path>
<path d="M44.3887 19.4405L43.3048 22.2755C42.0855 25.448 40.8661 26.393 39.0371 26.393C38.021 26.393 37.2758 26.123 36.4629 25.7855L37.0048 24.1655C37.6145 24.503 38.2919 24.7055 39.0371 24.7055C40.0532 24.7055 40.7984 24.1655 41.7468 21.668L42.6274 19.373L37.5468 6.48047H39.4435L43.5758 17.2805L47.6403 6.48047H49.4693L44.3887 19.4405Z" fill="#262626"></path>
<path d="M55.5665 3.4425V19.575H53.7375V3.4425H47.4375V1.6875H61.8665V3.375H55.5665V3.4425Z" fill="#262626"></path>
<path fill-rule="evenodd" clip-rule="evenodd" d="M60.6465 13.0277C60.6465 17.2127 63.3562 19.9127 67.0142 19.9127C70.6723 19.9127 73.4497 17.1452 73.4497 12.9602C73.4497 8.7752 70.8078 6.0752 67.1497 6.0752C63.4239 6.0752 60.6465 8.8427 60.6465 13.0277ZM62.4746 12.9613C62.4746 9.92379 64.3036 7.69629 67.0811 7.69629C69.8585 7.69629 71.7553 9.85629 71.7553 13.0288C71.7553 16.0663 69.9262 18.2938 67.1488 18.2938C64.3714 18.2938 62.4746 16.1338 62.4746 12.9613Z" fill="#262626"></path>
<path d="M77.9879 19.5731H76.2266V6.47813L77.9879 6.14062V8.90812C78.8685 7.22062 80.1556 6.14062 81.8491 6.14062C82.7298 6.14062 83.5427 6.41063 84.1524 6.74813L83.6782 8.43563C83.1362 8.09813 82.3911 7.89562 81.6459 7.89562C80.2911 7.89562 79.004 8.90813 77.9201 11.2706V19.5731H77.9879Z" fill="#262626"></path>
<path d="M91.1308 19.9127C87.2018 19.9127 84.6953 17.0777 84.6953 13.0277C84.6953 8.9102 87.405 6.0752 91.1308 6.0752C92.7566 6.0752 94.1114 6.4802 95.2631 7.2227L94.7889 8.8427C93.7727 8.1677 92.5534 7.7627 91.1308 7.7627C88.2856 7.7627 86.5243 9.8552 86.5243 12.9602C86.5243 16.1327 88.4211 18.2252 91.1985 18.2252C92.4856 18.2252 93.8405 17.8202 94.8566 17.1452L95.1953 18.7652C94.0437 19.5077 92.6211 19.9127 91.1308 19.9127Z" fill="#262626"></path>
<path d="M106.238 19.575V11.1375C106.238 8.8425 105.29 7.83 103.461 7.83C101.97 7.83 100.48 8.5725 99.3961 9.72V19.6425H97.6348V0.3375L99.3961 0C99.3961 0 99.3961 8.1675 99.3961 8.235C100.751 6.885 102.512 6.1425 103.935 6.1425C106.509 6.1425 108.067 7.7625 108.067 10.5975V19.575H106.238Z" fill="#262626"></path>
</svg>
				</a>
			</div>
			<div class="content-container">
				<ul class="mainNav">
					<li class="mainItem search" key="search">
						<button id="search-icon" aria-label="search">
							<svg role="img" width="17" height="16" viewbox="0 0 17 16" fill="none" xmlns="http://www.w3.org/2000/svg">
<path fill-rule="evenodd" clip-rule="evenodd" d="M11.7461 7C11.7461 9.48528 9.73137 11.5 7.24609 11.5C4.76081 11.5 2.74609 9.48528 2.74609 7C2.74609 4.51472 4.76081 2.5 7.24609 2.5C9.73137 2.5 11.7461 4.51472 11.7461 7ZM10.9253 11.7399C9.90931 12.5297 8.63263 13 7.24609 13C3.93239 13 1.24609 10.3137 1.24609 7C1.24609 3.68629 3.93239 1 7.24609 1C10.5598 1 13.2461 3.68629 13.2461 7C13.2461 8.38653 12.7758 9.66322 11.986 10.6792L15.2764 13.9697L14.2158 15.0303L10.9253 11.7399Z" fill="#262626"></path>
</svg>
						</button>
						<div class="search-border">
							<div id="inner-search-icon">
								<svg role="img" width="17" height="16" viewbox="0 0 17 16" fill="none" xmlns="http://www.w3.org/2000/svg">
<path fill-rule="evenodd" clip-rule="evenodd" d="M11.7461 7C11.7461 9.48528 9.73137 11.5 7.24609 11.5C4.76081 11.5 2.74609 9.48528 2.74609 7C2.74609 4.51472 4.76081 2.5 7.24609 2.5C9.73137 2.5 11.7461 4.51472 11.7461 7ZM10.9253 11.7399C9.90931 12.5297 8.63263 13 7.24609 13C3.93239 13 1.24609 10.3137 1.24609 7C1.24609 3.68629 3.93239 1 7.24609 1C10.5598 1 13.2461 3.68629 13.2461 7C13.2461 8.38653 12.7758 9.66322 11.986 10.6792L15.2764 13.9697L14.2158 15.0303L10.9253 11.7399Z" fill="#262626"></path>
</svg>
							</div>
								<input id="input" type="text" placeholder="Search" title="Search" autocomplete="off" role="combobox" aria-autocomplete="list" aria-expanded="false" aria-label="search input">
							
							<div id="close-search">X</div>
						</div>
					</li>
					<li class="mainItem menuIcon">
						<span class="hamburger"><svg role="img" width="22" height="18" viewbox="0 0 22 18" fill="none" xmlns="http://www.w3.org/2000/svg">
<path fill-rule="evenodd" clip-rule="evenodd" d="M21.5 2.125H0.5V0.625H21.5V2.125ZM21.5 17.625H0.5V16.125H21.5V17.625ZM0.5 9.75H21.5V8.25H0.5V9.75Z" fill="black"></path>
</svg>
</span>
						<span class="close"><svg role="img" width="22" height="22" viewbox="0 0 22 22" fill="none" xmlns="http://www.w3.org/2000/svg">
<path fill-rule="evenodd" clip-rule="evenodd" d="M11.0001 12.0607L20.2197 21.2803L21.2804 20.2197L12.0607 11L21.2804 1.78033L20.2197 0.719675L11.0001 9.93934L1.78039 0.719673L0.719727 1.78033L9.9394 11L0.719727 20.2197L1.78039 21.2803L11.0001 12.0607Z" fill="black"></path>
</svg>
</span>
					</li>
					<li class="navItems">
						<ul class="navItemsContainer">
																														<li class="mainItem home-menu">
									<a class="parentTitle" href="/" target="">
										<span>
											Home										</span>
									</a>
																	</li>
																							<li class="mainItem install-menu">
									<a class="parentTitle" href="/install/install-overview/" target="">
										<span>
											Install										</span>
									</a>
																			<div class="subitems-container">
											<div class="subitems-wrapper">
												<ul class="subItems">
																											<li class="subItem ">
															<a class="link" href="/install/install-overview/" target="">
																<p class="title">Overview</p>
																														</a>
														</li>
																											<li class="subItem ">
															<a class="link" href="/install/install-locally/" target="">
																<p class="title">Install Locally</p>
																														</a>
														</li>
																											<li class="subItem ">
															<a class="link" href="/install/install-mobile/" target="">
																<p class="title">Install Mobile</p>
																														</a>
														</li>
																											<li class="subItem ">
															<a class="link" href="/install/start-with-cloud-partners/" target="">
																<p class="title">Start with Cloud Partners</p>
																														</a>
														</li>
																											<li class="subItem ">
															<a class="link" href="/install/previous-versions/" target="">
																<p class="title">Previous PyTorch Versions</p>
																														</a>
														</li>
																									</ul>
											</div>
										</div>
																	</li>
																							<li class="mainItem features-menu">
									<a class="parentTitle" href="/features/" target="">
										<span>
											Features										</span>
									</a>
																	</li>
																							<li class="mainItem resources-menu">
									<a class="parentTitle" href="/resources/overview/" target="">
										<span>
											Resources										</span>
									</a>
																			<div class="subitems-container">
											<div class="subitems-wrapper">
												<ul class="subItems">
																											<li class="subItem ">
															<a class="link" href="/resources/overview/" target="">
																<p class="title">Overview</p>
																														</a>
														</li>
																											<li class="subItem ">
															<a class="link" href="/resources/blog/" target="">
																<p class="title">Blog</p>
																														</a>
														</li>
																											<li class="subItem ">
															<a class="link" href="/resources/education/" target="">
																<p class="title">Education</p>
																														</a>
														</li>
																											<li class="subItem ">
															<a class="link" href="/resources/localized-docs-tutorials/" target="">
																<p class="title">Localized Docs &#038; Tutorials</p>
																														</a>
														</li>
																											<li class="subItem ">
															<a class="link" href="/resources/enterprise-program/" target="">
																<p class="title">Enterprise Program</p>
																														</a>
														</li>
																									</ul>
											</div>
										</div>
																	</li>
																							<li class="mainItem docs-menu">
									<a class="parentTitle" href="https://pytorch.org/docs/stable/index.html" target="_blank">
										<span>
											Docs										</span>
									</a>
																	</li>
																							<li class="mainItem tutorials-menu">
									<a class="parentTitle" href="https://pytorch.org/tutorials/" target="_blank">
										<span>
											Tutorials										</span>
									</a>
																	</li>
																							<li class="mainItem community-menu">
									<a class="parentTitle" href="/community/overview/" target="">
										<span>
											Community										</span>
									</a>
																			<div class="subitems-container">
											<div class="subitems-wrapper">
												<ul class="subItems">
																											<li class="subItem ">
															<a class="link" href="/community/overview/" target="">
																<p class="title">Overview</p>
																														</a>
														</li>
																											<li class="subItem ">
															<a class="link" href="/community/case-studies/" target="">
																<p class="title">Case Studies</p>
																														</a>
														</li>
																											<li class="subItem ">
															<a class="link" href="/community/ecosystem-tools/" target="">
																<p class="title">Ecosystem Tools</p>
																														</a>
														</li>
																											<li class="subItem ">
															<a class="link" href="/community/events/" target="">
																<p class="title">Events</p>
																														</a>
														</li>
																									</ul>
											</div>
										</div>
																	</li>
														<li class="github mainItem">
								<div class="github-wrapper">
									<a href="https://github.com/pytorch/pytorch" target="_blank" class="parentTitle" aria-label="See Pytorch on GitHub">
										<svg role="img" width="25" height="24" viewbox="0 0 25 24" fill="none" xmlns="http://www.w3.org/2000/svg">
<path d="M23.0227 6.33146C21.9311 4.51257 20.4504 3.07256 18.5803 2.01109C16.7099 0.949571 14.6679 0.418945 12.453 0.418945C10.2384 0.418945 8.19578 0.949733 6.32575 2.01109C4.45545 3.07251 2.97484 4.51257 1.88325 6.33146C0.791831 8.15029 0.246094 10.1365 0.246094 12.2899C0.246094 14.8767 1.02214 17.2029 2.57462 19.2689C4.12694 21.3351 6.1323 22.7648 8.59054 23.5582C8.87669 23.6099 9.08851 23.5736 9.22624 23.4502C9.36403 23.3266 9.43284 23.1719 9.43284 22.9866C9.43284 22.9557 9.43011 22.6776 9.42482 22.152C9.41936 21.6263 9.4168 21.1677 9.4168 20.7765L9.05121 20.838C8.81812 20.8795 8.52407 20.8971 8.16906 20.8921C7.81422 20.8873 7.44584 20.8511 7.06445 20.7839C6.68288 20.7172 6.32798 20.5627 5.99947 20.3205C5.67113 20.0783 5.43803 19.7614 5.30025 19.37L5.14131 19.0143C5.03537 18.7775 4.86858 18.5145 4.64072 18.2261C4.41286 17.9375 4.18244 17.7418 3.94935 17.6388L3.83806 17.5613C3.76391 17.5098 3.6951 17.4477 3.63147 17.3757C3.5679 17.3036 3.5203 17.2315 3.48851 17.1593C3.45667 17.087 3.48305 17.0277 3.56795 16.9812C3.65285 16.9347 3.80628 16.9121 4.0289 16.9121L4.34667 16.9583C4.55861 16.9996 4.82076 17.123 5.13346 17.3292C5.44599 17.5353 5.70291 17.8032 5.90427 18.1328C6.14811 18.5554 6.44188 18.8774 6.78643 19.099C7.13069 19.3206 7.4778 19.4312 7.82741 19.4312C8.17702 19.4312 8.47898 19.4054 8.73339 19.3542C8.98753 19.3026 9.22596 19.2252 9.44859 19.1222C9.54395 18.4315 9.8036 17.9008 10.2273 17.5299C9.62339 17.4682 9.08044 17.3752 8.59817 17.2516C8.11617 17.1279 7.61809 16.927 7.10425 16.6485C6.59013 16.3704 6.16364 16.025 5.82466 15.613C5.48563 15.2008 5.20739 14.6596 4.99033 13.99C4.77316 13.3201 4.66455 12.5473 4.66455 11.6714C4.66455 10.4243 5.08319 9.36302 5.92031 8.48704C5.52816 7.54944 5.56518 6.49837 6.03148 5.33393C6.33878 5.24108 6.7945 5.31076 7.39841 5.54253C8.00244 5.77441 8.44468 5.97305 8.7256 6.13775C9.00651 6.30238 9.23159 6.4419 9.40116 6.55506C10.3868 6.28723 11.404 6.15328 12.4529 6.15328C13.5018 6.15328 14.5192 6.28723 15.5049 6.55506L16.1089 6.18425C16.5219 5.93683 17.0096 5.71009 17.5709 5.50398C18.1325 5.29798 18.562 5.24124 18.8588 5.33409C19.3354 6.49859 19.3779 7.54961 18.9857 8.4872C19.8227 9.36319 20.2415 10.4247 20.2415 11.6715C20.2415 12.5474 20.1325 13.3227 19.9157 13.9977C19.6986 14.6729 19.4179 15.2135 19.0737 15.6208C18.729 16.028 18.2998 16.3706 17.786 16.6487C17.272 16.927 16.7738 17.1278 16.2918 17.2516C15.8096 17.3754 15.2666 17.4684 14.6627 17.5302C15.2135 17.9937 15.4889 18.7254 15.4889 19.725V22.9862C15.4889 23.1715 15.5552 23.3261 15.6878 23.4497C15.8202 23.5731 16.0294 23.6095 16.3155 23.5578C18.7741 22.7644 20.7795 21.3347 22.3317 19.2685C23.8838 17.2024 24.6602 14.8763 24.6602 12.2895C24.6596 10.1363 24.1136 8.15029 23.0227 6.33146Z" fill="#262626"></path>
</svg>
									</a>
								</div>
							</li>
						</ul>
						
<div class="navItems-followContainer followMenu ">
			<div class="mainItem">Follow Us</div>
		<ul class="follow-list">
					<li class="followItem">
				<a aria-label="follow Menu  icon-twitter" href="https://twitter.com/pytorch" target="_blank" class=" icon-twitter">
					Twitter				</a>
			</li>
					<li class="followItem">
				<a aria-label="follow Menu  icon-facebook" href="https://www.facebook.com/pytorch" target="_blank" class=" icon-facebook">
					Facebook				</a>
			</li>
					<li class="followItem">
				<a aria-label="follow Menu  icon-youtube" href="https://www.youtube.com/pytorch" target="_blank" class=" icon-youtube">
					YouTube				</a>
			</li>
					<li class="followItem">
				<a aria-label="follow Menu  icon-linkedin" href="https://www.linkedin.com/company/pytorch" target="_blank" class=" icon-linkedin">
					Linkedin				</a>
			</li>
					<li class="followItem">
				<a aria-label="follow Menu  icon-medium" href="https://medium.com/pytorch" target="_blank" class=" icon-medium">
					Medium				</a>
			</li>
					<li class="followItem">
				<a aria-label="follow Menu  icon-github" href="https://github.com/pytorch/pytorch" target="_blank" class=" icon-github">
					GitHub				</a>
			</li>
			</ul>
</div>
					</li>
				</ul>
			</div>
		</div>
	</header>

	<main id="main" class="site-main" role="main">


<div class="Breadcrumbs">
	<div class="container breadcrumbs-lined">
		<ul class="list-container">
						<li class="breadcrumb-item breadcrumb-active">
				<a class="active-item" href="/blog">Blog</a>
			</li>
						<li class="breadcrumb-item">
				PyTorch 1.3 adds mobile, privacy, quantization, and named tensors			</li>
		</ul>
	</div>
</div>

<div class="BlogHeader ">
	<div class="container">
		<h2 class="title">PyTorch 1.3 adds mobile, privacy, quantization, and named tensors</h2>

		<div class="banner">
			
<img class="Image " src="/wp-content/uploads/2021/08/PyTorch_Blogs@3x-100-1.png" alt="">
		</div>

		<div class="foot">
			<div class="byline">
								<span class="date">October 10, 2019</span>
				<span class="author">by Team PyTorch</span>
			</div>

			
<div class="Share ">
  
  <div class="share-icons">
    
      </div>
</div>
		</div>


	</div>
</div>




<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">PyTorch continues to gain momentum because of its focus on meeting the needs of researchers, its streamlined workflow for production use, and most of all because of the enthusiastic support it has received from the AI community. PyTorch citations in papers on ArXiv <a href="https://www.oreilly.com/ideas/one-simple-graphic-researchers-love-pytorch-and-tensorflow?fbclid=IwAR3kYmlyD7zky37IYFu0cafQn7yemhl8P-7MNyB30z0q5RDzxcTOrP8kxDk" target="_blank">grew 194 percent in the first half of 2019 alone, as noted by O’Reilly</a>, and the number of contributors to the platform has grown more than 50 percent over the last year, to nearly 1,200. Facebook, Microsoft, Uber, and other organizations across industries are increasingly using it as the foundation for their most important machine learning (ML) research and production workloads.<br><br>We are now advancing the platform further with the release of PyTorch 1.3, which includes experimental support for features such as seamless model deployment to mobile devices, model quantization for better performance at inference time, and front-end improvements, like the ability to name tensors and create clearer code with less need for inline comments. We’re also launching a number of additional tools and libraries to support model interpretability and bringing multimodal research to production.<br><br>Additionally, we’ve collaborated with Google and Salesforce to add broad support for Cloud Tensor Processing Units, providing a significantly accelerated option for training large-scale deep neural networks. <a href="https://data.aliyun.com/bigdata/pai-pytorch?spm=5176.12825654.a9ylfrljh.d112.7b652c4ayuOO4M&amp;scm=20140722.1068.1.1098&amp;aly_as=-PvJ5e4c" target="_blank">Alibaba Cloud</a> also joins Amazon Web Services, Microsoft Azure, and Google Cloud as supported cloud platforms for PyTorch users. You can get started now at <a href="https://pytorch.org/get-started/locally/">pytorch.org</a>.</p>
	</div>
</div>

<div class="">
<h2 class="HeadingBlock Heading is-style-secondary-heading HeadingBlock  " id="block-adf97b3a-4923-4b64-828b-6712c4170221">
		
	PyTorch 1.3</h2>
	</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">The 1.3 release of PyTorch brings significant new features, including experimental support for mobile device deployment, eager mode quantization at 8-bit integer, and the ability to name tensors. With each of these enhancements, we look forward to additional contributions and improvements from the PyTorch community.</p>
	</div>
</div>

<div class="">
<h3 class="HeadingBlock Heading is-style-section-heading HeadingBlock  " id="block-e8cecf24-e334-42df-9475-57dc46af4500">
		
	NAMED TENSORS (EXPERIMENTAL)</h3>
	</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">Cornell University’s <a href="http://nlp.seas.harvard.edu/NamedTensor" target="_blank">Sasha Rush has argued</a> that, despite its ubiquity in deep learning, the traditional implementation of tensors has significant shortcomings, such as exposing private dimensions, broadcasting based on absolute position, and keeping type information in documentation. He proposed named tensors as an alternative approach.<br><br>Today, we name and access dimensions by comment:</p>
	</div>
</div>

<div class="code-block">
<pre class="wp-block-code"><code lang="bash" class="language-bash"># Tensor[N, C, H, W]
 images = torch.randn(32, 3, 56, 56)
 images.sum(dim=1)
 images.select(dim=1, index=0)</code></pre>
</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">But naming explicitly leads to more readable and maintainable code:</p>
	</div>
</div>

<div class="code-block">
<pre class="wp-block-code"><code lang="bash" class="language-bash">NCHW = [‘N’, ‘C’, ‘H’, ‘W’]
   images = torch.randn(32, 3, 56, 56, names=NCHW)
   images.sum('C')
   images.select('C', index=0)</code></pre>
</div>

<div class="">
<h3 class="HeadingBlock Heading is-style-section-heading HeadingBlock  " id="block-a07961d5-b02c-41ed-8a6e-2611a1ee0367">
		
	QUANTIZATION (EXPERIMENTAL)</h3>
	</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">It’s important to make efficient use of both server-side and on-device compute resources when developing ML applications. To support more efficient deployment on servers and edge devices, PyTorch 1.3 now supports 8-bit model quantization using the familiar eager mode Python API. Quantization refers to techniques used to perform computation and storage at reduced precision, such as 8-bit integer. This currently experimental feature includes support for post-training quantization, dynamic quantization, and quantization-aware training. It leverages the <a href="https://github.com/pytorch/FBGEMM" target="_blank">FBGEMM</a> and <a href="https://github.com/pytorch/QNNPACK" target="_blank">QNNPACK</a> state-of-the-art quantized kernel back ends, for x86 and ARM CPUs, respectively, which are integrated with PyTorch and now share a common API.<br><br>To learn more about the design and architecture, check out the API docs <a href="https://pytorch.org/docs/master/quantization.html">here</a>, and get started with any of the supported techniques using the tutorials available <a href="https://pytorch.org/tutorials/">here</a>.</p>
	</div>
</div>

<div class="">
<h3 class="HeadingBlock Heading is-style-section-heading HeadingBlock  " id="block-a19eaac6-c6ce-4b83-a178-9aa6c92226ef">
		
	PYTORCH MOBILE (EXPERIMENTAL)</h3>
	</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">Running ML on edge devices is growing in importance as applications continue to demand lower latency. It is also a foundational element for privacy-preserving techniques such as federated learning. To enable more efficient on-device ML, PyTorch 1.3 now supports an end-to-end workflow from Python to deployment on iOS and Android.<br><br>This is an early, experimental release, optimized for end-to-end development. Coming releases will focus on:</p>
	</div>
</div>


<div class="blog-list-container blog-list-container">
	<div class="container">
		<ul class="list unordered-list indent-con ">
												<li class="item">Optimization for size: Build level optimization and selective compilation depending on the operators needed for user applications (i.e., you pay binary size for only the operators you need)								</li>
												<li class="item">Performance: Further improvements to performance and coverage on mobile CPUs and GPUs								</li>
												<li class="item">High level API: Extend mobile native APIs to cover common preprocessing and integration tasks needed for incorporating ML in mobile applications. e.g. Computer vision and NLP								</li>
					</ul>
	</div>
</div>




<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">Learn more or get started on Android or iOS <a href="http://pytorch.org/mobile">here</a>.</p>
	</div>
</div>

<div class="">
<h2 class="HeadingBlock Heading is-style-secondary-heading HeadingBlock  " id="block-025047b4-10d4-4359-b315-4d7b19743ae7">
		
	New tools for model interpretability and privacy</h2>
	</div>

<div class="">
<h3 class="HeadingBlock Heading is-style-section-heading HeadingBlock  " id="block-6a53b4c7-ac8b-4baa-97d2-d8cfc23cfb35">
		
	CAPTUM</h3>
	</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">As models become ever more complex, it is increasingly important to develop new methods for model interpretability. To help address this need, we’re launching Captum, a tool to help developers working in PyTorch understand why their model generates a specific output. Captum provides state-of-the-art tools to understand how the importance of specific neurons and layers and affect predictions made by the models. Captum’s algorithms include integrated gradients, conductance, SmoothGrad and VarGrad, and DeepLift.<br><br>The example below shows how to apply model interpretability algorithms on a pretrained ResNet model and then visualize the attributions for each pixel by overlaying them on the image.</p>
	</div>
</div>

<div class="code-block">
<pre class="wp-block-code"><code lang="bash" class="language-bash">noise_tunnel = NoiseTunnel(integrated_gradients)

attributions_ig_nt, delta = noise_tunnel.attribute(input, n_samples=10, nt_type='smoothgrad_sq', target=pred_label_idx)
_ = viz.visualize_image_attr_multiple(["original_image", "heat_map"],
                                      ["all", "positive"],
                                      np.transpose(attributions_ig_nt.squeeze().cpu().detach().numpy(), (1,2,0)),
                                      np.transpose(transformed_img.squeeze().cpu().detach().numpy(), (1,2,0)),
                                      cmap=default_cmap,
                                      show_colorbar=True)</code></pre>
</div>


<div class="BlogImage BlogImage">
	<div class="container">
		<div class="imageCon">
			
<img class="Image image" src="/wp-content/uploads/2021/10/Captum-1.jpg" alt="">
		</div>
		<div class="descriptionCon">
					</div>
	</div>
</div>



<div class="BlogImage BlogImage">
	<div class="container">
		<div class="imageCon">
			
<img class="Image image" src="/wp-content/uploads/2021/10/Captum-2.png" alt="">
		</div>
		<div class="descriptionCon">
					</div>
	</div>
</div>




<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">Learn more about Captum at <a href="https://www.captum.ai/" target="_blank">captum.ai</a>.</p>
	</div>
</div>

<div class="">
<h3 class="HeadingBlock Heading is-style-section-heading HeadingBlock  " id="block-1ffd4737-1cd2-491d-b917-d66d2cdf7343">
		
	CRYPTEN</h3>
	</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">Practical applications of ML via cloud-based or machine-learning-as-a-service (MLaaS) platforms pose a range of security and privacy challenges. In particular, users of these platforms may not want or be able to share unencrypted data, which prevents them from taking full advantage of ML tools. To address these challenges, the ML community is exploring a number of technical approaches, at various levels of maturity. These include homomorphic encryption, secure multiparty computation, trusted execution environments, on-device computation, and differential privacy.<br><br>To provide a better understanding of how some of these technologies can be applied, we are releasing CrypTen, a new community-based research platform for taking the field of privacy-preserving ML forward. Learn more about CrypTen <a href="https://ai.facebook.com/blog/crypten-a-new-research-tool-for-secure-machine-learning-with-pytorch" target="_blank">here</a>. It is available on GitHub <a href="https://github.com/facebookresearch/CrypTen" target="_blank">here</a>.</p>
	</div>
</div>

<div class="">
<h2 class="HeadingBlock Heading is-style-secondary-heading HeadingBlock  " id="block-34cb1989-603f-4237-b3a9-db46a28f01f9">
		
	Tools for multimodal AI systems</h2>
	</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">Digital content is often made up of several modalities, such as text, images, audio, and video. For example, a single public post might contain an image, body text, a title, a video, and a landing page. Even one particular component may have more than one modality, such as a video that contains both visual and audio signals, or a landing page that is composed of images, text, and HTML sources.<br><br>The ecosystem of tools and libraries that work with PyTorch offer enhanced ways to address the challenges of building multimodal ML systems. Here are some of the latest libraries launching today:</p>
	</div>
</div>

<div class="">
<h3 class="HeadingBlock Heading is-style-section-heading HeadingBlock  " id="block-b808e0f9-f80f-48f7-af5d-0f746ad67a8a">
		
	DETECTRON2</h3>
	</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">Object detection and segmentation are used for tasks ranging from autonomous vehicles to content understanding for platform integrity. To advance this work, Facebook AI Research (FAIR) is releasing Detectron2, an object detection library now implemented in PyTorch. Detectron2 provides support for the latest models and tasks, increased flexibility to aid computer vision research, and improvements in maintainability and scalability to support production use cases.<br><br>Detectron2 is available <a href="https://github.com/facebookresearch/detectron2" target="_blank">here</a> and you can learn more <a href="https://ai.facebook.com/blog/-detectron2-a-pytorch-based-modular-object-detection-library-" target="_blank">here</a>.</p>
	</div>
</div>

<div class="">
<h3 class="HeadingBlock Heading is-style-section-heading HeadingBlock  " id="block-75fbaaa3-e65c-42dd-929f-7e451f343a5c">
		
	SPEECH EXTENSIONS TO FAIRSEQ</h3>
	</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">Language translation and audio processing are critical components in systems and applications such as search, translation, speech, and assistants. There has been tremendous progress in these fields recently thanks to the development of new architectures like transformers, as well as large-scale pretraining methods. We’ve extended fairseq, a framework for sequence-to-sequence applications such as language translation, to include support for end-to-end learning for speech and audio recognition tasks.These extensions to fairseq enable faster exploration and prototyping of new speech research ideas while offering a clear path to production.<br><br>Get started with fairseq <a href="https://github.com/pytorch/fairseq/tree/master/examples/speech_recognition" target="_blank">here</a>.</p>
	</div>
</div>

<div class="">
<h2 class="HeadingBlock Heading is-style-secondary-heading HeadingBlock  " id="block-a7f9ccaa-9831-4d8a-a65e-2fef99eed3e3">
		
	Cloud provider and hardware ecosystem support</h2>
	</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">Cloud providers such as Amazon Web Services, Microsoft Azure, and Google Cloud provide extensive support for anyone looking to develop ML on PyTorch and deploy in production. We’re excited to share the general availability of Google Cloud TPU support and a newly launched integration with Alibaba Cloud. We’re also expanding hardware ecosystem support.</p>
	</div>
</div>


<div class="blog-list-container blog-list-container">
	<div class="container">
		<ul class="list unordered-list indent-con ">
												<li class="item">Google Cloud TPU support now broadly available. To accelerate the largest-scale machine learning (ML) applications deployed today and enable rapid development of the ML applications of tomorrow, Google created custom silicon chips called Tensor Processing Units (<a href="https://cloud.google.com/tpu/" target="_blank">TPUs</a>). When assembled into multi-rack ML supercomputers called <a href="https://cloud.google.com/blog/products/ai-machine-learning/cloud-tpu-pods-break-ai-training-records" target="_blank">Cloud TPU Pods</a>, these TPUs can complete ML workloads in minutes or hours that previously took days or weeks on other systems. Engineers from Facebook, Google, and Salesforce worked together to enable and pilot Cloud TPU support in PyTorch, including experimental support for Cloud TPU Pods. PyTorch support for Cloud TPUs is also available in Colab. Learn more about how to get started with PyTorch on Cloud TPUs <a href="https://github.com/pytorch/xla" target="_blank">here</a>.								</li>
												<li class="item">Alibaba adds support for PyTorch in Alibaba Cloud. The initial integration involves a one-click solution for PyTorch 1.x, Data Science Workshop notebook service, distributed training with Gloo/NCCL, as well as seamless integration with Alibaba IaaS such as OSS, ODPS, and NAS. Together with the toolchain provided by Alibaba, we look forward to significantly reducing the overhead necessary for adoption, as well as helping Alibaba Cloud’s global customer base leverage PyTorch to develop new AI applications.								</li>
												<li class="item">ML hardware ecosystem expands. In addition to key GPU and CPU partners, the PyTorch ecosystem has also enabled support for dedicated ML accelerators. Updates from <a href="https://www.intel.ai/nnpi-glow-pytorch/" target="_blank">Intel</a> and <a href="https://medium.com/@HabanaLabs/unlocking-ai-scaling-through-software-and-hardware-interface-standardization-77561cb7598b" target="_blank">Habana</a> showcase how PyTorch, connected to the Glow optimizing compiler, enables developers to utilize these market-specific solutions.								</li>
					</ul>
	</div>
</div>


<div class="">
<h2 class="HeadingBlock Heading is-style-secondary-heading HeadingBlock  " id="block-c5c1665e-777d-4e27-8cf8-59cd551f9343">
		
	Growth in the PyTorch community</h2>
	</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">As an open source, community-driven project, PyTorch benefits from wide range of contributors bringing new capabilities to the ecosystem. Here are some recent examples:</p>
	</div>
</div>


<div class="blog-list-container blog-list-container">
	<div class="container">
		<ul class="list unordered-list indent-con ">
												<li class="item">Mila SpeechBrain aims to provide an open source, all-in-one speech toolkit based on PyTorch. The goal is to develop a single, flexible, user-friendly toolkit that can be used to easily develop state-of-the-art systems for speech recognition (both end to end and HMM-DNN), speaker recognition, speech separation, multi-microphone signal processing (e.g., beamforming), self-supervised learning, and many others. <a href="https://speechbrain.github.io/" target="_blank">Learn more</a>								</li>
												<li class="item">SpaCy is a new wrapping library with consistent and easy-to-use interfaces to several models, in order to extract features to power NLP pipelines. Support is provided for via spaCy’s standard training API. The library also calculates an alignment so the transformer features can be related back to actual words instead of just wordpieces. <a href="https://explosion.ai/blog/spacy-pytorch-transformers" target="_blank">Learn more</a>								</li>
												<li class="item">HuggingFace PyTorch-Transformers (formerly known as pytorch-pretrained-bert is a library of state-of-the-art pretrained models for Natural Language Processing (NLP). The library currently contains PyTorch implementations, pretrained model weights, usage scripts, and conversion utilities for models such as BERT, GPT-2, RoBERTa, and DistilBERT. It has also grown quickly, with more than 13,000 GitHub stars and a broad set of users. <a href="https://github.com/huggingface/transformers" target="_blank">Learn more</a>								</li>
												<li class="item">PyTorch Lightning is a Keras-like ML library for PyTorch. It leaves core training and validation logic to you and automates the rest. Reproducibility is a crucial requirement for many fields of research, including those based on ML techniques. As the number of research papers submitted to arXiv and conferences skyrockets into the tens of thousands, scaling reproducibility becomes difficult. <a href="https://github.com/williamFalcon/pytorch-lightning" target="_blank">Learn more</a>.								</li>
					</ul>
	</div>
</div>




<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">We recently held the first online Global PyTorch Summer Hackathon, where researchers and developers around the world were invited to build innovative new projects with PyTorch. Nearly 1,500 developers participated, submitting projects ranging from livestock disease detection to AI-powered financial assistants. The winning projects were:</p>
	</div>
</div>


<div class="blog-list-container blog-list-container">
	<div class="container">
		<ul class="list unordered-list indent-con ">
												<li class="item">Torchmeta, which provides extensions for PyTorch to simplify the development of meta-learning algorithms in PyTorch. It features a unified interface inspired by TorchVision for both few-shot classification and regression problems, to allow easy benchmarking on multiple data sets to aid with reproducibility.								</li>
												<li class="item">Open-Unmix, a system for end-to-end music demixing with PyTorch. Demixing separates the individual instruments or vocal track from any stereo recording.								</li>
												<li class="item">Endless AI-Generated Tees, a store featuring AI-generated T-shirt designs that can be purchased and delivered worldwide. The system uses a state-of-the-art generative model (StyleGAN) that was built with PyTorch and then trained on modern art.								</li>
					</ul>
	</div>
</div>




<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">Visit <a href="https://pytorch.org/">pytorch.org</a> to learn more and get started with PyTorch 1.3 and the latest libraries and ecosystem projects. We look forward to the contributions, exciting research advancements, and real-world applications that the community builds with PyTorch.<br><br><em>We’d like to thank the entire PyTorch team and the community for all their contributions to this work.</em></p>
	</div>
</div>	</main>

	<footer class="Footer">
		<div class="mainNav">
			<div class="logo">
				<a href="/" aria-label="Go to Pytorch home">
					<svg width="30" height="35" viewbox="0 0 30 35" fill="none" xmlns="http://www.w3.org/2000/svg" role="img">
<path d="M24.8384 10.3748L22.3344 12.8296C26.5077 16.9211 26.5077 23.5842 22.3344 27.6757C18.1612 31.7671 11.3647 31.7671 7.19148 27.6757C3.01823 23.5842 3.01823 16.9211 7.19148 12.8296L13.8687 6.28337L14.7033 5.34818V0.438477L4.56829 10.3748C-1.03579 15.869 -1.03579 24.6363 4.56829 30.1305C10.1724 35.6247 19.1151 35.6247 24.7191 30.1305C30.4424 24.6363 30.4424 15.7521 24.8384 10.3748Z" fill="#F05F42"></path>
<ellipse cx="19.8316" cy="7.80298" rx="1.90777" ry="1.87036" fill="#F05F42"></ellipse>
</svg>
				</a>
			</div>

			<ul class="footerNav">
													<li class="mainItem">
						<a href="#" target="" class="footer-item  ">
							PyTorch						</a>
													<ul>
																	<li class="subItem">
										<a href="/install/" target="" class=" ">
											Install										</a>
																			</li>
																	<li class="subItem">
										<a href="/features/" target="" class=" ">
											Features										</a>
																			</li>
																	<li class="subItem">
										<a href="/resources/" target="" class=" ">
											Resources										</a>
																			</li>
																	<li class="subItem">
										<a href="https://pytorch.org/docs/stable/index.html" target="" class="docs ">
											Docs										</a>
																			</li>
																	<li class="subItem">
										<a href="https://pytorch.org/tutorials/" target="" class="tutorials ">
											Tutorials										</a>
																			</li>
																	<li class="subItem">
										<a href="/community/" target="" class=" ">
											Community										</a>
																			</li>
																	<li class="subItem">
										<a href="https://github.com/pytorch/pytorch" target="" class=" ">
											Github										</a>
																			</li>
															</ul>
											</li>
									<li class="mainItem">
						<a href="#" target="" class="footer-item  ">
							Support						</a>
													<ul>
																	<li class="subItem">
										<a href="https://github.com/pytorch/pytorch/issues" target="_blank" class=" icon-github">
											Github Issues										</a>
																			</li>
																	<li class="subItem">
										<a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank" class=" ">
											Brand Guidelines										</a>
																			</li>
																	<li class="subItem">
										<a href="https://discuss.pytorch.org/" target="_blank" class=" ">
											Discuss										</a>
																			</li>
															</ul>
											</li>
								<li class="mainItem">
					
<div class="navItems-followContainer followMenu ">
			<div class="mainItem">Follow Us</div>
		<ul class="follow-list">
					<li class="followItem">
				<a aria-label="follow Menu  icon-twitter" href="https://twitter.com/pytorch" target="_blank" class=" icon-twitter">
					Twitter				</a>
			</li>
					<li class="followItem">
				<a aria-label="follow Menu  icon-facebook" href="https://www.facebook.com/pytorch" target="_blank" class=" icon-facebook">
					Facebook				</a>
			</li>
					<li class="followItem">
				<a aria-label="follow Menu  icon-youtube" href="https://www.youtube.com/pytorch" target="_blank" class=" icon-youtube">
					YouTube				</a>
			</li>
					<li class="followItem">
				<a aria-label="follow Menu  icon-linkedin" href="https://www.linkedin.com/company/pytorch" target="_blank" class=" icon-linkedin">
					Linkedin				</a>
			</li>
					<li class="followItem">
				<a aria-label="follow Menu  icon-medium" href="https://medium.com/pytorch" target="_blank" class=" icon-medium">
					Medium				</a>
			</li>
					<li class="followItem">
				<a aria-label="follow Menu  icon-github" href="https://github.com/pytorch/pytorch" target="_blank" class=" icon-github">
					GitHub				</a>
			</li>
			</ul>
</div>
				</li>
			</ul>
		</div>
		<div class="legalNav">
			<ul class="legalNavList">
													<li>
						<a href="/wp-content/uploads/2021/11/fb-tos-privacy-policy.pdf" target="" class=" ">
							Terms						</a>
					</li>
									<li>
						<a href="/wp-content/uploads/2021/11/fb-oss-privacy-policy.pdf" target="" class=" ">
							Privacy						</a>
					</li>
							</ul>
		</div>
	</footer>
</div>

<script id="pytorch-classic-js-js-extra">
var gridData = {"build":{"stable":"Stable (1.9.0)","nightly":"Preview (Nightly)","lts":"LTS (1.8.1)"},"os":{"mac":"MacOS","linux":"Linux","windows":"Windows"},"package":{"conda":"Conda","pip":"Pip","libtorch":"LibTorch","source":"Source"},"language":{"python":"Python","cplusplus":"C++\/Java"},"platform":{"cuda10.2":"CUDA 10.2","cuda11.1":"CUDA 11.1","rocm":"ROCm 4.2(beta)","cpu":"CPU"}};
var platformOSSupport = {"linux":["cuda10.2","rocm","cpu"],"mac":["cpu"],"windows":["cuda10.2","rocm","cpu"]};
var packageLanguageSupport = {"python":["pip","conda","source"],"cplusplus":["libtorch"]};
var commands = {"stable,conda,mac,cpu,python":"conda install pytorch torchvision torchaudio -c pytorch","nightly,conda,linux,cpu,python":"conda install pytorch torchvision torchaudio cpuonly -c pytorch-nightly","stable,libtorch,windows,rocm,cplusplus":"NOTE: ROCm is not available on Windows","stable,conda,windows,cpu,python":"conda install pytorch torchvision torchaudio cpuonly -c pytorch-nightly","stable,conda,windows,rocm,python":"NOTE: ROCm is not available on Windows","stable,pip,windows,rocm,python":"NOTE: ROCm is not available on Windows","stable,pip,windows,cpu,python":"pip3 install --pre torch torchvision torchaudio -f https:\/\/download.pytorch.org\/whl\/nightly\/cpu\/torch_nightly.html","stable,conda,windows,cuda10.2,python":"conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch-nightly","stable,conda,windows,cuda11.1,python":"NOTE: \\'conda-forge\\' channel is required for cudatoolkit 11.1\r\nconda install pytorch torchvision torchaudio cudatoolkit=11.1 -c pytorch-nightly -c conda-forge","stable,libtorch,mac,rocm,cplusplus":"NOTE: ROCm is not available on MacOS","stable,conda,mac,rocm,python":"NOTE: ROCm is not available on MacOS","stable,conda,linux,cpu,python":"conda install pytorch torchvision torchaudio cpuonly -c pytorch","stable,conda,linux,rocm,python":"NOTE: Conda packages are not currently available for ROCm, please use pip instead","stable,conda,linux,cuda10.2,python":"conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch","stable,conda,linux,cuda11.1,python":"NOTE: \\'nvidia\\' channel is required for cudatoolkit 11.1\r\nconda install pytorch torchvision torchaudio cudatoolkit=11.1 -c pytorch -c nvidia","lts,libtorch,windows,rocm,cplusplus":"NOTE: ROCm is not supported in LTS","lts,pip,mac,cpu,python":"# macOS is not currently supported for lts","lts,conda,mac,cuda10.2,python":"# macOS is not currently supported for lts","lts,conda,mac,cuda11.1,python":"# macOS is not currently supported for lts","lts,conda,mac,rocm,python":"# macOS is not currently supported for lts","lts,conda,mac,cpu,python":"# macOS is not currently supported for lts","stable,conda,mac,cuda10.2,python":"# MacOS Binaries dont support CUDA, install from source if CUDA is needed\r\nconda install pytorch torchvision torchaudio -c pytorch","lts,libtorch,mac,cpu,cplusplus":"# macOS is not currently supported for lts","lts,libtorch,mac,cuda10.2,cplusplus":"# macOS is not currently supported for lts","lts,libtorch,mac,cuda11.1,cplusplus":"# macOS is not currently supported for lts","lts,libtorch,mac,rocm,cplusplus":"# macOS is not currently supported for lts","lts,pip,windows,rocm,python":"NOTE: ROCm is not supported in LTS","stable,libtorch,linux,cpu,cplusplus":"Download here (Pre-cxx11 ABI):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/cpu\/libtorch-shared-with-deps-1.9.1%2Bcpu.zip\">https:\/\/download.pytorch.org\/libtorch\/cpu\/libtorch-shared-with-deps-1.9.1%2Bcpu.zip<\/a>\r\nDownload here (cxx11 ABI):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/cpu\/libtorch-cxx11-abi-shared-with-deps-1.9.1%2Bcpu.zip\">https:\/\/download.pytorch.org\/libtorch\/cpu\/libtorch-cxx11-abi-shared-with-deps-1.9.1%2Bcpu.zip<\/a>","stable,pip,linux,cpu,python":"pip3 install --pre torch torchvision torchaudio -f https:\/\/download.pytorch.org\/whl\/nightly\/cpu\/torch_nightly.html","stable,pip,linux,cuda11.1,python":"pip3 install torch==1.9.1+cu111 torchvision==0.10.1+cu111 torchaudio==0.9.1 -f https:\/\/download.pytorch.org\/whl\/torch_stable.html","stable,pip,linux,cuda10.2,python":"pip3 install torch torchvision torchaudio","stable,pip,linux,rocm,python":"pip3 install torch torchvision==0.10.1 -f https:\/\/download.pytorch.org\/whl\/rocm4.2\/torch_stable.html","stable,libtorch,linux,cuda10.2,cplusplus":"Download here (Pre-cxx11 ABI):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/cu102\/libtorch-shared-with-deps-1.9.1%2Bcu102.zip\">https:\/\/download.pytorch.org\/libtorch\/cu102\/libtorch-shared-with-deps-1.9.1%2Bcu102.zip<\/a>\r\nDownload here (cxx11 ABI):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/cu102\/libtorch-cxx11-abi-shared-with-deps-1.9.1%2Bcu102.zip\">https:\/\/download.pytorch.org\/libtorch\/cu102\/libtorch-cxx11-abi-shared-with-deps-1.9.1%2Bcu102.zip<\/a>","stable,libtorch,linux,cuda11.1,cplusplus":"Download here (Pre-cxx11 ABI):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/cu111\/libtorch-shared-with-deps-1.9.1%2Bcu111.zip\">https:\/\/download.pytorch.org\/libtorch\/cu111\/libtorch-shared-with-deps-1.9.1%2Bcu111.zip<\/a>\r\nDownload here (cxx11 ABI):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/cu111\/libtorch-cxx11-abi-shared-with-deps-1.9.1%2Bcu111.zip\">https:\/\/download.pytorch.org\/libtorch\/cu111\/libtorch-cxx11-abi-shared-with-deps-1.9.1%2Bcu111.zip<\/a>","stable,libtorch,linux,rocm,cplusplus":"LibTorch binaries are not available for ROCm, please build it from source","stable,pip,mac,cuda10.2,python":"# MacOS Binaries dont support CUDA, install from source if CUDA is needed\r\npip3 install torch torchvision torchaudio","stable,pip,mac,cuda11.1,python":"# MacOS Binaries dont support CUDA, install from source if CUDA is needed\r\npip3 install torch torchvision torchaudio","stable,pip,mac,rocm,python":"NOTE: ROCm is not available on MacOS","stable,pip,mac,cpu,python":"pip3 install torch torchvision torchaudio","stable,conda,mac,cuda11.1,python":"# MacOS Binaries dont support CUDA, install from source if CUDA is needed\r\nconda install pytorch torchvision torchaudio -c pytorch","stable,libtorch,mac,cpu,cplusplus":"Download here:\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/cpu\/libtorch-macos-1.9.1.zip\">https:\/\/download.pytorch.org\/libtorch\/cpu\/libtorch-macos-1.9.1.zip<\/a>","stable,libtorch,mac,cuda10.2,cplusplus":"MacOS binaries do not support CUDA. Download CPU libtorch here:\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/cpu\/libtorch-macos-1.9.1.zip\">https:\/\/download.pytorch.org\/libtorch\/cpu\/libtorch-macos-1.9.1.zip<\/a>","stable,libtorch,mac,cuda11.1,cplusplus":"MacOS binaries do not support CUDA. Download CPU libtorch here:\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/cpu\/libtorch-macos-1.9.1.zip\">https:\/\/download.pytorch.org\/libtorch\/cpu\/libtorch-macos-1.9.1.zip<\/a>","stable,libtorch,windows,cuda11.1,python":"Download here (Release version):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/cu111\/libtorch-win-shared-with-deps-1.9.1%2Bcu111.zip\">https:\/\/download.pytorch.org\/libtorch\/cu111\/libtorch-win-shared-with-deps-1.9.1%2Bcu111.zip<\/a>\r\nDownload here (Debug version):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/cu111\/libtorch-win-shared-with-deps-debug-1.9.1%2Bcu111.zip\">https:\/\/download.pytorch.org\/libtorch\/cu111\/libtorch-win-shared-with-deps-debug-1.9.1%2Bcu111.zip<\/a>","stable,libtorch,windows,cuda10.2,cplusplus":"Download here (Release version):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/nightly\/cu102\/libtorch-win-shared-with-deps-latest.zip\">https:\/\/download.pytorch.org\/libtorch\/nightly\/cu102\/libtorch-win-shared-with-deps-latest.zip<\/a>\r\nDownload here (Debug version):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/nightly\/cu102\/libtorch-win-shared-with-deps-debug-latest.zip\">https:\/\/download.pytorch.org\/libtorch\/nightly\/cu102\/libtorch-win-shared-with-deps-debug-latest.zip<\/a>","stable,libtorch,windows,cpu,cplusplus":"Download here (Release version):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/nightly\/cpu\/libtorch-win-shared-with-deps-latest.zip\">https:\/\/download.pytorch.org\/libtorch\/nightly\/cpu\/libtorch-win-shared-with-deps-latest.zip<\/a>\r\nDownload here (Debug version):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/nightly\/cpu\/libtorch-win-shared-with-deps-debug-latest.zip\">https:\/\/download.pytorch.org\/libtorch\/nightly\/cpu\/libtorch-win-shared-with-deps-debug-latest.zip<\/a>","stable,pip,windows,cuda11.1,python":"pip3 install --pre torch torchvision torchaudio -f https:\/\/download.pytorch.org\/whl\/nightly\/cu111\/torch_nightly.html","stable,pip,windows,cuda10.2,python":"pip3 install --pre torch torchvision torchaudio -f https:\/\/download.pytorch.org\/whl\/nightly\/cu102\/torch_nightly.html","stable,libtorch,windows,cuda11.1,cplusplus":"Download here (Release version):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/nightly\/cu111\/libtorch-win-shared-with-deps-latest.zip\">https:\/\/download.pytorch.org\/libtorch\/nightly\/cu111\/libtorch-win-shared-with-deps-latest.zip<\/a>\r\nDownload here (Debug version):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/nightly\/cu111\/libtorch-win-shared-with-deps-debug-latest.zip\">https:\/\/download.pytorch.org\/libtorch\/nightly\/cu111\/libtorch-win-shared-with-deps-debug-latest.zip<\/a>","lts,pip,linux,cpu,python":"pip3 install torch==1.8.2+cpu torchvision==0.9.2+cpu torchaudio==0.8.2 -f https:\/\/download.pytorch.org\/whl\/lts\/1.8\/torch_lts.html","lts,pip,linux,cuda10.2,python":"pip3 install torch==1.8.2+cu102 torchvision==0.9.2+cu102 torchaudio==0.8.2 -f https:\/\/download.pytorch.org\/whl\/lts\/1.8\/torch_lts.html","lts,pip,linux,cuda11.1,python":"pip3 install torch==1.8.2+cu111 torchvision==0.9.2+cu111 torchaudio==0.8.2 -f https:\/\/download.pytorch.org\/whl\/lts\/1.8\/torch_lts.html","lts,pip,linux,rocm,python":"NOTE: ROCm is not supported in LTS","lts,conda,linux,cuda10.2,python":"conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch-lts","lts,conda,linux,cuda11.1,python":"NOTE: \\'nvidia\\' channel is required for cudatoolkit 11.1\r\nconda install pytorch torchvision torchaudio cudatoolkit=11.1 -c pytorch-lts -c nvidia","lts,conda,linux,rocm,python":"NOTE: ROCm is not supported in LTS","lts,conda,linux,cpu,python":"conda install pytorch torchvision torchaudio cpuonly -c pytorch-lts","lts,libtorch,linux,cpu,cplusplus":"Download here (Pre-cxx11 ABI):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cpu\/libtorch-shared-with-deps-1.8.2%2Bcpu.zip\">https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cpu\/libtorch-shared-with-deps-1.8.2%2Bcpu.zip<\/a>\r\nDownload here (cxx11 ABI):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cpu\/libtorch-cxx11-abi-shared-with-deps-1.8.2%2Bcpu.zip\">https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cpu\/libtorch-cxx11-abi-shared-with-deps-1.8.2%2Bcpu.zip<\/a>","lts,libtorch,linux,cuda10.2,cplusplus":"Download here (Pre-cxx11 ABI):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu102\/libtorch-shared-with-deps-1.8.2%2Bcu102.zip\">https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu102\/libtorch-shared-with-deps-1.8.2%2Bcu102.zip<\/a>\r\nDownload here (cxx11 ABI):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu102\/libtorch-cxx11-abi-shared-with-deps-1.8.2%2Bcu102.zip\">https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu102\/libtorch-cxx11-abi-shared-with-deps-1.8.2%2Bcu102.zip<\/a>","lts,libtorch,linux,cuda11.1,cplusplus":"Download here (Pre-cxx11 ABI):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu111\/libtorch-shared-with-deps-1.8.2%2Bcu111.zip\">https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu111\/libtorch-shared-with-deps-1.8.2%2Bcu111.zip<\/a>\r\nDownload here (cxx11 ABI):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu111\/libtorch-cxx11-abi-shared-with-deps-1.8.2%2Bcu111.zip\">https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu111\/libtorch-cxx11-abi-shared-with-deps-1.8.2%2Bcu111.zip<\/a>","lts,libtorch,linux,rocm,python":"NOTE: ROCm is not supported in LTS","lts,pip,mac,cuda10.2,python":"# macOS is not currently supported for lts","lts,pip,mac,cuda11.1,python":"# macOS is not currently supported for lts","lts,pip,mac,rocm,python":"# macOS is not currently supported for lts","lts,pip,windows,cpu,python":"pip3 install torch==1.8.2+cpu torchvision==0.9.2+cpu torchaudio===0.8.2 -f https:\/\/download.pytorch.org\/whl\/lts\/1.8\/torch_lts.html","lts,pip,windows,cuda10.2,python":"pip3 install torch==1.8.2+cu102 torchvision==0.9.2+cu102 torchaudio===0.8.2 -f https:\/\/download.pytorch.org\/whl\/lts\/1.8\/torch_lts.html","lts,pip,windows,cuda11.1,python":"pip3 install torch==1.8.2+cu111 torchvision==0.9.2+cu111 torchaudio===0.8.2 -f https:\/\/download.pytorch.org\/whl\/lts\/1.8\/torch_lts.html","lts,conda,windows,cuda10.2,python":"conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch-lts","lts,conda,windows,cuda11.1,python":"NOTE: \\'conda-forge\\' channel is required for cudatoolkit 11.1\r\nconda install pytorch torchvision torchaudio cudatoolkit=11.1 -c pytorch-lts -c conda-forge","lts,conda,windows,cpu,python":"conda install pytorch torchvision torchaudio cpuonly -c pytorch-lts","lts,conda,windows,rocm,python":"NOTE: ROCm is not supported in LTS","lts,libtorch,windows,cpu,cplusplus":"Download here (Release version):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cpu\/libtorch-win-shared-with-deps-1.8.2%2Bcpu.zip\">https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cpu\/libtorch-win-shared-with-deps-1.8.2%2Bcpu.zip<\/a>\r\nDownload here (Debug version):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cpu\/libtorch-win-shared-with-deps-debug-1.8.2%2Bcpu.zip\">https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cpu\/libtorch-win-shared-with-deps-debug-1.8.2%2Bcpu.zip<\/a>","lts,libtorch,windows,cuda10.2,cplusplus":"Download here (Release version):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu102\/libtorch-win-shared-with-deps-1.8.2%2Bcu102.zip\">https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu102\/libtorch-win-shared-with-deps-1.8.2%2Bcu102.zip<\/a>\r\nDownload here (Debug version):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu102\/libtorch-win-shared-with-deps-debug-1.8.2%2Bcu102.zip\">https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu102\/libtorch-win-shared-with-deps-debug-1.8.2%2Bcu102.zip<\/a>","lts,libtorch,windows,cuda11.1,cplusplus":"Download here (Release version):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu111\/libtorch-win-shared-with-deps-1.8.2%2Bcu111.zip\">https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu111\/libtorch-win-shared-with-deps-1.8.2%2Bcu111.zip<\/a>\r\nDownload here (Debug version):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu111\/libtorch-win-shared-with-deps-debug-1.8.2%2Bcu111.zip\">https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu111\/libtorch-win-shared-with-deps-debug-1.8.2%2Bcu111.zip<\/a>"};
</script>
<script src="/wp-content/themes/pytorch/assets/js/index.bundle.js?ver=1" id="pytorch-classic-js-js"></script>
<script src="/wp-content/themes/pytorch/assets/js/blog-header.bundle.js?ver=1" id="pytorch-blog-header-js"></script>
<script src="/wp-content/themes/pytorch/assets/js/blog-text.bundle.js?ver=1" id="pytorch-blog-text-js"></script>
<script src="/wp-content/themes/pytorch/assets/js/heading.bundle.js?ver=1" id="pytorch-heading-js"></script>
<script src="/wp-content/themes/pytorch/assets/js/blog-list.bundle.js?ver=1" id="pytorch-blog-list-js"></script>
<script src="/wp-content/themes/pytorch/assets/js/blog-image.bundle.js?ver=1" id="pytorch-blog-image-js"></script>
<script id="mkaz-code-syntax-prism-js-js-extra">
var prism_settings = {"pluginUrl":"\/wp-content\/plugins\/code-syntax-block\/"};
</script>
<script src="/wp-content/plugins/code-syntax-block/assets/prism/prism.js?ver=1641826791" id="mkaz-code-syntax-prism-js-js"></script>
<script src="/wp-content/plugins/simply-static-pro/assets/fuse.js?ver=1.1" id="ssp-fuse-js"></script>
<script src="/wp-content/plugins/simply-static-pro/assets/ssp-search.js?ver=1.1" id="ssp-search-js"></script>
<script src="https://stats.wp.com/e-202203.js" defer></script>
<script>
	_stq = window._stq || [];
	_stq.push([ 'view', {v:'ext',j:'1:10.4',blog:'195752808',post:'1323',tz:'0',srv:'pytorch-org-preprod.go-vip.net'} ]);
	_stq.push([ 'clickTrackerInit', '195752808', '1323' ]);
</script>

</body>
</html>