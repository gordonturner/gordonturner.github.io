<!DOCTYPE html>
<html lang="en-US">
<head>
  <title> PyTorch 0.4.0 Migration Guide</title>
	<!-- Google Tag Manager -->
	<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
	new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
	j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
	'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
	})(window,document,'script','dataLayer','GTM-52DXT37');</script>
	<!-- End Google Tag Manager -->
	<!-- Docsearch -->
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css">
	<script src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script>
	<!-- End Docsearch -->

	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta name="robots" content="max-image-preview:large">
<link rel="dns-prefetch" href="//s.w.org">
<link rel="alternate" type="application/rss+xml" title="pytorch-org-preprod.go-vip.net &raquo; PyTorch 0.4.0 Migration Guide Comments Feed" href="/pytorch-0-4-0-migration-guide/feed/">
		<script type="text/javascript">
			window._wpemojiSettings = {"baseUrl":"https:\/\/s.w.org\/images\/core\/emoji\/13.0.1\/72x72\/","ext":".png","svgUrl":"https:\/\/s.w.org\/images\/core\/emoji\/13.0.1\/svg\/","svgExt":".svg","source":{"concatemoji":"\/wp-includes\/js\/wp-emoji-release.min.js?ver=5.7.5"}};
			!function(e,a,t){var n,r,o,i=a.createElement("canvas"),p=i.getContext&&i.getContext("2d");function s(e,t){var a=String.fromCharCode;p.clearRect(0,0,i.width,i.height),p.fillText(a.apply(this,e),0,0);e=i.toDataURL();return p.clearRect(0,0,i.width,i.height),p.fillText(a.apply(this,t),0,0),e===i.toDataURL()}function c(e){var t=a.createElement("script");t.src=e,t.defer=t.type="text/javascript",a.getElementsByTagName("head")[0].appendChild(t)}for(o=Array("flag","emoji"),t.supports={everything:!0,everythingExceptFlag:!0},r=0;r<o.length;r++)t.supports[o[r]]=function(e){if(!p||!p.fillText)return!1;switch(p.textBaseline="top",p.font="600 32px Arial",e){case"flag":return s([127987,65039,8205,9895,65039],[127987,65039,8203,9895,65039])?!1:!s([55356,56826,55356,56819],[55356,56826,8203,55356,56819])&&!s([55356,57332,56128,56423,56128,56418,56128,56421,56128,56430,56128,56423,56128,56447],[55356,57332,8203,56128,56423,8203,56128,56418,8203,56128,56421,8203,56128,56430,8203,56128,56423,8203,56128,56447]);case"emoji":return!s([55357,56424,8205,55356,57212],[55357,56424,8203,55356,57212])}return!1}(o[r]),t.supports.everything=t.supports.everything&&t.supports[o[r]],"flag"!==o[r]&&(t.supports.everythingExceptFlag=t.supports.everythingExceptFlag&&t.supports[o[r]]);t.supports.everythingExceptFlag=t.supports.everythingExceptFlag&&!t.supports.flag,t.DOMReady=!1,t.readyCallback=function(){t.DOMReady=!0},t.supports.everything||(n=function(){t.readyCallback()},a.addEventListener?(a.addEventListener("DOMContentLoaded",n,!1),e.addEventListener("load",n,!1)):(e.attachEvent("onload",n),a.attachEvent("onreadystatechange",function(){"complete"===a.readyState&&t.readyCallback()})),(n=t.source||{}).concatemoji?c(n.concatemoji):n.wpemoji&&n.twemoji&&(c(n.twemoji),c(n.wpemoji)))}(window,document,window._wpemojiSettings);
		</script>
		<style type="text/css">img.wp-smiley,
img.emoji {
	display: inline !important;
	border: none !important;
	box-shadow: none !important;
	height: 1em !important;
	width: 1em !important;
	margin: 0 .07em !important;
	vertical-align: -0.1em !important;
	background: none !important;
	padding: 0 !important;
}</style>
	<link rel="stylesheet" id="pytorch-classic-style-css" href="/wp-content/themes/pytorch/assets/css/index.css?ver=1" media="all">
<link rel="stylesheet" id="pytorch-blog-header-css" href="/wp-content/themes/pytorch/assets/css/blog-header.css?ver=1" media="all">
<link rel="stylesheet" id="pytorch-blog-text-css" href="/wp-content/themes/pytorch/assets/css/blog-text.css?ver=1" media="all">
<link rel="stylesheet" id="pytorch-blog-list-css" href="/wp-content/themes/pytorch/assets/css/blog-list.css?ver=1" media="all">
<link rel="stylesheet" id="pytorch-heading-css" href="/wp-content/themes/pytorch/assets/css/heading.css?ver=1" media="all">
<link rel="stylesheet" id="mediaelement-css" href="/wp-includes/js/mediaelement/mediaelementplayer-legacy.min.css?ver=4.2.16" media="all">
<link rel="stylesheet" id="wp-mediaelement-css" href="/wp-includes/js/mediaelement/wp-mediaelement.min.css?ver=5.7.5" media="all">
<link rel="stylesheet" id="mkaz-code-syntax-prism-css-css" href="/wp-content/plugins/code-syntax-block/assets/prism-ghcolors.css?ver=1641826791" media="all">
<link rel="stylesheet" id="ssp-search-css" href="/wp-content/plugins/simply-static-pro/assets/ssp-search.css?ver=1.1" media="all">
<link rel="https://api.w.org/" href="/wp-json/">
<link rel="alternate" type="application/json" href="/wp-json/wp/v2/posts/1310">
<link rel="EditURI" type="application/rsd+xml" title="RSD" href="/xmlrpc.php?rsd">
<link rel="wlwmanifest" type="application/wlwmanifest+xml" href="/wp-includes/wlwmanifest.xml"> 
<meta name="generator" content="WordPress 5.7.5">
<link rel="canonical" href="/pytorch-0-4-0-migration-guide/">
<link rel="shortlink" href="/?p=1310">
		<meta name="ssp-url" content="">
		<meta name="ssp-config-url" content="/wp-content/plugins/simply-static-pro/configs/">
		<style type="text/css">img#wpstats{display:none}</style>
		</head>

<body class="post-template-default single single-post postid-1310 single-format-standard">
    <a id="skip" href="#main" tabindex="0">Skip to content</a>
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-52DXT37" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
<div>
	<header class="mainHeader">
		<div class="container">
			<div class="logo">
				<a href="/" aria-label="PyTorch Logo" tabindex="0">
					<svg role="img" width="109" height="27" viewbox="0 0 109 27" fill="none" xmlns="http://www.w3.org/2000/svg">
<path d="M14.6172 5.92839L13.1892 7.32839C15.5692 9.66172 15.5692 13.4617 13.1892 15.7951C10.8092 18.1284 6.93316 18.1284 4.55316 15.7951C2.17316 13.4617 2.17316 9.66172 4.55316 7.32839L8.36116 3.59505L8.83716 3.06172V0.261719L3.05716 5.92839C-0.138844 9.06172 -0.138844 14.0617 3.05716 17.1951C6.25316 20.3284 11.3532 20.3284 14.5492 17.1951C17.8132 14.0617 17.8132 8.99505 14.6172 5.92839Z" fill="#DE3412"></path>
<ellipse cx="11.7618" cy="4.4612" rx="1.088" ry="1.06667" fill="#DE3412"></ellipse>
<path fill-rule="evenodd" clip-rule="evenodd" d="M26.5048 13.23H28.9435C33.3467 13.1625 36.1242 11.205 36.1242 7.29C36.1242 3.9825 33.8887 1.6875 29.1467 1.6875H24.6758V19.5075H26.5048V13.23ZM26.4371 3.375H29.079C32.4661 3.375 34.2274 4.7925 34.2274 7.29C34.2274 10.0575 32.3984 11.4075 29.0113 11.475L26.4371 11.5425V3.375Z" fill="#262626"></path>
<path d="M44.3887 19.4405L43.3048 22.2755C42.0855 25.448 40.8661 26.393 39.0371 26.393C38.021 26.393 37.2758 26.123 36.4629 25.7855L37.0048 24.1655C37.6145 24.503 38.2919 24.7055 39.0371 24.7055C40.0532 24.7055 40.7984 24.1655 41.7468 21.668L42.6274 19.373L37.5468 6.48047H39.4435L43.5758 17.2805L47.6403 6.48047H49.4693L44.3887 19.4405Z" fill="#262626"></path>
<path d="M55.5665 3.4425V19.575H53.7375V3.4425H47.4375V1.6875H61.8665V3.375H55.5665V3.4425Z" fill="#262626"></path>
<path fill-rule="evenodd" clip-rule="evenodd" d="M60.6465 13.0277C60.6465 17.2127 63.3562 19.9127 67.0142 19.9127C70.6723 19.9127 73.4497 17.1452 73.4497 12.9602C73.4497 8.7752 70.8078 6.0752 67.1497 6.0752C63.4239 6.0752 60.6465 8.8427 60.6465 13.0277ZM62.4746 12.9613C62.4746 9.92379 64.3036 7.69629 67.0811 7.69629C69.8585 7.69629 71.7553 9.85629 71.7553 13.0288C71.7553 16.0663 69.9262 18.2938 67.1488 18.2938C64.3714 18.2938 62.4746 16.1338 62.4746 12.9613Z" fill="#262626"></path>
<path d="M77.9879 19.5731H76.2266V6.47813L77.9879 6.14062V8.90812C78.8685 7.22062 80.1556 6.14062 81.8491 6.14062C82.7298 6.14062 83.5427 6.41063 84.1524 6.74813L83.6782 8.43563C83.1362 8.09813 82.3911 7.89562 81.6459 7.89562C80.2911 7.89562 79.004 8.90813 77.9201 11.2706V19.5731H77.9879Z" fill="#262626"></path>
<path d="M91.1308 19.9127C87.2018 19.9127 84.6953 17.0777 84.6953 13.0277C84.6953 8.9102 87.405 6.0752 91.1308 6.0752C92.7566 6.0752 94.1114 6.4802 95.2631 7.2227L94.7889 8.8427C93.7727 8.1677 92.5534 7.7627 91.1308 7.7627C88.2856 7.7627 86.5243 9.8552 86.5243 12.9602C86.5243 16.1327 88.4211 18.2252 91.1985 18.2252C92.4856 18.2252 93.8405 17.8202 94.8566 17.1452L95.1953 18.7652C94.0437 19.5077 92.6211 19.9127 91.1308 19.9127Z" fill="#262626"></path>
<path d="M106.238 19.575V11.1375C106.238 8.8425 105.29 7.83 103.461 7.83C101.97 7.83 100.48 8.5725 99.3961 9.72V19.6425H97.6348V0.3375L99.3961 0C99.3961 0 99.3961 8.1675 99.3961 8.235C100.751 6.885 102.512 6.1425 103.935 6.1425C106.509 6.1425 108.067 7.7625 108.067 10.5975V19.575H106.238Z" fill="#262626"></path>
</svg>
				</a>
			</div>
			<div class="content-container">
				<ul class="mainNav">
					<li class="mainItem search" key="search">
						<button id="search-icon" aria-label="search">
							<svg role="img" width="17" height="16" viewbox="0 0 17 16" fill="none" xmlns="http://www.w3.org/2000/svg">
<path fill-rule="evenodd" clip-rule="evenodd" d="M11.7461 7C11.7461 9.48528 9.73137 11.5 7.24609 11.5C4.76081 11.5 2.74609 9.48528 2.74609 7C2.74609 4.51472 4.76081 2.5 7.24609 2.5C9.73137 2.5 11.7461 4.51472 11.7461 7ZM10.9253 11.7399C9.90931 12.5297 8.63263 13 7.24609 13C3.93239 13 1.24609 10.3137 1.24609 7C1.24609 3.68629 3.93239 1 7.24609 1C10.5598 1 13.2461 3.68629 13.2461 7C13.2461 8.38653 12.7758 9.66322 11.986 10.6792L15.2764 13.9697L14.2158 15.0303L10.9253 11.7399Z" fill="#262626"></path>
</svg>
						</button>
						<div class="search-border">
							<div id="inner-search-icon">
								<svg role="img" width="17" height="16" viewbox="0 0 17 16" fill="none" xmlns="http://www.w3.org/2000/svg">
<path fill-rule="evenodd" clip-rule="evenodd" d="M11.7461 7C11.7461 9.48528 9.73137 11.5 7.24609 11.5C4.76081 11.5 2.74609 9.48528 2.74609 7C2.74609 4.51472 4.76081 2.5 7.24609 2.5C9.73137 2.5 11.7461 4.51472 11.7461 7ZM10.9253 11.7399C9.90931 12.5297 8.63263 13 7.24609 13C3.93239 13 1.24609 10.3137 1.24609 7C1.24609 3.68629 3.93239 1 7.24609 1C10.5598 1 13.2461 3.68629 13.2461 7C13.2461 8.38653 12.7758 9.66322 11.986 10.6792L15.2764 13.9697L14.2158 15.0303L10.9253 11.7399Z" fill="#262626"></path>
</svg>
							</div>
								<input id="input" type="text" placeholder="Search" title="Search" autocomplete="off" role="combobox" aria-autocomplete="list" aria-expanded="false" aria-label="search input">
							
							<div id="close-search">X</div>
						</div>
					</li>
					<li class="mainItem menuIcon">
						<span class="hamburger"><svg role="img" width="22" height="18" viewbox="0 0 22 18" fill="none" xmlns="http://www.w3.org/2000/svg">
<path fill-rule="evenodd" clip-rule="evenodd" d="M21.5 2.125H0.5V0.625H21.5V2.125ZM21.5 17.625H0.5V16.125H21.5V17.625ZM0.5 9.75H21.5V8.25H0.5V9.75Z" fill="black"></path>
</svg>
</span>
						<span class="close"><svg role="img" width="22" height="22" viewbox="0 0 22 22" fill="none" xmlns="http://www.w3.org/2000/svg">
<path fill-rule="evenodd" clip-rule="evenodd" d="M11.0001 12.0607L20.2197 21.2803L21.2804 20.2197L12.0607 11L21.2804 1.78033L20.2197 0.719675L11.0001 9.93934L1.78039 0.719673L0.719727 1.78033L9.9394 11L0.719727 20.2197L1.78039 21.2803L11.0001 12.0607Z" fill="black"></path>
</svg>
</span>
					</li>
					<li class="navItems">
						<ul class="navItemsContainer">
																														<li class="mainItem home-menu">
									<a class="parentTitle" href="/" target="">
										<span>
											Home										</span>
									</a>
																	</li>
																							<li class="mainItem install-menu">
									<a class="parentTitle" href="/install/install-overview/" target="">
										<span>
											Install										</span>
									</a>
																			<div class="subitems-container">
											<div class="subitems-wrapper">
												<ul class="subItems">
																											<li class="subItem ">
															<a class="link" href="/install/install-overview/" target="">
																<p class="title">Overview</p>
																														</a>
														</li>
																											<li class="subItem ">
															<a class="link" href="/install/install-locally/" target="">
																<p class="title">Install Locally</p>
																														</a>
														</li>
																											<li class="subItem ">
															<a class="link" href="/install/install-mobile/" target="">
																<p class="title">Install Mobile</p>
																														</a>
														</li>
																											<li class="subItem ">
															<a class="link" href="/install/start-with-cloud-partners/" target="">
																<p class="title">Start with Cloud Partners</p>
																														</a>
														</li>
																											<li class="subItem ">
															<a class="link" href="/install/previous-versions/" target="">
																<p class="title">Previous PyTorch Versions</p>
																														</a>
														</li>
																									</ul>
											</div>
										</div>
																	</li>
																							<li class="mainItem features-menu">
									<a class="parentTitle" href="/features/" target="">
										<span>
											Features										</span>
									</a>
																	</li>
																							<li class="mainItem resources-menu">
									<a class="parentTitle" href="/resources/overview/" target="">
										<span>
											Resources										</span>
									</a>
																			<div class="subitems-container">
											<div class="subitems-wrapper">
												<ul class="subItems">
																											<li class="subItem ">
															<a class="link" href="/resources/overview/" target="">
																<p class="title">Overview</p>
																														</a>
														</li>
																											<li class="subItem ">
															<a class="link" href="/resources/blog/" target="">
																<p class="title">Blog</p>
																														</a>
														</li>
																											<li class="subItem ">
															<a class="link" href="/resources/education/" target="">
																<p class="title">Education</p>
																														</a>
														</li>
																											<li class="subItem ">
															<a class="link" href="/resources/localized-docs-tutorials/" target="">
																<p class="title">Localized Docs &#038; Tutorials</p>
																														</a>
														</li>
																											<li class="subItem ">
															<a class="link" href="/resources/enterprise-program/" target="">
																<p class="title">Enterprise Program</p>
																														</a>
														</li>
																									</ul>
											</div>
										</div>
																	</li>
																							<li class="mainItem docs-menu">
									<a class="parentTitle" href="https://pytorch.org/docs/stable/index.html" target="_blank">
										<span>
											Docs										</span>
									</a>
																	</li>
																							<li class="mainItem tutorials-menu">
									<a class="parentTitle" href="https://pytorch.org/tutorials/" target="_blank">
										<span>
											Tutorials										</span>
									</a>
																	</li>
																							<li class="mainItem community-menu">
									<a class="parentTitle" href="/community/overview/" target="">
										<span>
											Community										</span>
									</a>
																			<div class="subitems-container">
											<div class="subitems-wrapper">
												<ul class="subItems">
																											<li class="subItem ">
															<a class="link" href="/community/overview/" target="">
																<p class="title">Overview</p>
																														</a>
														</li>
																											<li class="subItem ">
															<a class="link" href="/community/case-studies/" target="">
																<p class="title">Case Studies</p>
																														</a>
														</li>
																											<li class="subItem ">
															<a class="link" href="/community/ecosystem-tools/" target="">
																<p class="title">Ecosystem Tools</p>
																														</a>
														</li>
																											<li class="subItem ">
															<a class="link" href="/community/events/" target="">
																<p class="title">Events</p>
																														</a>
														</li>
																									</ul>
											</div>
										</div>
																	</li>
														<li class="github mainItem">
								<div class="github-wrapper">
									<a href="https://github.com/pytorch/pytorch" target="_blank" class="parentTitle" aria-label="See Pytorch on GitHub">
										<svg role="img" width="25" height="24" viewbox="0 0 25 24" fill="none" xmlns="http://www.w3.org/2000/svg">
<path d="M23.0227 6.33146C21.9311 4.51257 20.4504 3.07256 18.5803 2.01109C16.7099 0.949571 14.6679 0.418945 12.453 0.418945C10.2384 0.418945 8.19578 0.949733 6.32575 2.01109C4.45545 3.07251 2.97484 4.51257 1.88325 6.33146C0.791831 8.15029 0.246094 10.1365 0.246094 12.2899C0.246094 14.8767 1.02214 17.2029 2.57462 19.2689C4.12694 21.3351 6.1323 22.7648 8.59054 23.5582C8.87669 23.6099 9.08851 23.5736 9.22624 23.4502C9.36403 23.3266 9.43284 23.1719 9.43284 22.9866C9.43284 22.9557 9.43011 22.6776 9.42482 22.152C9.41936 21.6263 9.4168 21.1677 9.4168 20.7765L9.05121 20.838C8.81812 20.8795 8.52407 20.8971 8.16906 20.8921C7.81422 20.8873 7.44584 20.8511 7.06445 20.7839C6.68288 20.7172 6.32798 20.5627 5.99947 20.3205C5.67113 20.0783 5.43803 19.7614 5.30025 19.37L5.14131 19.0143C5.03537 18.7775 4.86858 18.5145 4.64072 18.2261C4.41286 17.9375 4.18244 17.7418 3.94935 17.6388L3.83806 17.5613C3.76391 17.5098 3.6951 17.4477 3.63147 17.3757C3.5679 17.3036 3.5203 17.2315 3.48851 17.1593C3.45667 17.087 3.48305 17.0277 3.56795 16.9812C3.65285 16.9347 3.80628 16.9121 4.0289 16.9121L4.34667 16.9583C4.55861 16.9996 4.82076 17.123 5.13346 17.3292C5.44599 17.5353 5.70291 17.8032 5.90427 18.1328C6.14811 18.5554 6.44188 18.8774 6.78643 19.099C7.13069 19.3206 7.4778 19.4312 7.82741 19.4312C8.17702 19.4312 8.47898 19.4054 8.73339 19.3542C8.98753 19.3026 9.22596 19.2252 9.44859 19.1222C9.54395 18.4315 9.8036 17.9008 10.2273 17.5299C9.62339 17.4682 9.08044 17.3752 8.59817 17.2516C8.11617 17.1279 7.61809 16.927 7.10425 16.6485C6.59013 16.3704 6.16364 16.025 5.82466 15.613C5.48563 15.2008 5.20739 14.6596 4.99033 13.99C4.77316 13.3201 4.66455 12.5473 4.66455 11.6714C4.66455 10.4243 5.08319 9.36302 5.92031 8.48704C5.52816 7.54944 5.56518 6.49837 6.03148 5.33393C6.33878 5.24108 6.7945 5.31076 7.39841 5.54253C8.00244 5.77441 8.44468 5.97305 8.7256 6.13775C9.00651 6.30238 9.23159 6.4419 9.40116 6.55506C10.3868 6.28723 11.404 6.15328 12.4529 6.15328C13.5018 6.15328 14.5192 6.28723 15.5049 6.55506L16.1089 6.18425C16.5219 5.93683 17.0096 5.71009 17.5709 5.50398C18.1325 5.29798 18.562 5.24124 18.8588 5.33409C19.3354 6.49859 19.3779 7.54961 18.9857 8.4872C19.8227 9.36319 20.2415 10.4247 20.2415 11.6715C20.2415 12.5474 20.1325 13.3227 19.9157 13.9977C19.6986 14.6729 19.4179 15.2135 19.0737 15.6208C18.729 16.028 18.2998 16.3706 17.786 16.6487C17.272 16.927 16.7738 17.1278 16.2918 17.2516C15.8096 17.3754 15.2666 17.4684 14.6627 17.5302C15.2135 17.9937 15.4889 18.7254 15.4889 19.725V22.9862C15.4889 23.1715 15.5552 23.3261 15.6878 23.4497C15.8202 23.5731 16.0294 23.6095 16.3155 23.5578C18.7741 22.7644 20.7795 21.3347 22.3317 19.2685C23.8838 17.2024 24.6602 14.8763 24.6602 12.2895C24.6596 10.1363 24.1136 8.15029 23.0227 6.33146Z" fill="#262626"></path>
</svg>
									</a>
								</div>
							</li>
						</ul>
						
<div class="navItems-followContainer followMenu ">
			<div class="mainItem">Follow Us</div>
		<ul class="follow-list">
					<li class="followItem">
				<a aria-label="follow Menu  icon-twitter" href="https://twitter.com/pytorch" target="_blank" class=" icon-twitter">
					Twitter				</a>
			</li>
					<li class="followItem">
				<a aria-label="follow Menu  icon-facebook" href="https://www.facebook.com/pytorch" target="_blank" class=" icon-facebook">
					Facebook				</a>
			</li>
					<li class="followItem">
				<a aria-label="follow Menu  icon-youtube" href="https://www.youtube.com/pytorch" target="_blank" class=" icon-youtube">
					YouTube				</a>
			</li>
					<li class="followItem">
				<a aria-label="follow Menu  icon-linkedin" href="https://www.linkedin.com/company/pytorch" target="_blank" class=" icon-linkedin">
					Linkedin				</a>
			</li>
					<li class="followItem">
				<a aria-label="follow Menu  icon-medium" href="https://medium.com/pytorch" target="_blank" class=" icon-medium">
					Medium				</a>
			</li>
					<li class="followItem">
				<a aria-label="follow Menu  icon-github" href="https://github.com/pytorch/pytorch" target="_blank" class=" icon-github">
					GitHub				</a>
			</li>
			</ul>
</div>
					</li>
				</ul>
			</div>
		</div>
	</header>

	<main id="main" class="site-main" role="main">


<div class="Breadcrumbs">
	<div class="container breadcrumbs-lined">
		<ul class="list-container">
						<li class="breadcrumb-item breadcrumb-active">
				<a class="active-item" href="/blog">Blog</a>
			</li>
						<li class="breadcrumb-item">
				PyTorch 0.4.0 Migration Guide			</li>
		</ul>
	</div>
</div>

<div class="BlogHeader ">
	<div class="container">
		<h2 class="title">PyTorch 0.4.0 Migration Guide</h2>

		<div class="banner">
			
<img class="Image " src="/wp-content/uploads/2021/08/PyTorch_Blogs@3x-100-1.png" alt="">
		</div>

		<div class="foot">
			<div class="byline">
								<span class="date">April 22, 2018</span>
				<span class="author">by The PyTorch Team</span>
			</div>

			
<div class="Share ">
  
  <div class="share-icons">
    
      </div>
</div>
		</div>


	</div>
</div>




<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">Welcome to the migration guide for PyTorch 0.4.0. In this release we introduced <a href="https://github.com/pytorch/pytorch/releases/tag/v0.4.0" target="_blank">many exciting new features and critical bug fixes</a>, with the goal of providing users a better and cleaner interface. In this guide, we will cover the most important changes in migrating existing code from previous versions:</p>
	</div>
</div>


<div class="blog-list-container blog-list-container">
	<div class="container">
		<ul class="list unordered-list indent-con ">
												<li class="item">
<code>Tensors</code> and <code>Variables</code> have merged								</li>
												<li class="item">Support for 0-dimensional (scalar) <code>Tensors</code>								</li>
												<li class="item">Deprecation of the <code>volatile</code> flag								</li>
												<li class="item">
<code>dtypes</code>, <code>devices</code>, and Numpy-style <code>Tensor</code> creation functions								</li>
												<li class="item">Writing device-agnostic code								</li>
												<li class="item">New edge-case constraints on names of submodules, parameters, and buffers in <code>nn.Module</code>								</li>
					</ul>
	</div>
</div>


<div class="">
<h2 class="HeadingBlock Heading is-style-secondary-heading HeadingBlock  " id="block-adb57910-90f3-4ea8-8ee3-93961361fb43">
		
	MERGING <a href="https://pytorch.org/docs/0.4.0/tensors.html"><code>TENSOR</code></a> AND <code>VARIABLE</code> AND CLASSES</h2>
	</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text"><a href="https://pytorch.org/docs/0.4.0/tensors.html"><code>torch.Tensor</code></a> and <code>torch.autograd.Variable</code> are now the same class. More precisely, <a href="https://pytorch.org/docs/0.4.0/tensors.html"><code>torch.Tensor</code></a> is capable of tracking history and behaves like the old <code>Variable</code>; <code>Variable</code> wrapping continues to work as before but returns an object of type <a href="https://pytorch.org/docs/0.4.0/tensors.html"><code>torch.Tensor</code></a>. This means that you don’t need the <code>Variable</code> wrapper everywhere in your code anymore.</p>
	</div>
</div>

<div class="">
<h3 class="HeadingBlock Heading is-style-section-heading HeadingBlock  " id="block-21ce855e-ad51-4d49-a697-d33a2f1bc22b">
		
	The <code>type()</code> of a <a href="https://pytorch.org/docs/0.4.0/tensors.html"><code>Tensor</code></a> has changed</h3>
	</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">Note also that the <code>type()</code> of a Tensor no longer reflects the data type. Use <code>isinstance()</code> or <code>x.type()</code>instead:</p>
	</div>
</div>

<div class="code-block">
<pre class="wp-block-code"><code lang="bash" class="language-bash">&gt;&gt;&gt; x = torch.DoubleTensor([1, 1, 1])
&gt;&gt;&gt; print(type(x))  # was torch.DoubleTensor
"&lt;class 'torch.Tensor'&gt;"
&gt;&gt;&gt; print(x.type())  # OK: 'torch.DoubleTensor'
'torch.DoubleTensor'
&gt;&gt;&gt; print(isinstance(x, torch.DoubleTensor))  # OK: True
True</code></pre>
</div>

<div class="">
<h3 class="HeadingBlock Heading is-style-section-heading HeadingBlock  " id="block-029857d0-1fde-4c62-9112-d8db8c89c0cf">
		
	When does <a href="https://pytorch.org/docs/0.4.0/autograd.html"><code>autograd</code></a> start tracking history now?</h3>
	</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text"><code>requires_grad</code>, the central flag for <a href="https://pytorch.org/docs/0.4.0/autograd.html"><code>autograd</code></a>, is now an attribute on <code>Tensors</code>. The same rules previously used for <code>Variables</code> applies to <code>Tensors</code>; <a href="https://pytorch.org/docs/0.4.0/autograd.html"><code>autograd</code></a> starts tracking history when any input <code>Tensor</code> of an operation has <code>requires_grad=True</code>. For example,</p>
	</div>
</div>

<div class="code-block">
<pre class="wp-block-code"><code lang="bash" class="language-bash">&gt;&gt;&gt; x = torch.ones(1)  # create a tensor with requires_grad=False (default)
&gt;&gt;&gt; x.requires_grad
False
&gt;&gt;&gt; y = torch.ones(1)  # another tensor with requires_grad=False
&gt;&gt;&gt; z = x + y
&gt;&gt;&gt; # both inputs have requires_grad=False. so does the output
&gt;&gt;&gt; z.requires_grad
False
&gt;&gt;&gt; # then autograd won't track this computation. let's verify!
&gt;&gt;&gt; z.backward()
RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn
&gt;&gt;&gt;
&gt;&gt;&gt; # now create a tensor with requires_grad=True
&gt;&gt;&gt; w = torch.ones(1, requires_grad=True)
&gt;&gt;&gt; w.requires_grad
True
&gt;&gt;&gt; # add to the previous result that has require_grad=False
&gt;&gt;&gt; total = w + z
&gt;&gt;&gt; # the total sum now requires grad!
&gt;&gt;&gt; total.requires_grad
True
&gt;&gt;&gt; # autograd can compute the gradients as well
&gt;&gt;&gt; total.backward()
&gt;&gt;&gt; w.grad
tensor([ 1.])
&gt;&gt;&gt; # and no computation is wasted to compute gradients for x, y and z, which don't require grad
&gt;&gt;&gt; z.grad == x.grad == y.grad == None
True</code></pre>
</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">Manipulating <code>requires_grad</code> flag<br><br>Other than directly setting the attribute, you can change this flag <code>in-place</code> using <a href="https://pytorch.org/docs/0.4.0/tensors.html#torch.Tensor.requires_grad_"><code>my_tensor.requires_grad_()</code></a>, or, as in the above example, at creation time by passing it in as an argument (default is <code>False</code>), e.g.,</p>
	</div>
</div>

<div class="code-block">
<pre class="wp-block-code"><code lang="bash" class="language-bash">&gt;&gt;&gt; existing_tensor.requires_grad_()
&gt;&gt;&gt; existing_tensor.requires_grad
True
&gt;&gt;&gt; my_tensor = torch.zeros(3, 4, requires_grad=True)
&gt;&gt;&gt; my_tensor.requires_grad
True</code></pre>
</div>

<div class="">
<h3 class="HeadingBlock Heading is-style-section-heading HeadingBlock  " id="block-c9f639f0-226d-4203-ad8d-3a2d0487c787">
		
	What about <code>.data?</code>
</h3>
	</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text"><code>.data</code> was the primary way to get the underlying <code>Tensor</code> from a <code>Variable</code>. After this merge, calling <code>y = x.data</code> still has similar semantics. So <code>y</code> will be a <code>Tensor</code> that shares the same data with <code>x</code>, is unrelated with the computation history of <code>x</code>, and has <code>requires_grad=False</code>.<br><br>However, <code>.data</code> can be unsafe in some cases. Any changes on <code>x.data</code> wouldn’t be tracked by <code>autograd</code>, and the computed gradients would be incorrect if <code>x</code> is needed in a backward pass. A safer alternative is to use <a href="https://pytorch.org/docs/master/autograd.html#torch.Tensor.detach"><code>x.detach()</code></a>, which also returns a <code>Tensor</code> that shares data with <code>requires_grad=False</code>, but will have its in-place changes reported by <code>autograd</code> if <code>x</code> is needed in backward.<br><br>Here is an example of the difference between <code>.data</code> and <code>x.detach()</code> (and why we recommend using <code>detach</code> in general).<br><br>If you use <code>Tensor.detach()</code>, the gradient computation is guaranteed to be correct.</p>
	</div>
</div>

<div class="code-block">
<pre class="wp-block-code"><code lang="bash" class="language-bash">&gt;&gt;&gt; a = torch.tensor([1,2,3.], requires_grad = True)
&gt;&gt;&gt; out = a.sigmoid()
&gt;&gt;&gt; c = out.detach()
&gt;&gt;&gt; c.zero_()
tensor([ 0.,  0.,  0.])

&gt;&gt;&gt; out  # modified by c.zero_() !!
tensor([ 0.,  0.,  0.])

&gt;&gt;&gt; out.sum().backward()  # Requires the original value of out, but that was overwritten by c.zero_()
RuntimeError: one of the variables needed for gradient computation has been modified by an</code></pre>
</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">However, using <code>Tensor.data</code> can be unsafe and can easily result in incorrect gradients when a tensor is required for gradient computation but modified in-place.</p>
	</div>
</div>

<div class="code-block">
<pre class="wp-block-code"><code lang="bash" class="language-bash">&gt;&gt;&gt; a = torch.tensor([1,2,3.], requires_grad = True)
&gt;&gt;&gt; out = a.sigmoid()
&gt;&gt;&gt; c = out.data
&gt;&gt;&gt; c.zero_()
tensor([ 0.,  0.,  0.])

&gt;&gt;&gt; out  # out  was modified by c.zero_()
tensor([ 0.,  0.,  0.])

&gt;&gt;&gt; out.sum().backward()
&gt;&gt;&gt; a.grad  # The result is very, very wrong because `out` changed!
tensor([ 0.,  0.,  0.])</code></pre>
</div>

<div class="">
<h2 class="HeadingBlock Heading is-style-secondary-heading HeadingBlock  " id="block-c6d0e6c4-f586-4513-82ed-6ae09953803c">
		
	SUPPORT FOR 0-DIMENSIONAL (SCALAR) TENSORS</h2>
	</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">Previously, indexing into a <code>Tensor</code> vector (1-dimensional tensor) gave a Python number but indexing into a <code>Variable</code> vector gave (inconsistently!) a vector of size <code>(1,)</code>! Similar behavior existed with reduction functions, e.g. <code>tensor.sum()</code> would return a Python number, but <code>variable.sum()</code> would return a vector of size <code>(1,)</code>.<br><br>Fortunately, this release introduces proper scalar (0-dimensional tensor) support in PyTorch! Scalars can be created using the new <code>torch.tensor</code> function (which will be explained in more detail later; for now just think of it as the PyTorch equivalent of <code>numpy.array</code>). Now you can do things like:</p>
	</div>
</div>

<div class="code-block">
<pre class="wp-block-code"><code lang="bash" class="language-bash">&gt;&gt;&gt; torch.tensor(3.1416)         # create a scalar directly
tensor(3.1416)
&gt;&gt;&gt; torch.tensor(3.1416).size()  # scalar is 0-dimensional
torch.Size([])
&gt;&gt;&gt; torch.tensor([3]).size()     # compare to a vector of size 1
torch.Size([1])
&gt;&gt;&gt;
&gt;&gt;&gt; vector = torch.arange(2, 6)  # this is a vector
&gt;&gt;&gt; vector
tensor([ 2.,  3.,  4.,  5.])
&gt;&gt;&gt; vector.size()
torch.Size([4])
&gt;&gt;&gt; vector[3]                    # indexing into a vector gives a scalar
tensor(5.)
&gt;&gt;&gt; vector[3].item()             # .item() gives the value as a Python number
5.0
&gt;&gt;&gt; mysum = torch.tensor([2, 3]).sum()
&gt;&gt;&gt; mysum
tensor(5)
&gt;&gt;&gt; mysum.size()
torch.Size([])</code></pre>
</div>

<div class="">
<h3 class="HeadingBlock Heading is-style-section-heading HeadingBlock  " id="block-63ade19c-456c-47e0-9daf-1062f90bd853">
		
	Accumulating losses</h3>
	</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">Consider the widely used pattern <code>total_loss += loss.data[0]</code>. Before 0.4.0. <code>loss</code> was a <code>Variable</code> wrapping a tensor of size <code>(1,)</code>, but in 0.4.0 <code>loss</code> is now a scalar and has <code>0</code> dimensions. Indexing into a scalar doesn’t make sense (it gives a warning now, but will be a hard error in 0.5.0). Use <code>loss.item()</code> to get the Python number from a scalar.<br><br>Note that if you don’t convert to a Python number when accumulating losses, you may find increased memory usage in your program. This is because the right-hand-side of the above expression used to be a Python float, while it is now a zero-dim Tensor. The total loss is thus accumulating Tensors and their gradient history, which may keep around large autograd graphs for much longer than necessary.</p>
	</div>
</div>

<div class="">
<h2 class="HeadingBlock Heading is-style-secondary-heading HeadingBlock  " id="block-c50cd19e-21b6-4587-8985-6c0d3b17c55a">
		
	DEPRECATION OF VOLATILE FLAG</h2>
	</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">The <code>volatile</code> flag is now deprecated and has no effect. Previously, any computation that involves a <code>Variable</code> with <code>volatile=True</code> wouldn’t be tracked by <code>autograd</code>. This has now been replaced by a <a href="https://pytorch.org/docs/0.4.0/torch.html#locally-disabling-gradient-computation">set of more flexible context managers</a> including <code>torch.no_grad()</code>, <code>torch.set_grad_enabled(grad_mode)</code>, and others.</p>
	</div>
</div>

<div class="code-block">
<pre class="wp-block-code"><code lang="bash" class="language-bash">&gt;&gt;&gt; x = torch.zeros(1, requires_grad=True)
&gt;&gt;&gt; with torch.no_grad():
...     y = x * 2
&gt;&gt;&gt; y.requires_grad
False
&gt;&gt;&gt;
&gt;&gt;&gt; is_train = False
&gt;&gt;&gt; with torch.set_grad_enabled(is_train):
...     y = x * 2
&gt;&gt;&gt; y.requires_grad
False
&gt;&gt;&gt; torch.set_grad_enabled(True)  # this can also be used as a function
&gt;&gt;&gt; y = x * 2
&gt;&gt;&gt; y.requires_grad
True
&gt;&gt;&gt; torch.set_grad_enabled(False)
&gt;&gt;&gt; y = x * 2
&gt;&gt;&gt; y.requires_grad
False</code></pre>
</div>

<div class="">
<h2 class="HeadingBlock Heading is-style-secondary-heading HeadingBlock  " id="block-02198d68-dad9-4747-8993-6660aa24e9ec">
		
	<a href="https://pytorch.org/docs/0.4.0/tensor_attributes.html#torch.torch.dtype"><code>DTYPES</code></a>, <a href="https://pytorch.org/docs/0.4.0/tensor_attributes.html#torch.torch.device"><code>DEVICES</code></a> AND NUMPY-STYLE CREATION FUNCTIONS</h2>
	</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">In previous versions of PyTorch, we used to specify data type (e.g. float vs double), device type (cpu vs cuda) and layout (dense vs sparse) together as a “tensor type”. For example, <code>torch.cuda.sparse.DoubleTensor</code> was the <code>Tensor</code> type representing the <code>double</code> data type, living on CUDA devices, and with <a href="https://en.wikipedia.org/wiki/Sparse_matrix#Coordinate_list_(COO)" target="_blank">COO sparse tensor</a> layout.<br><br>In this release, we introduce <a href="https://pytorch.org/docs/0.4.0/tensor_attributes.html#torch.torch.dtype"><code>torch.dtype</code></a>, <a href="https://pytorch.org/docs/0.4.0/tensor_attributes.html#torch.torch.device"><code>torch.device</code></a> and <a href="https://pytorch.org/docs/0.4.0/tensor_attributes.html#torch.torch.layout"><code>torch.layout</code></a> classes to allow better management of these properties via NumPy-style creation functions.</p>
	</div>
</div>

<div class="">
<h3 class="HeadingBlock Heading is-style-section-heading HeadingBlock  " id="block-64adfae6-0a21-4af1-81fd-b632f9fa49d1">
		
	<a href="https://pytorch.org/docs/0.4.0/tensor_attributes.html#torch.torch.dtype"><code>torch.dtype</code></a>
</h3>
	</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">Below is a complete list of available <a href="https://pytorch.org/docs/0.4.0/tensor_attributes.html#torch.torch.dtype"><code>torch.dtype</code></a>s (data types) and their corresponding tensor types.</p>
	</div>
</div>


<figure class="wp-block-table"><table class="has-fixed-layout">
<thead><tr>
<th>Data</th>
<th>type torch.dtype</th>
<th>Tensor types</th>
</tr></thead>
<tbody>
<tr>
<td>32-bit floating point</td>
<td>
<code>torch.float32</code>&nbsp;or&nbsp;<code>torch.float</code>
</td>
<td>torch.*.FloatTensor</td>
</tr>
<tr>
<td>64-bit floating point</td>
<td>
<code>torch.float64</code>&nbsp;or&nbsp;<code>torch.double</code>
</td>
<td><code>torch.*.DoubleTensor</code></td>
</tr>
<tr>
<td>16-bit floating point</td>
<td>
<code>torch.float16</code>&nbsp;or&nbsp;<code>torch.half</code>
</td>
<td>torch.*.HalfTensor</td>
</tr>
<tr>
<td>8-bit integer (unsigned)</td>
<td><code>torch.uint8</code></td>
<td>torch.*.ByteTensor</td>
</tr>
<tr>
<td>8-bit integer (signed)</td>
<td><code>torch.int8</code></td>
<td>torch.*.CharTensor</td>
</tr>
<tr>
<td>16-bit integer (signed)</td>
<td>
<code>torch.int16</code>&nbsp;or&nbsp;<code>torch.short</code>
</td>
<td>torch.*.ShortTensor</td>
</tr>
<tr>
<td>32-bit integer (signed)</td>
<td>
<code>torch.int32</code>&nbsp;or&nbsp;<code>torch.int</code>
</td>
<td>torch.*.IntTensor</td>
</tr>
<tr>
<td>64-bit integer (signed)</td>
<td>
<code>torch.int64</code>&nbsp;or&nbsp;<code>torch.long</code>
</td>
<td>torch.*.LongTensor</td>
</tr>
</tbody>
</table></figure>




<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">The dtype of a tensor can be access via its <code>dtype</code> attribute.</p>
	</div>
</div>

<div class="">
<h3 class="HeadingBlock Heading is-style-section-heading HeadingBlock  " id="block-346c69a3-f2e8-4684-b385-445326d4ef99">
		
	<a href="https://pytorch.org/docs/0.4.0/tensor_attributes.html#torch.torch.device"><code>torch.device</code></a>
</h3>
	</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">A <a href="https://pytorch.org/docs/0.4.0/tensor_attributes.html#torch.torch.device"><code>torch.device</code></a> contains a device type (<code>'cpu'</code> or <code>'cuda'</code>) and optional device ordinal (id) for the device type. It can be initialized with <code>torch.device('{device_type}')</code> or <code>torch.device('{device_type}:{device_ordinal}')</code>.<br><br>If the device ordinal is not present, this represents the current device for the device type; e.g., <code>torch.device('cuda')</code> is equivalent to <code>torch.device('cuda:X')</code> where <code>X</code> is the result of <code>torch.cuda.current_device()</code>.<br><br>The device of a tensor can be accessed via its <code>device</code> attribute.</p>
	</div>
</div>

<div class="">
<h3 class="HeadingBlock Heading is-style-section-heading HeadingBlock  " id="block-e56ca5e1-f645-4ef3-92c4-6773aa897914">
		
	<a href="https://pytorch.org/docs/0.4.0/tensor_attributes.html#torch.torch.layout"><code>torch.layout</code></a>
</h3>
	</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text"><a href="https://pytorch.org/docs/0.4.0/tensor_attributes.html#torch.torch.layout"><code>torch.layout</code></a> represents the data layout of a <a href="https://pytorch.org/docs/0.4.0/tensors.html"><code>Tensor</code></a>. Currently <code>torch.strided</code> (dense tensors, the default) and <code>torch.sparse_coo</code> (sparse tensors with COO format) are supported.<br><br>The layout of a tensor can be access via its <code>layout</code> attribute.</p>
	</div>
</div>

<div class="">
<h3 class="HeadingBlock Heading is-style-section-heading HeadingBlock  " id="block-0c1864cb-eee3-4e81-bc11-5593b97113dd">
		
	Creating Tensors</h3>
	</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text"><a href="https://pytorch.org/docs/0.4.0/torch.html#creation-ops">Methods that create a</a> <a href="https://pytorch.org/docs/0.4.0/tensors.html"><code>Tensor</code></a> now also take in <code>dtype</code>, <code>device</code>, <code>layout</code>, and <code>requires_grad</code> options to specify the desired attributes on the returned <code>Tensor</code>. For example,</p>
	</div>
</div>

<div class="code-block">
<pre class="wp-block-code"><code lang="bash" class="language-bash">&gt;&gt;&gt; device = torch.device("cuda:1")
&gt;&gt;&gt; x = torch.randn(3, 3, dtype=torch.float64, device=device)
tensor([[-0.6344,  0.8562, -1.2758],
        [ 0.8414,  1.7962,  1.0589],
        [-0.1369, -1.0462, -0.4373]], dtype=torch.float64, device='cuda:1')
&gt;&gt;&gt; x.requires_grad  # default is False
False
&gt;&gt;&gt; x = torch.zeros(3, requires_grad=True)
&gt;&gt;&gt; x.requires_grad
True</code></pre>
</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text"><a href="https://pytorch.org/docs/0.4.0/torch.html#torch.tensor"><code>torch.tensor(data, ...)</code></a><br><br><a href="https://pytorch.org/docs/0.4.0/torch.html#torch.tensor"><code>torch.tensor</code></a> is one of the newly added <a href="https://pytorch.org/docs/0.4.0/torch.html#creation-ops">tensor creation methods</a>. It takes in array-like data of all kinds and copies the contained values into a new <code>Tensor</code>. As mentioned earlier, <a href="https://pytorch.org/docs/0.4.0/torch.html#torch.tensor"><code>torch.tensor</code></a> is the PyTorch equivalent of NumPy’s <code>numpy.array</code>constructor. Unlike the <code>torch.*Tensor</code> methods, you can also create zero-dimensional <code>Tensor</code>s (aka scalars) this way (a single python number is treated as a Size in the <code>torch.*Tensor methods</code>). Moreover, if a <code>dtype</code> argument isn’t given, it will infer the suitable <code>dtype</code> given the data. It is the recommended way to create a tensor from existing data like a Python list. For example,</p>
	</div>
</div>

<div class="code-block">
<pre class="wp-block-code"><code lang="bash" class="language-bash">&gt;&gt;&gt; cuda = torch.device("cuda")
&gt;&gt;&gt; torch.tensor([[1], [2], [3]], dtype=torch.half, device=cuda)
tensor([[ 1],
        [ 2],
        [ 3]], device='cuda:0')
&gt;&gt;&gt; torch.tensor(1)               # scalar
tensor(1)
&gt;&gt;&gt; torch.tensor([1, 2.3]).dtype  # type inferece
torch.float32
&gt;&gt;&gt; torch.tensor([1, 2]).dtype    # type inferece
torch.int64</code></pre>
</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">We’ve also added more tensor creation methods. Some of them have <code>torch.*_like</code> and/or <code>tensor.new_*</code> variants.</p>
	</div>
</div>


<div class="blog-list-container blog-list-container">
	<div class="container">
		<ul class="list unordered-list indent-con ">
												<li class="item">
<code>torch.*_like</code> takes in an input <code>Tensor</code> instead of a shape. It returns a <code>Tensor</code> with same attributes as the input <code>Tensor</code> by default unless otherwise specified:								</li>
					</ul>
	</div>
</div>


<div class="code-block">
<pre class="wp-block-code"><code lang="bash" class="language-bash"> &gt;&gt;&gt; x = torch.randn(3, dtype=torch.float64)
 &gt;&gt;&gt; torch.zeros_like(x)
 tensor([ 0.,  0.,  0.], dtype=torch.float64)
 &gt;&gt;&gt; torch.zeros_like(x, dtype=torch.int)
 tensor([ 0,  0,  0], dtype=torch.int32)</code></pre>
</div>


<div class="blog-list-container blog-list-container">
	<div class="container">
		<ul class="list unordered-list indent-con ">
												<li class="item">
<code>tensor.new_*</code> can also create <code>Tensors</code> with same attributes as <code>tensor</code>, but it always takes in a shape argument:								</li>
					</ul>
	</div>
</div>


<div class="code-block">
<pre class="wp-block-code"><code lang="bash" class="language-bash"> &gt;&gt;&gt; x = torch.randn(3, dtype=torch.float64)
 &gt;&gt;&gt; x.new_ones(2)
 tensor([ 1.,  1.], dtype=torch.float64)
 &gt;&gt;&gt; x.new_ones(4, dtype=torch.int)
 tensor([ 1,  1,  1,  1], dtype=torch.int32)</code></pre>
</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text"><code><strong>&gt;&gt;&gt;</strong> x <strong>=</strong> torch.randn(3, dtype<strong>=</strong>torch.float64) <strong>&gt;&gt;&gt;</strong> x.new_ones(2) tensor([ 1., 1.], dtype<strong>=</strong>torch.float64) <strong>&gt;&gt;&gt;</strong> x.new_ones(4, dtype<strong>=</strong>torch.int) tensor([ 1, 1, 1, 1], dtype<strong>=</strong>torch.int32)</code></p>
	</div>
</div>


<figure class="wp-block-table"><table class="has-fixed-layout">
<thead><tr>
<th>Name</th>
<th>Returned&nbsp;<code>Tensor</code>
</th>
<th>
<code>torch.*_like</code>&nbsp;variant</th>
<th>
<code>tensor.new_*</code>&nbsp;variant</th>
</tr></thead>
<tbody>
<tr>
<td><a href="https://pytorch.org/docs/0.4.0/torch.html#torch.empty"><code>torch.empty</code></a></td>
<td>uninitialized memory</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><a href="https://pytorch.org/docs/0.4.0/torch.html#torch.zeros"><code>torch.zeros</code></a></td>
<td>all zeros</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><a href="https://pytorch.org/docs/0.4.0/torch.html#torch.ones"><code>torch.ones</code></a></td>
<td>all ones</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><a href="https://pytorch.org/docs/0.4.0/torch.html#torch.full"><code>torch.full</code></a></td>
<td>filled with a given value</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><a href="https://pytorch.org/docs/0.4.0/torch.html#torch.rand"><code>torch.rand</code></a></td>
<td>i.i.d. continuous Uniform[0, 1)</td>
<td>✔</td>
<td></td>
</tr>
<tr>
<td><a href="https://pytorch.org/docs/0.4.0/torch.html#torch.randn"><code>torch.randn</code></a></td>
<td>i.i.d.&nbsp;<code>Normal(0, 1)</code>
</td>
<td>✔</td>
<td></td>
</tr>
<tr>
<td><a href="https://pytorch.org/docs/0.4.0/torch.html#torch.randint"><code>torch.randint</code></a></td>
<td>i.i.d. discrete Uniform in given range</td>
<td>✔</td>
<td></td>
</tr>
<tr>
<td><a href="https://pytorch.org/docs/0.4.0/torch.html#torch.randperm"><code>torch.randperm</code></a></td>
<td>random permutation of&nbsp;<code>{0, 1, ..., n - 1}</code>
</td>
<td></td>
<td></td>
</tr>
<tr>
<td><a href="https://pytorch.org/docs/0.4.0/torch.html#torch.tensor"><code>torch.tensor</code></a></td>
<td>copied from existing data (list, NumPy ndarray, etc.)</td>
<td></td>
<td>✔</td>
</tr>
<tr>
<td><a href="https://pytorch.org/docs/0.4.0/torch.html#torch.from_numpy"><code>torch.from_numpy</code>*</a></td>
<td>from NumPy&nbsp;<code>ndarray</code>&nbsp;(sharing storage without copying)</td>
<td></td>
<td></td>
</tr>
<tr>
<td>
<a href="https://pytorch.org/docs/0.4.0/torch.html#torch.arange"><code>torch.arange</code></a>,&nbsp;<a href="https://pytorch.org/docs/0.4.0/torch.html#torch.range"><code>torch.range</code></a>, and&nbsp;<a href="https://pytorch.org/docs/0.4.0/torch.html#torch.linspace"><code>torch.linspace</code></a>
</td>
<td>uniformly spaced values in a given range</td>
<td></td>
<td></td>
</tr>
<tr>
<td><a href="https://pytorch.org/docs/0.4.0/torch.html#torch.logspace"><code>torch.logspace</code></a></td>
<td>logarithmically spaced values in a given range</td>
<td></td>
<td></td>
</tr>
<tr>
<td><a href="https://pytorch.org/docs/0.4.0/torch.html#torch.eye"><code>torch.eye</code></a></td>
<td>identity matrix</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table></figure>




<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">*: <a href="https://pytorch.org/docs/0.4.0/torch.html#torch.from_numpy"><code>torch.from_numpy</code></a> only takes in a NumPy <code>ndarray</code> as its input argument.</p>
	</div>
</div>

<div class="">
<h2 class="HeadingBlock Heading is-style-secondary-heading HeadingBlock  " id="block-86d96a39-15f1-45e7-acb6-60ed83d4c329">
		
	WRITING DEVICE-AGNOSTIC CODE</h2>
	</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">Previous versions of PyTorch made it difficult to write code that was device agnostic (i.e. that could run on both CUDA-enabled and CPU-only machines without modification).<br><br>PyTorch 0.4.0 makes this easier in two ways:</p>
	</div>
</div>


<div class="blog-list-container blog-list-container">
	<div class="container">
		<ul class="list unordered-list indent-con ">
												<li class="item">The <code>device</code> attribute of a Tensor gives the <a href="https://pytorch.org/docs/0.4.0/tensor_attributes.html#torch.torch.device">torch.device</a> for all Tensors (<code>get_device</code> only works for CUDA tensors)								</li>
												<li class="item">The <code>to</code> method of <code>Tensors</code> and <code>Modules</code> can be used to easily move objects to different devices (instead of having to call <code>cpu()</code> or <code>cuda()</code> based on the context)								</li>
					</ul>
	</div>
</div>




<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">We recommend the following pattern:</p>
	</div>
</div>

<div class="code-block">
<pre class="wp-block-code"><code lang="bash" class="language-bash"># at beginning of the script
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

...

# then whenever you get a new Tensor or Module
# this won't copy if they are already on the desired device
input = data.to(device)
model = MyModule(...).to(device)</code></pre>
</div>

<div class="">
<h2 class="HeadingBlock Heading is-style-secondary-heading HeadingBlock  " id="block-16bf859a-f823-4ab6-8c81-5a55348cd2e9">
		
	NEW EDGE-CASE CONSTRAINTS ON NAMES OF SUBMODULES, PARAMETERS, AND BUFFERS IN <code>NN.MODULE</code>
</h2>
	</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text"><code>name</code> that is an empty string or contains <code>"."</code> is no longer permitted in <code>module.add_module(name, value)</code>, <code>module.add_parameter(name, value)</code> or <code>module.add_buffer(name, value)</code> because such names may cause lost data in the <code>state_dict</code>. If you are loading a checkpoint for modules containing such names, please update the module definition and patch the <code>state_dict</code> before loading it.</p>
	</div>
</div>

<div class="">
<h2 class="HeadingBlock Heading is-style-secondary-heading HeadingBlock  " id="block-d62c7666-bd65-418e-8209-3b1169303748">
		
	CODE SAMPLES (PUTTING IT ALL TOGETHER)</h2>
	</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">To get a flavor of the overall recommended changes in 0.4.0, let’s look at a quick example for a common code pattern in both 0.3.1 and 0.4.0:</p>
	</div>
</div>


<div class="blog-list-container blog-list-container">
	<div class="container">
		<ul class="list unordered-list indent-con ">
												<li class="item">0.3.1 (old)								</li>
					</ul>
	</div>
</div>


<div class="code-block">
<pre class="wp-block-code"><code lang="bash" class="language-bash">model = MyRNN()
if use_cuda:
    model = model.cuda()

# train
total_loss = 0
for input, target in train_loader:
    input, target = Variable(input), Variable(target)
    hidden = Variable(torch.zeros(*h_shape))  # init hidden
    if use_cuda:
        input, target, hidden = input.cuda(), target.cuda(), hidden.cuda()
    ...  # get loss and optimize
    total_loss += loss.data[0]

# evaluate
for input, target in test_loader:
    input = Variable(input, volatile=True)
    if use_cuda:
        ...
    ...</code></pre>
</div>


<div class="blog-list-container blog-list-container">
	<div class="container">
		<ul class="list unordered-list indent-con ">
												<li class="item">0.4.0 (new)								</li>
					</ul>
	</div>
</div>


<div class="code-block">
<pre class="wp-block-code"><code lang="bash" class="language-bash"># torch.device object used throughout this script
device = torch.device("cuda" if use_cuda else "cpu")

model = MyRNN().to(device)

# train
total_loss = 0
for input, target in train_loader:
    input, target = input.to(device), target.to(device)
    hidden = input.new_zeros(*h_shape)  # has the same device &amp; dtype as `input`
    ...  # get loss and optimize
    total_loss += loss.item()           # get Python number from 1-element Tensor

# evaluate
with torch.no_grad():                   # operations inside don't track history
    for input, target in test_loader:
        ...</code></pre>
</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">Thank you for reading! Please refer to our <a href="https://pytorch.org/docs/0.4.0/index.html">documentation</a> and <a href="https://github.com/pytorch/pytorch/releases/tag/v0.4.0" target="_blank">release notes</a> for more details.<br><br>Happy PyTorch-ing!</p>
	</div>
</div>	</main>

	<footer class="Footer">
		<div class="mainNav">
			<div class="logo">
				<a href="/" aria-label="Go to Pytorch home">
					<svg width="30" height="35" viewbox="0 0 30 35" fill="none" xmlns="http://www.w3.org/2000/svg" role="img">
<path d="M24.8384 10.3748L22.3344 12.8296C26.5077 16.9211 26.5077 23.5842 22.3344 27.6757C18.1612 31.7671 11.3647 31.7671 7.19148 27.6757C3.01823 23.5842 3.01823 16.9211 7.19148 12.8296L13.8687 6.28337L14.7033 5.34818V0.438477L4.56829 10.3748C-1.03579 15.869 -1.03579 24.6363 4.56829 30.1305C10.1724 35.6247 19.1151 35.6247 24.7191 30.1305C30.4424 24.6363 30.4424 15.7521 24.8384 10.3748Z" fill="#F05F42"></path>
<ellipse cx="19.8316" cy="7.80298" rx="1.90777" ry="1.87036" fill="#F05F42"></ellipse>
</svg>
				</a>
			</div>

			<ul class="footerNav">
													<li class="mainItem">
						<a href="#" target="" class="footer-item  ">
							PyTorch						</a>
													<ul>
																	<li class="subItem">
										<a href="/install/" target="" class=" ">
											Install										</a>
																			</li>
																	<li class="subItem">
										<a href="/features/" target="" class=" ">
											Features										</a>
																			</li>
																	<li class="subItem">
										<a href="/resources/" target="" class=" ">
											Resources										</a>
																			</li>
																	<li class="subItem">
										<a href="https://pytorch.org/docs/stable/index.html" target="" class="docs ">
											Docs										</a>
																			</li>
																	<li class="subItem">
										<a href="https://pytorch.org/tutorials/" target="" class="tutorials ">
											Tutorials										</a>
																			</li>
																	<li class="subItem">
										<a href="/community/" target="" class=" ">
											Community										</a>
																			</li>
																	<li class="subItem">
										<a href="https://github.com/pytorch/pytorch" target="" class=" ">
											Github										</a>
																			</li>
															</ul>
											</li>
									<li class="mainItem">
						<a href="#" target="" class="footer-item  ">
							Support						</a>
													<ul>
																	<li class="subItem">
										<a href="https://github.com/pytorch/pytorch/issues" target="_blank" class=" icon-github">
											Github Issues										</a>
																			</li>
																	<li class="subItem">
										<a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank" class=" ">
											Brand Guidelines										</a>
																			</li>
																	<li class="subItem">
										<a href="https://discuss.pytorch.org/" target="_blank" class=" ">
											Discuss										</a>
																			</li>
															</ul>
											</li>
								<li class="mainItem">
					
<div class="navItems-followContainer followMenu ">
			<div class="mainItem">Follow Us</div>
		<ul class="follow-list">
					<li class="followItem">
				<a aria-label="follow Menu  icon-twitter" href="https://twitter.com/pytorch" target="_blank" class=" icon-twitter">
					Twitter				</a>
			</li>
					<li class="followItem">
				<a aria-label="follow Menu  icon-facebook" href="https://www.facebook.com/pytorch" target="_blank" class=" icon-facebook">
					Facebook				</a>
			</li>
					<li class="followItem">
				<a aria-label="follow Menu  icon-youtube" href="https://www.youtube.com/pytorch" target="_blank" class=" icon-youtube">
					YouTube				</a>
			</li>
					<li class="followItem">
				<a aria-label="follow Menu  icon-linkedin" href="https://www.linkedin.com/company/pytorch" target="_blank" class=" icon-linkedin">
					Linkedin				</a>
			</li>
					<li class="followItem">
				<a aria-label="follow Menu  icon-medium" href="https://medium.com/pytorch" target="_blank" class=" icon-medium">
					Medium				</a>
			</li>
					<li class="followItem">
				<a aria-label="follow Menu  icon-github" href="https://github.com/pytorch/pytorch" target="_blank" class=" icon-github">
					GitHub				</a>
			</li>
			</ul>
</div>
				</li>
			</ul>
		</div>
		<div class="legalNav">
			<ul class="legalNavList">
													<li>
						<a href="/wp-content/uploads/2021/11/fb-tos-privacy-policy.pdf" target="" class=" ">
							Terms						</a>
					</li>
									<li>
						<a href="/wp-content/uploads/2021/11/fb-oss-privacy-policy.pdf" target="" class=" ">
							Privacy						</a>
					</li>
							</ul>
		</div>
	</footer>
</div>

<script id="pytorch-classic-js-js-extra">
var gridData = {"build":{"stable":"Stable (1.9.0)","nightly":"Preview (Nightly)","lts":"LTS (1.8.1)"},"os":{"mac":"MacOS","linux":"Linux","windows":"Windows"},"package":{"conda":"Conda","pip":"Pip","libtorch":"LibTorch","source":"Source"},"language":{"python":"Python","cplusplus":"C++\/Java"},"platform":{"cuda10.2":"CUDA 10.2","cuda11.1":"CUDA 11.1","rocm":"ROCm 4.2(beta)","cpu":"CPU"}};
var platformOSSupport = {"linux":["cuda10.2","rocm","cpu"],"mac":["cpu"],"windows":["cuda10.2","rocm","cpu"]};
var packageLanguageSupport = {"python":["pip","conda","source"],"cplusplus":["libtorch"]};
var commands = {"stable,conda,mac,cpu,python":"conda install pytorch torchvision torchaudio -c pytorch","nightly,conda,linux,cpu,python":"conda install pytorch torchvision torchaudio cpuonly -c pytorch-nightly","stable,libtorch,windows,rocm,cplusplus":"NOTE: ROCm is not available on Windows","stable,conda,windows,cpu,python":"conda install pytorch torchvision torchaudio cpuonly -c pytorch-nightly","stable,conda,windows,rocm,python":"NOTE: ROCm is not available on Windows","stable,pip,windows,rocm,python":"NOTE: ROCm is not available on Windows","stable,pip,windows,cpu,python":"pip3 install --pre torch torchvision torchaudio -f https:\/\/download.pytorch.org\/whl\/nightly\/cpu\/torch_nightly.html","stable,conda,windows,cuda10.2,python":"conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch-nightly","stable,conda,windows,cuda11.1,python":"NOTE: \\'conda-forge\\' channel is required for cudatoolkit 11.1\r\nconda install pytorch torchvision torchaudio cudatoolkit=11.1 -c pytorch-nightly -c conda-forge","stable,libtorch,mac,rocm,cplusplus":"NOTE: ROCm is not available on MacOS","stable,conda,mac,rocm,python":"NOTE: ROCm is not available on MacOS","stable,conda,linux,cpu,python":"conda install pytorch torchvision torchaudio cpuonly -c pytorch","stable,conda,linux,rocm,python":"NOTE: Conda packages are not currently available for ROCm, please use pip instead","stable,conda,linux,cuda10.2,python":"conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch","stable,conda,linux,cuda11.1,python":"NOTE: \\'nvidia\\' channel is required for cudatoolkit 11.1\r\nconda install pytorch torchvision torchaudio cudatoolkit=11.1 -c pytorch -c nvidia","lts,libtorch,windows,rocm,cplusplus":"NOTE: ROCm is not supported in LTS","lts,pip,mac,cpu,python":"# macOS is not currently supported for lts","lts,conda,mac,cuda10.2,python":"# macOS is not currently supported for lts","lts,conda,mac,cuda11.1,python":"# macOS is not currently supported for lts","lts,conda,mac,rocm,python":"# macOS is not currently supported for lts","lts,conda,mac,cpu,python":"# macOS is not currently supported for lts","stable,conda,mac,cuda10.2,python":"# MacOS Binaries dont support CUDA, install from source if CUDA is needed\r\nconda install pytorch torchvision torchaudio -c pytorch","lts,libtorch,mac,cpu,cplusplus":"# macOS is not currently supported for lts","lts,libtorch,mac,cuda10.2,cplusplus":"# macOS is not currently supported for lts","lts,libtorch,mac,cuda11.1,cplusplus":"# macOS is not currently supported for lts","lts,libtorch,mac,rocm,cplusplus":"# macOS is not currently supported for lts","lts,pip,windows,rocm,python":"NOTE: ROCm is not supported in LTS","stable,libtorch,linux,cpu,cplusplus":"Download here (Pre-cxx11 ABI):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/cpu\/libtorch-shared-with-deps-1.9.1%2Bcpu.zip\">https:\/\/download.pytorch.org\/libtorch\/cpu\/libtorch-shared-with-deps-1.9.1%2Bcpu.zip<\/a>\r\nDownload here (cxx11 ABI):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/cpu\/libtorch-cxx11-abi-shared-with-deps-1.9.1%2Bcpu.zip\">https:\/\/download.pytorch.org\/libtorch\/cpu\/libtorch-cxx11-abi-shared-with-deps-1.9.1%2Bcpu.zip<\/a>","stable,pip,linux,cpu,python":"pip3 install --pre torch torchvision torchaudio -f https:\/\/download.pytorch.org\/whl\/nightly\/cpu\/torch_nightly.html","stable,pip,linux,cuda11.1,python":"pip3 install torch==1.9.1+cu111 torchvision==0.10.1+cu111 torchaudio==0.9.1 -f https:\/\/download.pytorch.org\/whl\/torch_stable.html","stable,pip,linux,cuda10.2,python":"pip3 install torch torchvision torchaudio","stable,pip,linux,rocm,python":"pip3 install torch torchvision==0.10.1 -f https:\/\/download.pytorch.org\/whl\/rocm4.2\/torch_stable.html","stable,libtorch,linux,cuda10.2,cplusplus":"Download here (Pre-cxx11 ABI):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/cu102\/libtorch-shared-with-deps-1.9.1%2Bcu102.zip\">https:\/\/download.pytorch.org\/libtorch\/cu102\/libtorch-shared-with-deps-1.9.1%2Bcu102.zip<\/a>\r\nDownload here (cxx11 ABI):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/cu102\/libtorch-cxx11-abi-shared-with-deps-1.9.1%2Bcu102.zip\">https:\/\/download.pytorch.org\/libtorch\/cu102\/libtorch-cxx11-abi-shared-with-deps-1.9.1%2Bcu102.zip<\/a>","stable,libtorch,linux,cuda11.1,cplusplus":"Download here (Pre-cxx11 ABI):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/cu111\/libtorch-shared-with-deps-1.9.1%2Bcu111.zip\">https:\/\/download.pytorch.org\/libtorch\/cu111\/libtorch-shared-with-deps-1.9.1%2Bcu111.zip<\/a>\r\nDownload here (cxx11 ABI):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/cu111\/libtorch-cxx11-abi-shared-with-deps-1.9.1%2Bcu111.zip\">https:\/\/download.pytorch.org\/libtorch\/cu111\/libtorch-cxx11-abi-shared-with-deps-1.9.1%2Bcu111.zip<\/a>","stable,libtorch,linux,rocm,cplusplus":"LibTorch binaries are not available for ROCm, please build it from source","stable,pip,mac,cuda10.2,python":"# MacOS Binaries dont support CUDA, install from source if CUDA is needed\r\npip3 install torch torchvision torchaudio","stable,pip,mac,cuda11.1,python":"# MacOS Binaries dont support CUDA, install from source if CUDA is needed\r\npip3 install torch torchvision torchaudio","stable,pip,mac,rocm,python":"NOTE: ROCm is not available on MacOS","stable,pip,mac,cpu,python":"pip3 install torch torchvision torchaudio","stable,conda,mac,cuda11.1,python":"# MacOS Binaries dont support CUDA, install from source if CUDA is needed\r\nconda install pytorch torchvision torchaudio -c pytorch","stable,libtorch,mac,cpu,cplusplus":"Download here:\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/cpu\/libtorch-macos-1.9.1.zip\">https:\/\/download.pytorch.org\/libtorch\/cpu\/libtorch-macos-1.9.1.zip<\/a>","stable,libtorch,mac,cuda10.2,cplusplus":"MacOS binaries do not support CUDA. Download CPU libtorch here:\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/cpu\/libtorch-macos-1.9.1.zip\">https:\/\/download.pytorch.org\/libtorch\/cpu\/libtorch-macos-1.9.1.zip<\/a>","stable,libtorch,mac,cuda11.1,cplusplus":"MacOS binaries do not support CUDA. Download CPU libtorch here:\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/cpu\/libtorch-macos-1.9.1.zip\">https:\/\/download.pytorch.org\/libtorch\/cpu\/libtorch-macos-1.9.1.zip<\/a>","stable,libtorch,windows,cuda11.1,python":"Download here (Release version):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/cu111\/libtorch-win-shared-with-deps-1.9.1%2Bcu111.zip\">https:\/\/download.pytorch.org\/libtorch\/cu111\/libtorch-win-shared-with-deps-1.9.1%2Bcu111.zip<\/a>\r\nDownload here (Debug version):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/cu111\/libtorch-win-shared-with-deps-debug-1.9.1%2Bcu111.zip\">https:\/\/download.pytorch.org\/libtorch\/cu111\/libtorch-win-shared-with-deps-debug-1.9.1%2Bcu111.zip<\/a>","stable,libtorch,windows,cuda10.2,cplusplus":"Download here (Release version):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/nightly\/cu102\/libtorch-win-shared-with-deps-latest.zip\">https:\/\/download.pytorch.org\/libtorch\/nightly\/cu102\/libtorch-win-shared-with-deps-latest.zip<\/a>\r\nDownload here (Debug version):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/nightly\/cu102\/libtorch-win-shared-with-deps-debug-latest.zip\">https:\/\/download.pytorch.org\/libtorch\/nightly\/cu102\/libtorch-win-shared-with-deps-debug-latest.zip<\/a>","stable,libtorch,windows,cpu,cplusplus":"Download here (Release version):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/nightly\/cpu\/libtorch-win-shared-with-deps-latest.zip\">https:\/\/download.pytorch.org\/libtorch\/nightly\/cpu\/libtorch-win-shared-with-deps-latest.zip<\/a>\r\nDownload here (Debug version):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/nightly\/cpu\/libtorch-win-shared-with-deps-debug-latest.zip\">https:\/\/download.pytorch.org\/libtorch\/nightly\/cpu\/libtorch-win-shared-with-deps-debug-latest.zip<\/a>","stable,pip,windows,cuda11.1,python":"pip3 install --pre torch torchvision torchaudio -f https:\/\/download.pytorch.org\/whl\/nightly\/cu111\/torch_nightly.html","stable,pip,windows,cuda10.2,python":"pip3 install --pre torch torchvision torchaudio -f https:\/\/download.pytorch.org\/whl\/nightly\/cu102\/torch_nightly.html","stable,libtorch,windows,cuda11.1,cplusplus":"Download here (Release version):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/nightly\/cu111\/libtorch-win-shared-with-deps-latest.zip\">https:\/\/download.pytorch.org\/libtorch\/nightly\/cu111\/libtorch-win-shared-with-deps-latest.zip<\/a>\r\nDownload here (Debug version):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/nightly\/cu111\/libtorch-win-shared-with-deps-debug-latest.zip\">https:\/\/download.pytorch.org\/libtorch\/nightly\/cu111\/libtorch-win-shared-with-deps-debug-latest.zip<\/a>","lts,pip,linux,cpu,python":"pip3 install torch==1.8.2+cpu torchvision==0.9.2+cpu torchaudio==0.8.2 -f https:\/\/download.pytorch.org\/whl\/lts\/1.8\/torch_lts.html","lts,pip,linux,cuda10.2,python":"pip3 install torch==1.8.2+cu102 torchvision==0.9.2+cu102 torchaudio==0.8.2 -f https:\/\/download.pytorch.org\/whl\/lts\/1.8\/torch_lts.html","lts,pip,linux,cuda11.1,python":"pip3 install torch==1.8.2+cu111 torchvision==0.9.2+cu111 torchaudio==0.8.2 -f https:\/\/download.pytorch.org\/whl\/lts\/1.8\/torch_lts.html","lts,pip,linux,rocm,python":"NOTE: ROCm is not supported in LTS","lts,conda,linux,cuda10.2,python":"conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch-lts","lts,conda,linux,cuda11.1,python":"NOTE: \\'nvidia\\' channel is required for cudatoolkit 11.1\r\nconda install pytorch torchvision torchaudio cudatoolkit=11.1 -c pytorch-lts -c nvidia","lts,conda,linux,rocm,python":"NOTE: ROCm is not supported in LTS","lts,conda,linux,cpu,python":"conda install pytorch torchvision torchaudio cpuonly -c pytorch-lts","lts,libtorch,linux,cpu,cplusplus":"Download here (Pre-cxx11 ABI):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cpu\/libtorch-shared-with-deps-1.8.2%2Bcpu.zip\">https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cpu\/libtorch-shared-with-deps-1.8.2%2Bcpu.zip<\/a>\r\nDownload here (cxx11 ABI):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cpu\/libtorch-cxx11-abi-shared-with-deps-1.8.2%2Bcpu.zip\">https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cpu\/libtorch-cxx11-abi-shared-with-deps-1.8.2%2Bcpu.zip<\/a>","lts,libtorch,linux,cuda10.2,cplusplus":"Download here (Pre-cxx11 ABI):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu102\/libtorch-shared-with-deps-1.8.2%2Bcu102.zip\">https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu102\/libtorch-shared-with-deps-1.8.2%2Bcu102.zip<\/a>\r\nDownload here (cxx11 ABI):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu102\/libtorch-cxx11-abi-shared-with-deps-1.8.2%2Bcu102.zip\">https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu102\/libtorch-cxx11-abi-shared-with-deps-1.8.2%2Bcu102.zip<\/a>","lts,libtorch,linux,cuda11.1,cplusplus":"Download here (Pre-cxx11 ABI):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu111\/libtorch-shared-with-deps-1.8.2%2Bcu111.zip\">https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu111\/libtorch-shared-with-deps-1.8.2%2Bcu111.zip<\/a>\r\nDownload here (cxx11 ABI):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu111\/libtorch-cxx11-abi-shared-with-deps-1.8.2%2Bcu111.zip\">https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu111\/libtorch-cxx11-abi-shared-with-deps-1.8.2%2Bcu111.zip<\/a>","lts,libtorch,linux,rocm,python":"NOTE: ROCm is not supported in LTS","lts,pip,mac,cuda10.2,python":"# macOS is not currently supported for lts","lts,pip,mac,cuda11.1,python":"# macOS is not currently supported for lts","lts,pip,mac,rocm,python":"# macOS is not currently supported for lts","lts,pip,windows,cpu,python":"pip3 install torch==1.8.2+cpu torchvision==0.9.2+cpu torchaudio===0.8.2 -f https:\/\/download.pytorch.org\/whl\/lts\/1.8\/torch_lts.html","lts,pip,windows,cuda10.2,python":"pip3 install torch==1.8.2+cu102 torchvision==0.9.2+cu102 torchaudio===0.8.2 -f https:\/\/download.pytorch.org\/whl\/lts\/1.8\/torch_lts.html","lts,pip,windows,cuda11.1,python":"pip3 install torch==1.8.2+cu111 torchvision==0.9.2+cu111 torchaudio===0.8.2 -f https:\/\/download.pytorch.org\/whl\/lts\/1.8\/torch_lts.html","lts,conda,windows,cuda10.2,python":"conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch-lts","lts,conda,windows,cuda11.1,python":"NOTE: \\'conda-forge\\' channel is required for cudatoolkit 11.1\r\nconda install pytorch torchvision torchaudio cudatoolkit=11.1 -c pytorch-lts -c conda-forge","lts,conda,windows,cpu,python":"conda install pytorch torchvision torchaudio cpuonly -c pytorch-lts","lts,conda,windows,rocm,python":"NOTE: ROCm is not supported in LTS","lts,libtorch,windows,cpu,cplusplus":"Download here (Release version):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cpu\/libtorch-win-shared-with-deps-1.8.2%2Bcpu.zip\">https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cpu\/libtorch-win-shared-with-deps-1.8.2%2Bcpu.zip<\/a>\r\nDownload here (Debug version):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cpu\/libtorch-win-shared-with-deps-debug-1.8.2%2Bcpu.zip\">https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cpu\/libtorch-win-shared-with-deps-debug-1.8.2%2Bcpu.zip<\/a>","lts,libtorch,windows,cuda10.2,cplusplus":"Download here (Release version):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu102\/libtorch-win-shared-with-deps-1.8.2%2Bcu102.zip\">https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu102\/libtorch-win-shared-with-deps-1.8.2%2Bcu102.zip<\/a>\r\nDownload here (Debug version):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu102\/libtorch-win-shared-with-deps-debug-1.8.2%2Bcu102.zip\">https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu102\/libtorch-win-shared-with-deps-debug-1.8.2%2Bcu102.zip<\/a>","lts,libtorch,windows,cuda11.1,cplusplus":"Download here (Release version):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu111\/libtorch-win-shared-with-deps-1.8.2%2Bcu111.zip\">https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu111\/libtorch-win-shared-with-deps-1.8.2%2Bcu111.zip<\/a>\r\nDownload here (Debug version):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu111\/libtorch-win-shared-with-deps-debug-1.8.2%2Bcu111.zip\">https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu111\/libtorch-win-shared-with-deps-debug-1.8.2%2Bcu111.zip<\/a>"};
</script>
<script src="/wp-content/themes/pytorch/assets/js/index.bundle.js?ver=1" id="pytorch-classic-js-js"></script>
<script src="/wp-content/themes/pytorch/assets/js/blog-header.bundle.js?ver=1" id="pytorch-blog-header-js"></script>
<script src="/wp-content/themes/pytorch/assets/js/blog-text.bundle.js?ver=1" id="pytorch-blog-text-js"></script>
<script src="/wp-content/themes/pytorch/assets/js/blog-list.bundle.js?ver=1" id="pytorch-blog-list-js"></script>
<script src="/wp-content/themes/pytorch/assets/js/heading.bundle.js?ver=1" id="pytorch-heading-js"></script>
<script id="mkaz-code-syntax-prism-js-js-extra">
var prism_settings = {"pluginUrl":"\/wp-content\/plugins\/code-syntax-block\/"};
</script>
<script src="/wp-content/plugins/code-syntax-block/assets/prism/prism.js?ver=1641826791" id="mkaz-code-syntax-prism-js-js"></script>
<script src="/wp-content/plugins/simply-static-pro/assets/fuse.js?ver=1.1" id="ssp-fuse-js"></script>
<script src="/wp-content/plugins/simply-static-pro/assets/ssp-search.js?ver=1.1" id="ssp-search-js"></script>
<script src="https://stats.wp.com/e-202203.js" defer></script>
<script>
	_stq = window._stq || [];
	_stq.push([ 'view', {v:'ext',j:'1:10.4',blog:'195752808',post:'1310',tz:'0',srv:'pytorch-org-preprod.go-vip.net'} ]);
	_stq.push([ 'clickTrackerInit', '195752808', '1310' ]);
</script>

</body>
</html>