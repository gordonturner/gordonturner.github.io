<!DOCTYPE html>
<html lang="en-US">
<head>
  <title> Efficient PyTorch I/O library for Large Datasets, Many Files, Many GPUs</title>
	<!-- Google Tag Manager -->
	<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
	new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
	j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
	'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
	})(window,document,'script','dataLayer','GTM-52DXT37');</script>
	<!-- End Google Tag Manager -->
	<!-- Docsearch -->
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css">
	<script src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script>
	<!-- End Docsearch -->

	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta name="robots" content="max-image-preview:large">
<link rel="dns-prefetch" href="//s.w.org">
<link rel="alternate" type="application/rss+xml" title="pytorch-org-preprod.go-vip.net &raquo; Efficient PyTorch I/O library for Large Datasets, Many Files, Many GPUs Comments Feed" href="/efficient-pytorch-i-o-library-for-large-datasets-many-files-many-gpus/feed/">
		<script type="text/javascript">
			window._wpemojiSettings = {"baseUrl":"https:\/\/s.w.org\/images\/core\/emoji\/13.0.1\/72x72\/","ext":".png","svgUrl":"https:\/\/s.w.org\/images\/core\/emoji\/13.0.1\/svg\/","svgExt":".svg","source":{"concatemoji":"\/wp-includes\/js\/wp-emoji-release.min.js?ver=5.7.5"}};
			!function(e,a,t){var n,r,o,i=a.createElement("canvas"),p=i.getContext&&i.getContext("2d");function s(e,t){var a=String.fromCharCode;p.clearRect(0,0,i.width,i.height),p.fillText(a.apply(this,e),0,0);e=i.toDataURL();return p.clearRect(0,0,i.width,i.height),p.fillText(a.apply(this,t),0,0),e===i.toDataURL()}function c(e){var t=a.createElement("script");t.src=e,t.defer=t.type="text/javascript",a.getElementsByTagName("head")[0].appendChild(t)}for(o=Array("flag","emoji"),t.supports={everything:!0,everythingExceptFlag:!0},r=0;r<o.length;r++)t.supports[o[r]]=function(e){if(!p||!p.fillText)return!1;switch(p.textBaseline="top",p.font="600 32px Arial",e){case"flag":return s([127987,65039,8205,9895,65039],[127987,65039,8203,9895,65039])?!1:!s([55356,56826,55356,56819],[55356,56826,8203,55356,56819])&&!s([55356,57332,56128,56423,56128,56418,56128,56421,56128,56430,56128,56423,56128,56447],[55356,57332,8203,56128,56423,8203,56128,56418,8203,56128,56421,8203,56128,56430,8203,56128,56423,8203,56128,56447]);case"emoji":return!s([55357,56424,8205,55356,57212],[55357,56424,8203,55356,57212])}return!1}(o[r]),t.supports.everything=t.supports.everything&&t.supports[o[r]],"flag"!==o[r]&&(t.supports.everythingExceptFlag=t.supports.everythingExceptFlag&&t.supports[o[r]]);t.supports.everythingExceptFlag=t.supports.everythingExceptFlag&&!t.supports.flag,t.DOMReady=!1,t.readyCallback=function(){t.DOMReady=!0},t.supports.everything||(n=function(){t.readyCallback()},a.addEventListener?(a.addEventListener("DOMContentLoaded",n,!1),e.addEventListener("load",n,!1)):(e.attachEvent("onload",n),a.attachEvent("onreadystatechange",function(){"complete"===a.readyState&&t.readyCallback()})),(n=t.source||{}).concatemoji?c(n.concatemoji):n.wpemoji&&n.twemoji&&(c(n.twemoji),c(n.wpemoji)))}(window,document,window._wpemojiSettings);
		</script>
		<style type="text/css">img.wp-smiley,
img.emoji {
	display: inline !important;
	border: none !important;
	box-shadow: none !important;
	height: 1em !important;
	width: 1em !important;
	margin: 0 .07em !important;
	vertical-align: -0.1em !important;
	background: none !important;
	padding: 0 !important;
}</style>
	<link rel="stylesheet" id="pytorch-classic-style-css" href="/wp-content/themes/pytorch/assets/css/index.css?ver=1" media="all">
<link rel="stylesheet" id="pytorch-blog-header-css" href="/wp-content/themes/pytorch/assets/css/blog-header.css?ver=1" media="all">
<link rel="stylesheet" id="pytorch-blog-text-css" href="/wp-content/themes/pytorch/assets/css/blog-text.css?ver=1" media="all">
<link rel="stylesheet" id="pytorch-blog-list-css" href="/wp-content/themes/pytorch/assets/css/blog-list.css?ver=1" media="all">
<link rel="stylesheet" id="pytorch-heading-css" href="/wp-content/themes/pytorch/assets/css/heading.css?ver=1" media="all">
<link rel="stylesheet" id="pytorch-blog-image-css" href="/wp-content/themes/pytorch/assets/css/blog-image.css?ver=1" media="all">
<link rel="stylesheet" id="mediaelement-css" href="/wp-includes/js/mediaelement/mediaelementplayer-legacy.min.css?ver=4.2.16" media="all">
<link rel="stylesheet" id="wp-mediaelement-css" href="/wp-includes/js/mediaelement/wp-mediaelement.min.css?ver=5.7.5" media="all">
<link rel="stylesheet" id="mkaz-code-syntax-prism-css-css" href="/wp-content/plugins/code-syntax-block/assets/prism-ghcolors.css?ver=1641826791" media="all">
<link rel="stylesheet" id="ssp-search-css" href="/wp-content/plugins/simply-static-pro/assets/ssp-search.css?ver=1.1" media="all">
<link rel="https://api.w.org/" href="/wp-json/">
<link rel="alternate" type="application/json" href="/wp-json/wp/v2/posts/1001">
<link rel="EditURI" type="application/rsd+xml" title="RSD" href="/xmlrpc.php?rsd">
<link rel="wlwmanifest" type="application/wlwmanifest+xml" href="/wp-includes/wlwmanifest.xml"> 
<meta name="generator" content="WordPress 5.7.5">
<link rel="canonical" href="/efficient-pytorch-i-o-library-for-large-datasets-many-files-many-gpus/">
<link rel="shortlink" href="/?p=1001">
		<meta name="ssp-url" content="">
		<meta name="ssp-config-url" content="/wp-content/plugins/simply-static-pro/configs/">
		<style type="text/css">img#wpstats{display:none}</style>
		</head>

<body class="post-template-default single single-post postid-1001 single-format-standard">
    <a id="skip" href="#main" tabindex="0">Skip to content</a>
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-52DXT37" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
<div>
	<header class="mainHeader">
		<div class="container">
			<div class="logo">
				<a href="/" aria-label="PyTorch Logo" tabindex="0">
					<svg role="img" width="109" height="27" viewbox="0 0 109 27" fill="none" xmlns="http://www.w3.org/2000/svg">
<path d="M14.6172 5.92839L13.1892 7.32839C15.5692 9.66172 15.5692 13.4617 13.1892 15.7951C10.8092 18.1284 6.93316 18.1284 4.55316 15.7951C2.17316 13.4617 2.17316 9.66172 4.55316 7.32839L8.36116 3.59505L8.83716 3.06172V0.261719L3.05716 5.92839C-0.138844 9.06172 -0.138844 14.0617 3.05716 17.1951C6.25316 20.3284 11.3532 20.3284 14.5492 17.1951C17.8132 14.0617 17.8132 8.99505 14.6172 5.92839Z" fill="#DE3412"></path>
<ellipse cx="11.7618" cy="4.4612" rx="1.088" ry="1.06667" fill="#DE3412"></ellipse>
<path fill-rule="evenodd" clip-rule="evenodd" d="M26.5048 13.23H28.9435C33.3467 13.1625 36.1242 11.205 36.1242 7.29C36.1242 3.9825 33.8887 1.6875 29.1467 1.6875H24.6758V19.5075H26.5048V13.23ZM26.4371 3.375H29.079C32.4661 3.375 34.2274 4.7925 34.2274 7.29C34.2274 10.0575 32.3984 11.4075 29.0113 11.475L26.4371 11.5425V3.375Z" fill="#262626"></path>
<path d="M44.3887 19.4405L43.3048 22.2755C42.0855 25.448 40.8661 26.393 39.0371 26.393C38.021 26.393 37.2758 26.123 36.4629 25.7855L37.0048 24.1655C37.6145 24.503 38.2919 24.7055 39.0371 24.7055C40.0532 24.7055 40.7984 24.1655 41.7468 21.668L42.6274 19.373L37.5468 6.48047H39.4435L43.5758 17.2805L47.6403 6.48047H49.4693L44.3887 19.4405Z" fill="#262626"></path>
<path d="M55.5665 3.4425V19.575H53.7375V3.4425H47.4375V1.6875H61.8665V3.375H55.5665V3.4425Z" fill="#262626"></path>
<path fill-rule="evenodd" clip-rule="evenodd" d="M60.6465 13.0277C60.6465 17.2127 63.3562 19.9127 67.0142 19.9127C70.6723 19.9127 73.4497 17.1452 73.4497 12.9602C73.4497 8.7752 70.8078 6.0752 67.1497 6.0752C63.4239 6.0752 60.6465 8.8427 60.6465 13.0277ZM62.4746 12.9613C62.4746 9.92379 64.3036 7.69629 67.0811 7.69629C69.8585 7.69629 71.7553 9.85629 71.7553 13.0288C71.7553 16.0663 69.9262 18.2938 67.1488 18.2938C64.3714 18.2938 62.4746 16.1338 62.4746 12.9613Z" fill="#262626"></path>
<path d="M77.9879 19.5731H76.2266V6.47813L77.9879 6.14062V8.90812C78.8685 7.22062 80.1556 6.14062 81.8491 6.14062C82.7298 6.14062 83.5427 6.41063 84.1524 6.74813L83.6782 8.43563C83.1362 8.09813 82.3911 7.89562 81.6459 7.89562C80.2911 7.89562 79.004 8.90813 77.9201 11.2706V19.5731H77.9879Z" fill="#262626"></path>
<path d="M91.1308 19.9127C87.2018 19.9127 84.6953 17.0777 84.6953 13.0277C84.6953 8.9102 87.405 6.0752 91.1308 6.0752C92.7566 6.0752 94.1114 6.4802 95.2631 7.2227L94.7889 8.8427C93.7727 8.1677 92.5534 7.7627 91.1308 7.7627C88.2856 7.7627 86.5243 9.8552 86.5243 12.9602C86.5243 16.1327 88.4211 18.2252 91.1985 18.2252C92.4856 18.2252 93.8405 17.8202 94.8566 17.1452L95.1953 18.7652C94.0437 19.5077 92.6211 19.9127 91.1308 19.9127Z" fill="#262626"></path>
<path d="M106.238 19.575V11.1375C106.238 8.8425 105.29 7.83 103.461 7.83C101.97 7.83 100.48 8.5725 99.3961 9.72V19.6425H97.6348V0.3375L99.3961 0C99.3961 0 99.3961 8.1675 99.3961 8.235C100.751 6.885 102.512 6.1425 103.935 6.1425C106.509 6.1425 108.067 7.7625 108.067 10.5975V19.575H106.238Z" fill="#262626"></path>
</svg>
				</a>
			</div>
			<div class="content-container">
				<ul class="mainNav">
					<li class="mainItem search" key="search">
						<button id="search-icon" aria-label="search">
							<svg role="img" width="17" height="16" viewbox="0 0 17 16" fill="none" xmlns="http://www.w3.org/2000/svg">
<path fill-rule="evenodd" clip-rule="evenodd" d="M11.7461 7C11.7461 9.48528 9.73137 11.5 7.24609 11.5C4.76081 11.5 2.74609 9.48528 2.74609 7C2.74609 4.51472 4.76081 2.5 7.24609 2.5C9.73137 2.5 11.7461 4.51472 11.7461 7ZM10.9253 11.7399C9.90931 12.5297 8.63263 13 7.24609 13C3.93239 13 1.24609 10.3137 1.24609 7C1.24609 3.68629 3.93239 1 7.24609 1C10.5598 1 13.2461 3.68629 13.2461 7C13.2461 8.38653 12.7758 9.66322 11.986 10.6792L15.2764 13.9697L14.2158 15.0303L10.9253 11.7399Z" fill="#262626"></path>
</svg>
						</button>
						<div class="search-border">
							<div id="inner-search-icon">
								<svg role="img" width="17" height="16" viewbox="0 0 17 16" fill="none" xmlns="http://www.w3.org/2000/svg">
<path fill-rule="evenodd" clip-rule="evenodd" d="M11.7461 7C11.7461 9.48528 9.73137 11.5 7.24609 11.5C4.76081 11.5 2.74609 9.48528 2.74609 7C2.74609 4.51472 4.76081 2.5 7.24609 2.5C9.73137 2.5 11.7461 4.51472 11.7461 7ZM10.9253 11.7399C9.90931 12.5297 8.63263 13 7.24609 13C3.93239 13 1.24609 10.3137 1.24609 7C1.24609 3.68629 3.93239 1 7.24609 1C10.5598 1 13.2461 3.68629 13.2461 7C13.2461 8.38653 12.7758 9.66322 11.986 10.6792L15.2764 13.9697L14.2158 15.0303L10.9253 11.7399Z" fill="#262626"></path>
</svg>
							</div>
								<input id="input" type="text" placeholder="Search" title="Search" autocomplete="off" role="combobox" aria-autocomplete="list" aria-expanded="false" aria-label="search input">
							
							<div id="close-search">X</div>
						</div>
					</li>
					<li class="mainItem menuIcon">
						<span class="hamburger"><svg role="img" width="22" height="18" viewbox="0 0 22 18" fill="none" xmlns="http://www.w3.org/2000/svg">
<path fill-rule="evenodd" clip-rule="evenodd" d="M21.5 2.125H0.5V0.625H21.5V2.125ZM21.5 17.625H0.5V16.125H21.5V17.625ZM0.5 9.75H21.5V8.25H0.5V9.75Z" fill="black"></path>
</svg>
</span>
						<span class="close"><svg role="img" width="22" height="22" viewbox="0 0 22 22" fill="none" xmlns="http://www.w3.org/2000/svg">
<path fill-rule="evenodd" clip-rule="evenodd" d="M11.0001 12.0607L20.2197 21.2803L21.2804 20.2197L12.0607 11L21.2804 1.78033L20.2197 0.719675L11.0001 9.93934L1.78039 0.719673L0.719727 1.78033L9.9394 11L0.719727 20.2197L1.78039 21.2803L11.0001 12.0607Z" fill="black"></path>
</svg>
</span>
					</li>
					<li class="navItems">
						<ul class="navItemsContainer">
																														<li class="mainItem home-menu">
									<a class="parentTitle" href="/" target="">
										<span>
											Home										</span>
									</a>
																	</li>
																							<li class="mainItem install-menu">
									<a class="parentTitle" href="/install/install-overview/" target="">
										<span>
											Install										</span>
									</a>
																			<div class="subitems-container">
											<div class="subitems-wrapper">
												<ul class="subItems">
																											<li class="subItem ">
															<a class="link" href="/install/install-overview/" target="">
																<p class="title">Overview</p>
																														</a>
														</li>
																											<li class="subItem ">
															<a class="link" href="/install/install-locally/" target="">
																<p class="title">Install Locally</p>
																														</a>
														</li>
																											<li class="subItem ">
															<a class="link" href="/install/install-mobile/" target="">
																<p class="title">Install Mobile</p>
																														</a>
														</li>
																											<li class="subItem ">
															<a class="link" href="/install/start-with-cloud-partners/" target="">
																<p class="title">Start with Cloud Partners</p>
																														</a>
														</li>
																											<li class="subItem ">
															<a class="link" href="/install/previous-versions/" target="">
																<p class="title">Previous PyTorch Versions</p>
																														</a>
														</li>
																									</ul>
											</div>
										</div>
																	</li>
																							<li class="mainItem features-menu">
									<a class="parentTitle" href="/features/" target="">
										<span>
											Features										</span>
									</a>
																	</li>
																							<li class="mainItem resources-menu">
									<a class="parentTitle" href="/resources/overview/" target="">
										<span>
											Resources										</span>
									</a>
																			<div class="subitems-container">
											<div class="subitems-wrapper">
												<ul class="subItems">
																											<li class="subItem ">
															<a class="link" href="/resources/overview/" target="">
																<p class="title">Overview</p>
																														</a>
														</li>
																											<li class="subItem ">
															<a class="link" href="/resources/blog/" target="">
																<p class="title">Blog</p>
																														</a>
														</li>
																											<li class="subItem ">
															<a class="link" href="/resources/education/" target="">
																<p class="title">Education</p>
																														</a>
														</li>
																											<li class="subItem ">
															<a class="link" href="/resources/localized-docs-tutorials/" target="">
																<p class="title">Localized Docs &#038; Tutorials</p>
																														</a>
														</li>
																											<li class="subItem ">
															<a class="link" href="/resources/enterprise-program/" target="">
																<p class="title">Enterprise Program</p>
																														</a>
														</li>
																									</ul>
											</div>
										</div>
																	</li>
																							<li class="mainItem docs-menu">
									<a class="parentTitle" href="https://pytorch.org/docs/stable/index.html" target="_blank">
										<span>
											Docs										</span>
									</a>
																	</li>
																							<li class="mainItem tutorials-menu">
									<a class="parentTitle" href="https://pytorch.org/tutorials/" target="_blank">
										<span>
											Tutorials										</span>
									</a>
																	</li>
																							<li class="mainItem community-menu">
									<a class="parentTitle" href="/community/overview/" target="">
										<span>
											Community										</span>
									</a>
																			<div class="subitems-container">
											<div class="subitems-wrapper">
												<ul class="subItems">
																											<li class="subItem ">
															<a class="link" href="/community/overview/" target="">
																<p class="title">Overview</p>
																														</a>
														</li>
																											<li class="subItem ">
															<a class="link" href="/community/case-studies/" target="">
																<p class="title">Case Studies</p>
																														</a>
														</li>
																											<li class="subItem ">
															<a class="link" href="/community/ecosystem-tools/" target="">
																<p class="title">Ecosystem Tools</p>
																														</a>
														</li>
																											<li class="subItem ">
															<a class="link" href="/community/events/" target="">
																<p class="title">Events</p>
																														</a>
														</li>
																									</ul>
											</div>
										</div>
																	</li>
														<li class="github mainItem">
								<div class="github-wrapper">
									<a href="https://github.com/pytorch/pytorch" target="_blank" class="parentTitle" aria-label="See Pytorch on GitHub">
										<svg role="img" width="25" height="24" viewbox="0 0 25 24" fill="none" xmlns="http://www.w3.org/2000/svg">
<path d="M23.0227 6.33146C21.9311 4.51257 20.4504 3.07256 18.5803 2.01109C16.7099 0.949571 14.6679 0.418945 12.453 0.418945C10.2384 0.418945 8.19578 0.949733 6.32575 2.01109C4.45545 3.07251 2.97484 4.51257 1.88325 6.33146C0.791831 8.15029 0.246094 10.1365 0.246094 12.2899C0.246094 14.8767 1.02214 17.2029 2.57462 19.2689C4.12694 21.3351 6.1323 22.7648 8.59054 23.5582C8.87669 23.6099 9.08851 23.5736 9.22624 23.4502C9.36403 23.3266 9.43284 23.1719 9.43284 22.9866C9.43284 22.9557 9.43011 22.6776 9.42482 22.152C9.41936 21.6263 9.4168 21.1677 9.4168 20.7765L9.05121 20.838C8.81812 20.8795 8.52407 20.8971 8.16906 20.8921C7.81422 20.8873 7.44584 20.8511 7.06445 20.7839C6.68288 20.7172 6.32798 20.5627 5.99947 20.3205C5.67113 20.0783 5.43803 19.7614 5.30025 19.37L5.14131 19.0143C5.03537 18.7775 4.86858 18.5145 4.64072 18.2261C4.41286 17.9375 4.18244 17.7418 3.94935 17.6388L3.83806 17.5613C3.76391 17.5098 3.6951 17.4477 3.63147 17.3757C3.5679 17.3036 3.5203 17.2315 3.48851 17.1593C3.45667 17.087 3.48305 17.0277 3.56795 16.9812C3.65285 16.9347 3.80628 16.9121 4.0289 16.9121L4.34667 16.9583C4.55861 16.9996 4.82076 17.123 5.13346 17.3292C5.44599 17.5353 5.70291 17.8032 5.90427 18.1328C6.14811 18.5554 6.44188 18.8774 6.78643 19.099C7.13069 19.3206 7.4778 19.4312 7.82741 19.4312C8.17702 19.4312 8.47898 19.4054 8.73339 19.3542C8.98753 19.3026 9.22596 19.2252 9.44859 19.1222C9.54395 18.4315 9.8036 17.9008 10.2273 17.5299C9.62339 17.4682 9.08044 17.3752 8.59817 17.2516C8.11617 17.1279 7.61809 16.927 7.10425 16.6485C6.59013 16.3704 6.16364 16.025 5.82466 15.613C5.48563 15.2008 5.20739 14.6596 4.99033 13.99C4.77316 13.3201 4.66455 12.5473 4.66455 11.6714C4.66455 10.4243 5.08319 9.36302 5.92031 8.48704C5.52816 7.54944 5.56518 6.49837 6.03148 5.33393C6.33878 5.24108 6.7945 5.31076 7.39841 5.54253C8.00244 5.77441 8.44468 5.97305 8.7256 6.13775C9.00651 6.30238 9.23159 6.4419 9.40116 6.55506C10.3868 6.28723 11.404 6.15328 12.4529 6.15328C13.5018 6.15328 14.5192 6.28723 15.5049 6.55506L16.1089 6.18425C16.5219 5.93683 17.0096 5.71009 17.5709 5.50398C18.1325 5.29798 18.562 5.24124 18.8588 5.33409C19.3354 6.49859 19.3779 7.54961 18.9857 8.4872C19.8227 9.36319 20.2415 10.4247 20.2415 11.6715C20.2415 12.5474 20.1325 13.3227 19.9157 13.9977C19.6986 14.6729 19.4179 15.2135 19.0737 15.6208C18.729 16.028 18.2998 16.3706 17.786 16.6487C17.272 16.927 16.7738 17.1278 16.2918 17.2516C15.8096 17.3754 15.2666 17.4684 14.6627 17.5302C15.2135 17.9937 15.4889 18.7254 15.4889 19.725V22.9862C15.4889 23.1715 15.5552 23.3261 15.6878 23.4497C15.8202 23.5731 16.0294 23.6095 16.3155 23.5578C18.7741 22.7644 20.7795 21.3347 22.3317 19.2685C23.8838 17.2024 24.6602 14.8763 24.6602 12.2895C24.6596 10.1363 24.1136 8.15029 23.0227 6.33146Z" fill="#262626"></path>
</svg>
									</a>
								</div>
							</li>
						</ul>
						
<div class="navItems-followContainer followMenu ">
			<div class="mainItem">Follow Us</div>
		<ul class="follow-list">
					<li class="followItem">
				<a aria-label="follow Menu  icon-twitter" href="https://twitter.com/pytorch" target="_blank" class=" icon-twitter">
					Twitter				</a>
			</li>
					<li class="followItem">
				<a aria-label="follow Menu  icon-facebook" href="https://www.facebook.com/pytorch" target="_blank" class=" icon-facebook">
					Facebook				</a>
			</li>
					<li class="followItem">
				<a aria-label="follow Menu  icon-youtube" href="https://www.youtube.com/pytorch" target="_blank" class=" icon-youtube">
					YouTube				</a>
			</li>
					<li class="followItem">
				<a aria-label="follow Menu  icon-linkedin" href="https://www.linkedin.com/company/pytorch" target="_blank" class=" icon-linkedin">
					Linkedin				</a>
			</li>
					<li class="followItem">
				<a aria-label="follow Menu  icon-medium" href="https://medium.com/pytorch" target="_blank" class=" icon-medium">
					Medium				</a>
			</li>
					<li class="followItem">
				<a aria-label="follow Menu  icon-github" href="https://github.com/pytorch/pytorch" target="_blank" class=" icon-github">
					GitHub				</a>
			</li>
			</ul>
</div>
					</li>
				</ul>
			</div>
		</div>
	</header>

	<main id="main" class="site-main" role="main">


<div class="Breadcrumbs">
	<div class="container breadcrumbs-lined">
		<ul class="list-container">
						<li class="breadcrumb-item breadcrumb-active">
				<a class="active-item" href="/blog">Blog</a>
			</li>
						<li class="breadcrumb-item">
				Efficient PyTorch I/O library for Large Datasets, Many Files, Many GPUs			</li>
		</ul>
	</div>
</div>

<div class="BlogHeader ">
	<div class="container">
		<h2 class="title">Efficient PyTorch I/O library for Large Datasets, Many Files, Many GPUs</h2>

		<div class="banner">
			
<img class="Image " src="/wp-content/uploads/2021/08/PyTorch_Blogs@3x-100-1.png" alt="">
		</div>

		<div class="foot">
			<div class="byline">
								<span class="date">August 11, 2020</span>
				<span class="author">by Alex Aizman, Gavin Maltby, Thomas Breuel</span>
			</div>

			
<div class="Share ">
  
  <div class="share-icons">
    
      </div>
</div>
		</div>


	</div>
</div>




<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">Data sets are growing bigger every day and GPUs are getting faster. This means there are more data sets for deep learning researchers and engineers to train and validate their models.</p>
	</div>
</div>


<div class="blog-list-container blog-list-container">
	<div class="container">
		<ul class="list unordered-list indent-con ">
												<li class="item">Many datasets for research in still image recognition are becoming available with 10 million or more images, including OpenImages and Places.								</li>
												<li class="item">million YouTube videos <a href="https://research.google.com/youtube8m/" target="_blank">(YouTube 8M)</a> consume about 300 TB in 720p, used for research in object recognition, video analytics, and action recognition.								</li>
												<li class="item">The Tobacco Corpus consists of about 20 million scanned HD pages, useful for OCR and text analytics research.								</li>
					</ul>
	</div>
</div>




<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">Although the most commonly encountered big data sets right now involve images and videos, big datasets occur in many other domains and involve many other kinds of data types: web pages, financial transactions, network traces, brain scans, etc.<br><br>However, working with the large amount of data sets presents a number of challenges:</p>
	</div>
</div>


<div class="blog-list-container blog-list-container">
	<div class="container">
		<ul class="list unordered-list indent-con ">
												<li class="item">
<strong>Dataset Size:</strong> datasets often exceed the capacity of node-local disk storage, requiring distributed storage systems and efficient network access.								</li>
												<li class="item">
<strong>Number of Files:</strong> datasets often consist of billions of files with uniformly random access patterns, something that often overwhelms both local and network file systems.								</li>
												<li class="item">
<strong>Data Rates:</strong> training jobs on large datasets often use many GPUs, requiring aggregate I/O bandwidths to the dataset of many GBytes/s; these can only be satisfied by massively parallel I/O systems.								</li>
												<li class="item">
<strong>Shuffling and Augmentation:</strong> training data needs to be shuffled and augmented prior to training.								</li>
												<li class="item">
<strong>Scalability:</strong> users often want to develop and test on small datasets and then rapidly scale up to large datasets.								</li>
					</ul>
	</div>
</div>




<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">Traditional local and network file systems, and even object storage servers, are not designed for these kinds of applications. <a href="https://github.com/tmbdev/webdataset" target="_blank">The WebDataset I/O library</a> for PyTorch, together with the optional <a href="https://github.com/NVIDIA/aistore" target="_blank">AIStore server</a> and <a href="https://github.com/NVlabs/tensorcom" target="_blank">Tensorcom</a> RDMA libraries, provide an efficient, simple, and standards-based solution to all these problems. The library is simple enough for day-to-day use, is based on mature open source standards, and is easy to migrate to from existing file-based datasets.<br><br>Using WebDataset is simple and requires little effort, and it will let you scale up the same code from running local experiments to using hundreds of GPUs on clusters or in the cloud with linearly scalable performance. Even on small problems and on your desktop, it can speed up I/O tenfold and simplifies data management and processing of large datasets. The rest of this blog post tells you how to get started with WebDataset and how it works.</p>
	</div>
</div>

<div class="">
<h2 class="HeadingBlock Heading is-style-secondary-heading HeadingBlock  " id="block-f66f4e33-71ae-4938-962e-591995398b33">
		
	THE WEBDATASET LIBRARY</h2>
	</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">The WebDataset library provides a simple solution to the challenges listed above. Currently, it is available as a separate library <a href="https://github.com/tmbdev/webdataset" target="_blank">(github.com/tmbdev/webdataset)</a>, but it is on track for being incorporated into PyTorch (see <a href="https://github.com/pytorch/pytorch/issues/38419" target="_blank">RFC 38419</a>). The WebDataset implementation is small (about 1500 LOC) and has no external dependencies.<br><br>Instead of inventing a new format, WebDataset represents large datasets as collections of POSIX tar archive files consisting of the original data files. The WebDataset library can use such tar archives directly for training, without the need for unpacking or local storage.<br><br>WebDataset scales perfectly from small, local datasets to petascale datasets and training on hundreds of GPUs and allows data to be stored on local disk, on web servers, or dedicated file servers. For container-based training, WebDataset eliminates the need for volume plugins or node-local storage. As an additional benefit, datasets need not be unpacked prior to training, simplifying the distribution and use of research data.<br><br>WebDataset implements PyTorch’s <a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset">IterableDataset</a> interface and can be used like existing DataLoader-based code. Since data is stored as files inside an archive, existing loading and data augmentation code usually requires minimal modification.<br><br>The WebDataset library is a complete solution for working with large datasets and distributed training in PyTorch (and also works with TensorFlow, Keras, and DALI via their Python APIs). Since POSIX tar archives are a standard, widely supported format, it is easy to write other tools for manipulating datasets in this format. E.g., the <a href="https://github.com/tmbdev/tarp" target="_blank">tarp</a> command is written in Go and can shuffle and process training datasets.</p>
	</div>
</div>

<div class="">
<h2 class="HeadingBlock Heading is-style-secondary-heading HeadingBlock  " id="block-4ac46ff1-f1ce-4dbb-8a4c-08e95704b434">
		
	BENEFITS</h2>
	</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">The use of sharded, sequentially readable formats is essential for very large datasets. In addition, it has benefits in many other environments. WebDataset provides a solution that scales well from small problems on a desktop machine to very large deep learning problems in clusters or in the cloud. The following table summarizes some of the benefits in different environments.</p>
	</div>
</div>


<figure class="wp-block-table is-style-stripes"><table class="has-fixed-layout">
<thead><tr>
<th>Environment</th>
<th>Benefits of WebDataset</th>
</tr></thead>
<tbody>
<tr>
<td>Local Cluster with AIStore</td>
<td>AIStore can be deployed easily as K8s containers and offers linear scalability and near 100% utilization of network and I/O bandwidth. Suitable for petascale deep learning.</td>
</tr>
<tr>
<td>Cloud Computing</td>
<td>WebDataset deep learning jobs can be trained directly against datasets stored in cloud buckets; no volume plugins required. Local and cloud jobs work identically. Suitable for petascale learning.</td>
</tr>
<tr>
<td>Local Cluster with existing distributed FS or object store</td>
<td>WebDataset’s large sequential reads improve performance with existing distributed stores and eliminate the need for dedicated volume plugins.</td>
</tr>
<tr>
<td>Educational Environments</td>
<td>WebDatasets can be stored on existing web servers and web caches, and can be accessed directly by students by URL</td>
</tr>
<tr>
<td>Training on Workstations from Local Drives</td>
<td>Jobs can start training as the data still downloads. Data doesn’t need to be unpacked for training. Ten-fold improvements in I/O performance on hard drives over random access file-based datasets.</td>
</tr>
<tr>
<td>All Environments</td>
<td>Datasets are represented in an archival format and contain metadata such as file types. Data is compressed in native formats (JPEG, MP4, etc.). Data management, ETL-style jobs, and data transformations and I/O are simplified and easily parallelized.</td>
</tr>
</tbody>
</table></figure>




<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">We will be adding more examples giving benchmarks and showing how to use WebDataset in these environments over the coming months.</p>
	</div>
</div>

<div class="">
<h2 class="HeadingBlock Heading is-style-secondary-heading HeadingBlock  " id="block-3e02dcc7-b5ed-49b0-ad8a-f8fd5df064c1">
		
	HIGH-PERFORMANCE</h2>
	</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">For high-performance computation on local clusters, the companion open-source <a href="https://github.com/NVIDIA/AIStore" target="_blank">AIStore</a> server provides full disk to GPU I/O bandwidth, subject only to hardware constraints. <a href="https://arxiv.org/abs/2001.01858" target="_blank">This Bigdata 2019 Paper</a> contains detailed benchmarks and performance measurements. In addition to benchmarks, research projects at NVIDIA and Microsoft have used WebDataset for petascale datasets and billions of training samples.<br><br>Below is a benchmark of AIStore with WebDataset clients using 12 server nodes with 10 rotational drives each.</p>
	</div>
</div>


<div class="BlogImage BlogImage">
	<div class="container">
		<div class="imageCon">
			
<img class="Image image" src="/wp-content/uploads/2021/10/pytorchwebdataset1.png" alt="">
		</div>
		<div class="descriptionCon">
					</div>
	</div>
</div>




<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">The left axis shows the aggregate bandwidth from the cluster, while the right scale shows the measured per drive I/O bandwidth. WebDataset and AIStore scale linearly to about 300 clients, at which point they are increasingly limited by the maximum I/O bandwidth available from the rotational drives (about 150 MBytes/s per drive). For comparison, HDFS is shown. HDFS uses a similar approach to AIStore/WebDataset and also exhibits linear scaling up to about 192 clients; at that point, it hits a performance limit of about 120 MBytes/s per drive, and it failed when using more than 1024 clients. Unlike HDFS, the WebDataset-based code just uses standard URLs and HTTP to access data and works identically with local files, with files stored on web servers, and with AIStore. For comparison, NFS in similar experiments delivers about 10-20 MBytes/s per drive.</p>
	</div>
</div>

<div class="">
<h2 class="HeadingBlock Heading is-style-secondary-heading HeadingBlock  " id="block-156d5ad5-9cf7-4338-adf1-4121e0bf07d2">
		
	STORING DATASETS IN TAR ARCHIVES</h2>
	</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">The format used for WebDataset is standard POSIX tar archives, the same archives used for backup and data distribution. In order to use the format to store training samples for deep learning, we adopt some simple naming conventions:</p>
	</div>
</div>


<div class="blog-list-container blog-list-container">
	<div class="container">
		<ul class="list unordered-list indent-con ">
												<li class="item">datasets are POSIX tar archives								</li>
												<li class="item">each training sample consists of adjacent files with the same basename								</li>
												<li class="item">shards are numbered consecutively								</li>
					</ul>
	</div>
</div>




<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">For example, ImageNet is stored in 1282 separate 100 Mbyte shards with names <code>pythonimagenet-train-000000.tar to imagenet-train-001281.tar,</code> the contents of the first shard are:</p>
	</div>
</div>

<div class="code-block">
<pre class="wp-block-code"><code lang="bash" class="language-bash">-r--r--r-- bigdata/bigdata      3 2020-05-08 21:23 n03991062_24866.cls
-r--r--r-- bigdata/bigdata 108611 2020-05-08 21:23 n03991062_24866.jpg
-r--r--r-- bigdata/bigdata      3 2020-05-08 21:23 n07749582_9506.cls
-r--r--r-- bigdata/bigdata 129044 2020-05-08 21:23 n07749582_9506.jpg
-r--r--r-- bigdata/bigdata      3 2020-05-08 21:23 n03425413_23604.cls
-r--r--r-- bigdata/bigdata 106255 2020-05-08 21:23 n03425413_23604.jpg
-r--r--r-- bigdata/bigdata      3 2020-05-08 21:23 n02795169_27274.cls</code></pre>
</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">WebDataset datasets can be used directly from local disk, from web servers (hence the name), from cloud storage and object stores, just by changing a URL. WebDataset datasets can be used for training without unpacking, and training can even be carried out on streaming data, with no local storage.<br><br>Shuffling during training is important for many deep learning applications, and WebDataset performs shuffling both at the shard level and at the sample level. Splitting of data across multiple workers is performed at the shard level using a user-provided <code>shard_selection</code> function that defaults to a function that splits based on <code>get_worker_info.</code> (WebDataset can be combined with the <a href="https://github.com/NVLabs/tensorcom" target="_blank">tensorcom</a> library to offload decompression/data augmentation and provide RDMA and direct-to-GPU loading; see below.)</p>
	</div>
</div>

<div class="">
<h2 class="HeadingBlock Heading is-style-secondary-heading HeadingBlock  " id="block-fe44a635-3292-47b8-9d7e-c7747d7b32e6">
		
	CODE SAMPLE</h2>
	</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">Here are some code snippets illustrating the use of WebDataset in a typical PyTorch deep learning application (you can find a full example at <a href="http://github.com/tmbdev/pytorch-imagenet-wds" target="_blank">http://github.com/tmbdev/pytorch-imagenet-wds</a>.</p>
	</div>
</div>

<div class="code-block">
<pre class="wp-block-code"><code lang="wasm" class="language-wasm">import webdataset as wds
import ...

sharedurl = "/imagenet/imagenet-train-{000000..001281}.tar"

normalize = transforms.Normalize(
  mean=[0.485, 0.456, 0.406],
  std=[0.229, 0.224, 0.225])

preproc = transforms.Compose([
  transforms.RandomResizedCrop(224),
  transforms.RandomHorizontalFlip(),
  transforms.ToTensor(),
  normalize,
])

dataset = (
  wds.Dataset(sharedurl)
  .shuffle(1000)
  .decode("pil")
  .rename(image="jpg;png", data="json")
  .map_dict(image=preproc)
  .to_tuple("image", "data")
)

loader = torch.utils.data.DataLoader(dataset, batch_size=64, num_workers=8)

for inputs, targets in loader:
  ...</code></pre>
</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">This code is nearly identical to the file-based I/O pipeline found in the PyTorch Imagenet example: it creates a preprocessing/augmentation pipeline, instantiates a dataset using that pipeline and a data source location, and then constructs a DataLoader instance from the dataset.<br><br>WebDataset uses a fluent API for a configuration that internally builds up a processing pipeline. Without any added processing stages, In this example, WebDataset is used with the PyTorch DataLoader class, which replicates DataSet instances across multiple threads and performs both parallel I/O and parallel data augmentation.<br><br>WebDataset instances themselves just iterate through each training sample as a dictionary:</p>
	</div>
</div>

<div class="code-block">
<pre class="wp-block-code"><code lang="bash" class="language-bash"># load from a web server using a separate client process
sharedurl = "pipe:curl -s http://server/imagenet/imagenet-train-{000000..001281}.tar"

dataset = wds.Dataset(sharedurl)

for sample in dataset:
  # sample["jpg"] contains the raw image data
  # sample["cls"] contains the class
  ...</code></pre>
</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">For a general introduction to how we handle large scale training with WebDataset, see these <a href="https://www.youtube.com/playlist?list=PL0dsKxFNMcX4XcB0w1Wm-pvSfQu-eWM26" target="_blank">YouTube videos</a>.</p>
	</div>
</div>

<div class="">
<h2 class="HeadingBlock Heading is-style-secondary-heading HeadingBlock  " id="block-0a5843b1-291c-4b6e-8c84-d9a1c3988ad3">
		
	RELATED SOFTWARE</h2>
	</div>


<div class="blog-list-container blog-list-container">
	<div class="container">
		<ul class="list unordered-list indent-con ">
												<li class="item">
<a href="https://github.com/NVIDIA/AIStore" target="_blank">AIStore</a> is an open-source object store capable of full-bandwidth disk-to-GPU data delivery (meaning that if you have 1000 rotational drives with 200 MB/s read speed, AIStore actually delivers an aggregate bandwidth of 200 GB/s to the GPUs). AIStore is fully compatible with WebDataset as a client, and in addition understands the WebDataset format, permitting it to perform shuffling, sorting, ETL, and some map-reduce operations directly in the storage system. AIStore can be thought of as a remix of a distributed object store, a network file system, a distributed database, and a GPU-accelerated map-reduce implementation.								</li>
												<li class="item">
<a href="https://github.com/tmbdev/tarp" target="_blank">tarp</a> is a small command-line program for splitting, merging, shuffling, and processing tar archives and WebDataset datasets.								</li>
												<li class="item">
<a href="https://github.com/NVLabs/tensorcom" target="_blank">tensorcom</a> is a library supporting distributed data augmentation and RDMA to GPU.								</li>
												<li class="item">
<a href="https://github.com/tmbdev/pytorch-imagenet-wds" target="_blank">pytorch-imagenet-wds</a> contains an example of how to use WebDataset with ImageNet, based on the PyTorch ImageNet example.								</li>
												<li class="item">
<a href="https://arxiv.org/abs/2001.01858" target="_blank">Bigdata 2019 Paper with Benchmarks</a>								</li>
					</ul>
	</div>
</div>




<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">Check out <a href="https://github.com/tmbdev/webdataset" target="_blank">the library</a> and provide your feedback for <a href="https://github.com/pytorch/pytorch/issues/38419" target="_blank">RFC 38419</a>.</p>
	</div>
</div>	</main>

	<footer class="Footer">
		<div class="mainNav">
			<div class="logo">
				<a href="/" aria-label="Go to Pytorch home">
					<svg width="30" height="35" viewbox="0 0 30 35" fill="none" xmlns="http://www.w3.org/2000/svg" role="img">
<path d="M24.8384 10.3748L22.3344 12.8296C26.5077 16.9211 26.5077 23.5842 22.3344 27.6757C18.1612 31.7671 11.3647 31.7671 7.19148 27.6757C3.01823 23.5842 3.01823 16.9211 7.19148 12.8296L13.8687 6.28337L14.7033 5.34818V0.438477L4.56829 10.3748C-1.03579 15.869 -1.03579 24.6363 4.56829 30.1305C10.1724 35.6247 19.1151 35.6247 24.7191 30.1305C30.4424 24.6363 30.4424 15.7521 24.8384 10.3748Z" fill="#F05F42"></path>
<ellipse cx="19.8316" cy="7.80298" rx="1.90777" ry="1.87036" fill="#F05F42"></ellipse>
</svg>
				</a>
			</div>

			<ul class="footerNav">
													<li class="mainItem">
						<a href="#" target="" class="footer-item  ">
							PyTorch						</a>
													<ul>
																	<li class="subItem">
										<a href="/install/" target="" class=" ">
											Install										</a>
																			</li>
																	<li class="subItem">
										<a href="/features/" target="" class=" ">
											Features										</a>
																			</li>
																	<li class="subItem">
										<a href="/resources/" target="" class=" ">
											Resources										</a>
																			</li>
																	<li class="subItem">
										<a href="https://pytorch.org/docs/stable/index.html" target="" class="docs ">
											Docs										</a>
																			</li>
																	<li class="subItem">
										<a href="https://pytorch.org/tutorials/" target="" class="tutorials ">
											Tutorials										</a>
																			</li>
																	<li class="subItem">
										<a href="/community/" target="" class=" ">
											Community										</a>
																			</li>
																	<li class="subItem">
										<a href="https://github.com/pytorch/pytorch" target="" class=" ">
											Github										</a>
																			</li>
															</ul>
											</li>
									<li class="mainItem">
						<a href="#" target="" class="footer-item  ">
							Support						</a>
													<ul>
																	<li class="subItem">
										<a href="https://github.com/pytorch/pytorch/issues" target="_blank" class=" icon-github">
											Github Issues										</a>
																			</li>
																	<li class="subItem">
										<a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank" class=" ">
											Brand Guidelines										</a>
																			</li>
																	<li class="subItem">
										<a href="https://discuss.pytorch.org/" target="_blank" class=" ">
											Discuss										</a>
																			</li>
															</ul>
											</li>
								<li class="mainItem">
					
<div class="navItems-followContainer followMenu ">
			<div class="mainItem">Follow Us</div>
		<ul class="follow-list">
					<li class="followItem">
				<a aria-label="follow Menu  icon-twitter" href="https://twitter.com/pytorch" target="_blank" class=" icon-twitter">
					Twitter				</a>
			</li>
					<li class="followItem">
				<a aria-label="follow Menu  icon-facebook" href="https://www.facebook.com/pytorch" target="_blank" class=" icon-facebook">
					Facebook				</a>
			</li>
					<li class="followItem">
				<a aria-label="follow Menu  icon-youtube" href="https://www.youtube.com/pytorch" target="_blank" class=" icon-youtube">
					YouTube				</a>
			</li>
					<li class="followItem">
				<a aria-label="follow Menu  icon-linkedin" href="https://www.linkedin.com/company/pytorch" target="_blank" class=" icon-linkedin">
					Linkedin				</a>
			</li>
					<li class="followItem">
				<a aria-label="follow Menu  icon-medium" href="https://medium.com/pytorch" target="_blank" class=" icon-medium">
					Medium				</a>
			</li>
					<li class="followItem">
				<a aria-label="follow Menu  icon-github" href="https://github.com/pytorch/pytorch" target="_blank" class=" icon-github">
					GitHub				</a>
			</li>
			</ul>
</div>
				</li>
			</ul>
		</div>
		<div class="legalNav">
			<ul class="legalNavList">
													<li>
						<a href="/wp-content/uploads/2021/11/fb-tos-privacy-policy.pdf" target="" class=" ">
							Terms						</a>
					</li>
									<li>
						<a href="/wp-content/uploads/2021/11/fb-oss-privacy-policy.pdf" target="" class=" ">
							Privacy						</a>
					</li>
							</ul>
		</div>
	</footer>
</div>

<script id="pytorch-classic-js-js-extra">
var gridData = {"build":{"stable":"Stable (1.9.0)","nightly":"Preview (Nightly)","lts":"LTS (1.8.1)"},"os":{"mac":"MacOS","linux":"Linux","windows":"Windows"},"package":{"conda":"Conda","pip":"Pip","libtorch":"LibTorch","source":"Source"},"language":{"python":"Python","cplusplus":"C++\/Java"},"platform":{"cuda10.2":"CUDA 10.2","cuda11.1":"CUDA 11.1","rocm":"ROCm 4.2(beta)","cpu":"CPU"}};
var platformOSSupport = {"linux":["cuda10.2","rocm","cpu"],"mac":["cpu"],"windows":["cuda10.2","rocm","cpu"]};
var packageLanguageSupport = {"python":["pip","conda","source"],"cplusplus":["libtorch"]};
var commands = {"stable,conda,mac,cpu,python":"conda install pytorch torchvision torchaudio -c pytorch","nightly,conda,linux,cpu,python":"conda install pytorch torchvision torchaudio cpuonly -c pytorch-nightly","stable,libtorch,windows,rocm,cplusplus":"NOTE: ROCm is not available on Windows","stable,conda,windows,cpu,python":"conda install pytorch torchvision torchaudio cpuonly -c pytorch-nightly","stable,conda,windows,rocm,python":"NOTE: ROCm is not available on Windows","stable,pip,windows,rocm,python":"NOTE: ROCm is not available on Windows","stable,pip,windows,cpu,python":"pip3 install --pre torch torchvision torchaudio -f https:\/\/download.pytorch.org\/whl\/nightly\/cpu\/torch_nightly.html","stable,conda,windows,cuda10.2,python":"conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch-nightly","stable,conda,windows,cuda11.1,python":"NOTE: \\'conda-forge\\' channel is required for cudatoolkit 11.1\r\nconda install pytorch torchvision torchaudio cudatoolkit=11.1 -c pytorch-nightly -c conda-forge","stable,libtorch,mac,rocm,cplusplus":"NOTE: ROCm is not available on MacOS","stable,conda,mac,rocm,python":"NOTE: ROCm is not available on MacOS","stable,conda,linux,cpu,python":"conda install pytorch torchvision torchaudio cpuonly -c pytorch","stable,conda,linux,rocm,python":"NOTE: Conda packages are not currently available for ROCm, please use pip instead","stable,conda,linux,cuda10.2,python":"conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch","stable,conda,linux,cuda11.1,python":"NOTE: \\'nvidia\\' channel is required for cudatoolkit 11.1\r\nconda install pytorch torchvision torchaudio cudatoolkit=11.1 -c pytorch -c nvidia","lts,libtorch,windows,rocm,cplusplus":"NOTE: ROCm is not supported in LTS","lts,pip,mac,cpu,python":"# macOS is not currently supported for lts","lts,conda,mac,cuda10.2,python":"# macOS is not currently supported for lts","lts,conda,mac,cuda11.1,python":"# macOS is not currently supported for lts","lts,conda,mac,rocm,python":"# macOS is not currently supported for lts","lts,conda,mac,cpu,python":"# macOS is not currently supported for lts","stable,conda,mac,cuda10.2,python":"# MacOS Binaries dont support CUDA, install from source if CUDA is needed\r\nconda install pytorch torchvision torchaudio -c pytorch","lts,libtorch,mac,cpu,cplusplus":"# macOS is not currently supported for lts","lts,libtorch,mac,cuda10.2,cplusplus":"# macOS is not currently supported for lts","lts,libtorch,mac,cuda11.1,cplusplus":"# macOS is not currently supported for lts","lts,libtorch,mac,rocm,cplusplus":"# macOS is not currently supported for lts","lts,pip,windows,rocm,python":"NOTE: ROCm is not supported in LTS","stable,libtorch,linux,cpu,cplusplus":"Download here (Pre-cxx11 ABI):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/cpu\/libtorch-shared-with-deps-1.9.1%2Bcpu.zip\">https:\/\/download.pytorch.org\/libtorch\/cpu\/libtorch-shared-with-deps-1.9.1%2Bcpu.zip<\/a>\r\nDownload here (cxx11 ABI):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/cpu\/libtorch-cxx11-abi-shared-with-deps-1.9.1%2Bcpu.zip\">https:\/\/download.pytorch.org\/libtorch\/cpu\/libtorch-cxx11-abi-shared-with-deps-1.9.1%2Bcpu.zip<\/a>","stable,pip,linux,cpu,python":"pip3 install --pre torch torchvision torchaudio -f https:\/\/download.pytorch.org\/whl\/nightly\/cpu\/torch_nightly.html","stable,pip,linux,cuda11.1,python":"pip3 install torch==1.9.1+cu111 torchvision==0.10.1+cu111 torchaudio==0.9.1 -f https:\/\/download.pytorch.org\/whl\/torch_stable.html","stable,pip,linux,cuda10.2,python":"pip3 install torch torchvision torchaudio","stable,pip,linux,rocm,python":"pip3 install torch torchvision==0.10.1 -f https:\/\/download.pytorch.org\/whl\/rocm4.2\/torch_stable.html","stable,libtorch,linux,cuda10.2,cplusplus":"Download here (Pre-cxx11 ABI):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/cu102\/libtorch-shared-with-deps-1.9.1%2Bcu102.zip\">https:\/\/download.pytorch.org\/libtorch\/cu102\/libtorch-shared-with-deps-1.9.1%2Bcu102.zip<\/a>\r\nDownload here (cxx11 ABI):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/cu102\/libtorch-cxx11-abi-shared-with-deps-1.9.1%2Bcu102.zip\">https:\/\/download.pytorch.org\/libtorch\/cu102\/libtorch-cxx11-abi-shared-with-deps-1.9.1%2Bcu102.zip<\/a>","stable,libtorch,linux,cuda11.1,cplusplus":"Download here (Pre-cxx11 ABI):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/cu111\/libtorch-shared-with-deps-1.9.1%2Bcu111.zip\">https:\/\/download.pytorch.org\/libtorch\/cu111\/libtorch-shared-with-deps-1.9.1%2Bcu111.zip<\/a>\r\nDownload here (cxx11 ABI):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/cu111\/libtorch-cxx11-abi-shared-with-deps-1.9.1%2Bcu111.zip\">https:\/\/download.pytorch.org\/libtorch\/cu111\/libtorch-cxx11-abi-shared-with-deps-1.9.1%2Bcu111.zip<\/a>","stable,libtorch,linux,rocm,cplusplus":"LibTorch binaries are not available for ROCm, please build it from source","stable,pip,mac,cuda10.2,python":"# MacOS Binaries dont support CUDA, install from source if CUDA is needed\r\npip3 install torch torchvision torchaudio","stable,pip,mac,cuda11.1,python":"# MacOS Binaries dont support CUDA, install from source if CUDA is needed\r\npip3 install torch torchvision torchaudio","stable,pip,mac,rocm,python":"NOTE: ROCm is not available on MacOS","stable,pip,mac,cpu,python":"pip3 install torch torchvision torchaudio","stable,conda,mac,cuda11.1,python":"# MacOS Binaries dont support CUDA, install from source if CUDA is needed\r\nconda install pytorch torchvision torchaudio -c pytorch","stable,libtorch,mac,cpu,cplusplus":"Download here:\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/cpu\/libtorch-macos-1.9.1.zip\">https:\/\/download.pytorch.org\/libtorch\/cpu\/libtorch-macos-1.9.1.zip<\/a>","stable,libtorch,mac,cuda10.2,cplusplus":"MacOS binaries do not support CUDA. Download CPU libtorch here:\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/cpu\/libtorch-macos-1.9.1.zip\">https:\/\/download.pytorch.org\/libtorch\/cpu\/libtorch-macos-1.9.1.zip<\/a>","stable,libtorch,mac,cuda11.1,cplusplus":"MacOS binaries do not support CUDA. Download CPU libtorch here:\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/cpu\/libtorch-macos-1.9.1.zip\">https:\/\/download.pytorch.org\/libtorch\/cpu\/libtorch-macos-1.9.1.zip<\/a>","stable,libtorch,windows,cuda11.1,python":"Download here (Release version):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/cu111\/libtorch-win-shared-with-deps-1.9.1%2Bcu111.zip\">https:\/\/download.pytorch.org\/libtorch\/cu111\/libtorch-win-shared-with-deps-1.9.1%2Bcu111.zip<\/a>\r\nDownload here (Debug version):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/cu111\/libtorch-win-shared-with-deps-debug-1.9.1%2Bcu111.zip\">https:\/\/download.pytorch.org\/libtorch\/cu111\/libtorch-win-shared-with-deps-debug-1.9.1%2Bcu111.zip<\/a>","stable,libtorch,windows,cuda10.2,cplusplus":"Download here (Release version):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/nightly\/cu102\/libtorch-win-shared-with-deps-latest.zip\">https:\/\/download.pytorch.org\/libtorch\/nightly\/cu102\/libtorch-win-shared-with-deps-latest.zip<\/a>\r\nDownload here (Debug version):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/nightly\/cu102\/libtorch-win-shared-with-deps-debug-latest.zip\">https:\/\/download.pytorch.org\/libtorch\/nightly\/cu102\/libtorch-win-shared-with-deps-debug-latest.zip<\/a>","stable,libtorch,windows,cpu,cplusplus":"Download here (Release version):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/nightly\/cpu\/libtorch-win-shared-with-deps-latest.zip\">https:\/\/download.pytorch.org\/libtorch\/nightly\/cpu\/libtorch-win-shared-with-deps-latest.zip<\/a>\r\nDownload here (Debug version):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/nightly\/cpu\/libtorch-win-shared-with-deps-debug-latest.zip\">https:\/\/download.pytorch.org\/libtorch\/nightly\/cpu\/libtorch-win-shared-with-deps-debug-latest.zip<\/a>","stable,pip,windows,cuda11.1,python":"pip3 install --pre torch torchvision torchaudio -f https:\/\/download.pytorch.org\/whl\/nightly\/cu111\/torch_nightly.html","stable,pip,windows,cuda10.2,python":"pip3 install --pre torch torchvision torchaudio -f https:\/\/download.pytorch.org\/whl\/nightly\/cu102\/torch_nightly.html","stable,libtorch,windows,cuda11.1,cplusplus":"Download here (Release version):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/nightly\/cu111\/libtorch-win-shared-with-deps-latest.zip\">https:\/\/download.pytorch.org\/libtorch\/nightly\/cu111\/libtorch-win-shared-with-deps-latest.zip<\/a>\r\nDownload here (Debug version):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/nightly\/cu111\/libtorch-win-shared-with-deps-debug-latest.zip\">https:\/\/download.pytorch.org\/libtorch\/nightly\/cu111\/libtorch-win-shared-with-deps-debug-latest.zip<\/a>","lts,pip,linux,cpu,python":"pip3 install torch==1.8.2+cpu torchvision==0.9.2+cpu torchaudio==0.8.2 -f https:\/\/download.pytorch.org\/whl\/lts\/1.8\/torch_lts.html","lts,pip,linux,cuda10.2,python":"pip3 install torch==1.8.2+cu102 torchvision==0.9.2+cu102 torchaudio==0.8.2 -f https:\/\/download.pytorch.org\/whl\/lts\/1.8\/torch_lts.html","lts,pip,linux,cuda11.1,python":"pip3 install torch==1.8.2+cu111 torchvision==0.9.2+cu111 torchaudio==0.8.2 -f https:\/\/download.pytorch.org\/whl\/lts\/1.8\/torch_lts.html","lts,pip,linux,rocm,python":"NOTE: ROCm is not supported in LTS","lts,conda,linux,cuda10.2,python":"conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch-lts","lts,conda,linux,cuda11.1,python":"NOTE: \\'nvidia\\' channel is required for cudatoolkit 11.1\r\nconda install pytorch torchvision torchaudio cudatoolkit=11.1 -c pytorch-lts -c nvidia","lts,conda,linux,rocm,python":"NOTE: ROCm is not supported in LTS","lts,conda,linux,cpu,python":"conda install pytorch torchvision torchaudio cpuonly -c pytorch-lts","lts,libtorch,linux,cpu,cplusplus":"Download here (Pre-cxx11 ABI):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cpu\/libtorch-shared-with-deps-1.8.2%2Bcpu.zip\">https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cpu\/libtorch-shared-with-deps-1.8.2%2Bcpu.zip<\/a>\r\nDownload here (cxx11 ABI):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cpu\/libtorch-cxx11-abi-shared-with-deps-1.8.2%2Bcpu.zip\">https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cpu\/libtorch-cxx11-abi-shared-with-deps-1.8.2%2Bcpu.zip<\/a>","lts,libtorch,linux,cuda10.2,cplusplus":"Download here (Pre-cxx11 ABI):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu102\/libtorch-shared-with-deps-1.8.2%2Bcu102.zip\">https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu102\/libtorch-shared-with-deps-1.8.2%2Bcu102.zip<\/a>\r\nDownload here (cxx11 ABI):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu102\/libtorch-cxx11-abi-shared-with-deps-1.8.2%2Bcu102.zip\">https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu102\/libtorch-cxx11-abi-shared-with-deps-1.8.2%2Bcu102.zip<\/a>","lts,libtorch,linux,cuda11.1,cplusplus":"Download here (Pre-cxx11 ABI):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu111\/libtorch-shared-with-deps-1.8.2%2Bcu111.zip\">https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu111\/libtorch-shared-with-deps-1.8.2%2Bcu111.zip<\/a>\r\nDownload here (cxx11 ABI):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu111\/libtorch-cxx11-abi-shared-with-deps-1.8.2%2Bcu111.zip\">https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu111\/libtorch-cxx11-abi-shared-with-deps-1.8.2%2Bcu111.zip<\/a>","lts,libtorch,linux,rocm,python":"NOTE: ROCm is not supported in LTS","lts,pip,mac,cuda10.2,python":"# macOS is not currently supported for lts","lts,pip,mac,cuda11.1,python":"# macOS is not currently supported for lts","lts,pip,mac,rocm,python":"# macOS is not currently supported for lts","lts,pip,windows,cpu,python":"pip3 install torch==1.8.2+cpu torchvision==0.9.2+cpu torchaudio===0.8.2 -f https:\/\/download.pytorch.org\/whl\/lts\/1.8\/torch_lts.html","lts,pip,windows,cuda10.2,python":"pip3 install torch==1.8.2+cu102 torchvision==0.9.2+cu102 torchaudio===0.8.2 -f https:\/\/download.pytorch.org\/whl\/lts\/1.8\/torch_lts.html","lts,pip,windows,cuda11.1,python":"pip3 install torch==1.8.2+cu111 torchvision==0.9.2+cu111 torchaudio===0.8.2 -f https:\/\/download.pytorch.org\/whl\/lts\/1.8\/torch_lts.html","lts,conda,windows,cuda10.2,python":"conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch-lts","lts,conda,windows,cuda11.1,python":"NOTE: \\'conda-forge\\' channel is required for cudatoolkit 11.1\r\nconda install pytorch torchvision torchaudio cudatoolkit=11.1 -c pytorch-lts -c conda-forge","lts,conda,windows,cpu,python":"conda install pytorch torchvision torchaudio cpuonly -c pytorch-lts","lts,conda,windows,rocm,python":"NOTE: ROCm is not supported in LTS","lts,libtorch,windows,cpu,cplusplus":"Download here (Release version):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cpu\/libtorch-win-shared-with-deps-1.8.2%2Bcpu.zip\">https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cpu\/libtorch-win-shared-with-deps-1.8.2%2Bcpu.zip<\/a>\r\nDownload here (Debug version):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cpu\/libtorch-win-shared-with-deps-debug-1.8.2%2Bcpu.zip\">https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cpu\/libtorch-win-shared-with-deps-debug-1.8.2%2Bcpu.zip<\/a>","lts,libtorch,windows,cuda10.2,cplusplus":"Download here (Release version):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu102\/libtorch-win-shared-with-deps-1.8.2%2Bcu102.zip\">https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu102\/libtorch-win-shared-with-deps-1.8.2%2Bcu102.zip<\/a>\r\nDownload here (Debug version):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu102\/libtorch-win-shared-with-deps-debug-1.8.2%2Bcu102.zip\">https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu102\/libtorch-win-shared-with-deps-debug-1.8.2%2Bcu102.zip<\/a>","lts,libtorch,windows,cuda11.1,cplusplus":"Download here (Release version):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu111\/libtorch-win-shared-with-deps-1.8.2%2Bcu111.zip\">https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu111\/libtorch-win-shared-with-deps-1.8.2%2Bcu111.zip<\/a>\r\nDownload here (Debug version):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu111\/libtorch-win-shared-with-deps-debug-1.8.2%2Bcu111.zip\">https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu111\/libtorch-win-shared-with-deps-debug-1.8.2%2Bcu111.zip<\/a>"};
</script>
<script src="/wp-content/themes/pytorch/assets/js/index.bundle.js?ver=1" id="pytorch-classic-js-js"></script>
<script src="/wp-content/themes/pytorch/assets/js/blog-header.bundle.js?ver=1" id="pytorch-blog-header-js"></script>
<script src="/wp-content/themes/pytorch/assets/js/blog-text.bundle.js?ver=1" id="pytorch-blog-text-js"></script>
<script src="/wp-content/themes/pytorch/assets/js/blog-list.bundle.js?ver=1" id="pytorch-blog-list-js"></script>
<script src="/wp-content/themes/pytorch/assets/js/heading.bundle.js?ver=1" id="pytorch-heading-js"></script>
<script src="/wp-content/themes/pytorch/assets/js/blog-image.bundle.js?ver=1" id="pytorch-blog-image-js"></script>
<script id="mkaz-code-syntax-prism-js-js-extra">
var prism_settings = {"pluginUrl":"\/wp-content\/plugins\/code-syntax-block\/"};
</script>
<script src="/wp-content/plugins/code-syntax-block/assets/prism/prism.js?ver=1641826791" id="mkaz-code-syntax-prism-js-js"></script>
<script src="/wp-content/plugins/simply-static-pro/assets/fuse.js?ver=1.1" id="ssp-fuse-js"></script>
<script src="/wp-content/plugins/simply-static-pro/assets/ssp-search.js?ver=1.1" id="ssp-search-js"></script>
<script src="https://stats.wp.com/e-202203.js" defer></script>
<script>
	_stq = window._stq || [];
	_stq.push([ 'view', {v:'ext',j:'1:10.4',blog:'195752808',post:'1001',tz:'0',srv:'pytorch-org-preprod.go-vip.net'} ]);
	_stq.push([ 'clickTrackerInit', '195752808', '1001' ]);
</script>

</body>
</html>