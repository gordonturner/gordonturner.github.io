<!DOCTYPE html>
<html lang="en-US">
<head>
  <title> How Computational Graphs are Constructed in PyTorch</title>
	<!-- Google Tag Manager -->
	<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
	new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
	j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
	'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
	})(window,document,'script','dataLayer','GTM-52DXT37');</script>
	<!-- End Google Tag Manager -->
	<!-- Docsearch -->
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css">
	<script src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script>
	<!-- End Docsearch -->

	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta name="robots" content="max-image-preview:large">
<link rel="dns-prefetch" href="//s.w.org">
<link rel="alternate" type="application/rss+xml" title="pytorch-org-preprod.go-vip.net &raquo; How Computational Graphs are Constructed in PyTorch Comments Feed" href="/how-computational-graphs-are-constructed-in-pytorch/feed/">
		<script type="text/javascript">
			window._wpemojiSettings = {"baseUrl":"https:\/\/s.w.org\/images\/core\/emoji\/13.0.1\/72x72\/","ext":".png","svgUrl":"https:\/\/s.w.org\/images\/core\/emoji\/13.0.1\/svg\/","svgExt":".svg","source":{"concatemoji":"\/wp-includes\/js\/wp-emoji-release.min.js?ver=5.7.5"}};
			!function(e,a,t){var n,r,o,i=a.createElement("canvas"),p=i.getContext&&i.getContext("2d");function s(e,t){var a=String.fromCharCode;p.clearRect(0,0,i.width,i.height),p.fillText(a.apply(this,e),0,0);e=i.toDataURL();return p.clearRect(0,0,i.width,i.height),p.fillText(a.apply(this,t),0,0),e===i.toDataURL()}function c(e){var t=a.createElement("script");t.src=e,t.defer=t.type="text/javascript",a.getElementsByTagName("head")[0].appendChild(t)}for(o=Array("flag","emoji"),t.supports={everything:!0,everythingExceptFlag:!0},r=0;r<o.length;r++)t.supports[o[r]]=function(e){if(!p||!p.fillText)return!1;switch(p.textBaseline="top",p.font="600 32px Arial",e){case"flag":return s([127987,65039,8205,9895,65039],[127987,65039,8203,9895,65039])?!1:!s([55356,56826,55356,56819],[55356,56826,8203,55356,56819])&&!s([55356,57332,56128,56423,56128,56418,56128,56421,56128,56430,56128,56423,56128,56447],[55356,57332,8203,56128,56423,8203,56128,56418,8203,56128,56421,8203,56128,56430,8203,56128,56423,8203,56128,56447]);case"emoji":return!s([55357,56424,8205,55356,57212],[55357,56424,8203,55356,57212])}return!1}(o[r]),t.supports.everything=t.supports.everything&&t.supports[o[r]],"flag"!==o[r]&&(t.supports.everythingExceptFlag=t.supports.everythingExceptFlag&&t.supports[o[r]]);t.supports.everythingExceptFlag=t.supports.everythingExceptFlag&&!t.supports.flag,t.DOMReady=!1,t.readyCallback=function(){t.DOMReady=!0},t.supports.everything||(n=function(){t.readyCallback()},a.addEventListener?(a.addEventListener("DOMContentLoaded",n,!1),e.addEventListener("load",n,!1)):(e.attachEvent("onload",n),a.attachEvent("onreadystatechange",function(){"complete"===a.readyState&&t.readyCallback()})),(n=t.source||{}).concatemoji?c(n.concatemoji):n.wpemoji&&n.twemoji&&(c(n.twemoji),c(n.wpemoji)))}(window,document,window._wpemojiSettings);
		</script>
		<style type="text/css">img.wp-smiley,
img.emoji {
	display: inline !important;
	border: none !important;
	box-shadow: none !important;
	height: 1em !important;
	width: 1em !important;
	margin: 0 .07em !important;
	vertical-align: -0.1em !important;
	background: none !important;
	padding: 0 !important;
}</style>
	<link rel="stylesheet" id="pytorch-classic-style-css" href="/wp-content/themes/pytorch/assets/css/index.css?ver=1" media="all">
<link rel="stylesheet" id="pytorch-blog-header-css" href="/wp-content/themes/pytorch/assets/css/blog-header.css?ver=1" media="all">
<link rel="stylesheet" id="pytorch-blog-text-css" href="/wp-content/themes/pytorch/assets/css/blog-text.css?ver=1" media="all">
<link rel="stylesheet" id="pytorch-heading-css" href="/wp-content/themes/pytorch/assets/css/heading.css?ver=1" media="all">
<link rel="stylesheet" id="pytorch-blog-image-css" href="/wp-content/themes/pytorch/assets/css/blog-image.css?ver=1" media="all">
<link rel="stylesheet" id="mediaelement-css" href="/wp-includes/js/mediaelement/mediaelementplayer-legacy.min.css?ver=4.2.16" media="all">
<link rel="stylesheet" id="wp-mediaelement-css" href="/wp-includes/js/mediaelement/wp-mediaelement.min.css?ver=5.7.5" media="all">
<link rel="stylesheet" id="mkaz-code-syntax-prism-css-css" href="/wp-content/plugins/code-syntax-block/assets/prism-ghcolors.css?ver=1641826791" media="all">
<link rel="stylesheet" id="ssp-search-css" href="/wp-content/plugins/simply-static-pro/assets/ssp-search.css?ver=1.1" media="all">
<link rel="https://api.w.org/" href="/wp-json/">
<link rel="alternate" type="application/json" href="/wp-json/wp/v2/posts/3154">
<link rel="EditURI" type="application/rsd+xml" title="RSD" href="/xmlrpc.php?rsd">
<link rel="wlwmanifest" type="application/wlwmanifest+xml" href="/wp-includes/wlwmanifest.xml"> 
<meta name="generator" content="WordPress 5.7.5">
<link rel="canonical" href="/how-computational-graphs-are-constructed-in-pytorch/">
<link rel="shortlink" href="/?p=3154">
		<meta name="ssp-url" content="">
		<meta name="ssp-config-url" content="/wp-content/plugins/simply-static-pro/configs/">
		<style type="text/css">img#wpstats{display:none}</style>
		</head>

<body class="post-template-default single single-post postid-3154 single-format-standard">
    <a id="skip" href="#main" tabindex="0">Skip to content</a>
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-52DXT37" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
<div>
	<header class="mainHeader">
		<div class="container">
			<div class="logo">
				<a href="/" aria-label="PyTorch Logo" tabindex="0">
					<svg role="img" width="109" height="27" viewbox="0 0 109 27" fill="none" xmlns="http://www.w3.org/2000/svg">
<path d="M14.6172 5.92839L13.1892 7.32839C15.5692 9.66172 15.5692 13.4617 13.1892 15.7951C10.8092 18.1284 6.93316 18.1284 4.55316 15.7951C2.17316 13.4617 2.17316 9.66172 4.55316 7.32839L8.36116 3.59505L8.83716 3.06172V0.261719L3.05716 5.92839C-0.138844 9.06172 -0.138844 14.0617 3.05716 17.1951C6.25316 20.3284 11.3532 20.3284 14.5492 17.1951C17.8132 14.0617 17.8132 8.99505 14.6172 5.92839Z" fill="#DE3412"></path>
<ellipse cx="11.7618" cy="4.4612" rx="1.088" ry="1.06667" fill="#DE3412"></ellipse>
<path fill-rule="evenodd" clip-rule="evenodd" d="M26.5048 13.23H28.9435C33.3467 13.1625 36.1242 11.205 36.1242 7.29C36.1242 3.9825 33.8887 1.6875 29.1467 1.6875H24.6758V19.5075H26.5048V13.23ZM26.4371 3.375H29.079C32.4661 3.375 34.2274 4.7925 34.2274 7.29C34.2274 10.0575 32.3984 11.4075 29.0113 11.475L26.4371 11.5425V3.375Z" fill="#262626"></path>
<path d="M44.3887 19.4405L43.3048 22.2755C42.0855 25.448 40.8661 26.393 39.0371 26.393C38.021 26.393 37.2758 26.123 36.4629 25.7855L37.0048 24.1655C37.6145 24.503 38.2919 24.7055 39.0371 24.7055C40.0532 24.7055 40.7984 24.1655 41.7468 21.668L42.6274 19.373L37.5468 6.48047H39.4435L43.5758 17.2805L47.6403 6.48047H49.4693L44.3887 19.4405Z" fill="#262626"></path>
<path d="M55.5665 3.4425V19.575H53.7375V3.4425H47.4375V1.6875H61.8665V3.375H55.5665V3.4425Z" fill="#262626"></path>
<path fill-rule="evenodd" clip-rule="evenodd" d="M60.6465 13.0277C60.6465 17.2127 63.3562 19.9127 67.0142 19.9127C70.6723 19.9127 73.4497 17.1452 73.4497 12.9602C73.4497 8.7752 70.8078 6.0752 67.1497 6.0752C63.4239 6.0752 60.6465 8.8427 60.6465 13.0277ZM62.4746 12.9613C62.4746 9.92379 64.3036 7.69629 67.0811 7.69629C69.8585 7.69629 71.7553 9.85629 71.7553 13.0288C71.7553 16.0663 69.9262 18.2938 67.1488 18.2938C64.3714 18.2938 62.4746 16.1338 62.4746 12.9613Z" fill="#262626"></path>
<path d="M77.9879 19.5731H76.2266V6.47813L77.9879 6.14062V8.90812C78.8685 7.22062 80.1556 6.14062 81.8491 6.14062C82.7298 6.14062 83.5427 6.41063 84.1524 6.74813L83.6782 8.43563C83.1362 8.09813 82.3911 7.89562 81.6459 7.89562C80.2911 7.89562 79.004 8.90813 77.9201 11.2706V19.5731H77.9879Z" fill="#262626"></path>
<path d="M91.1308 19.9127C87.2018 19.9127 84.6953 17.0777 84.6953 13.0277C84.6953 8.9102 87.405 6.0752 91.1308 6.0752C92.7566 6.0752 94.1114 6.4802 95.2631 7.2227L94.7889 8.8427C93.7727 8.1677 92.5534 7.7627 91.1308 7.7627C88.2856 7.7627 86.5243 9.8552 86.5243 12.9602C86.5243 16.1327 88.4211 18.2252 91.1985 18.2252C92.4856 18.2252 93.8405 17.8202 94.8566 17.1452L95.1953 18.7652C94.0437 19.5077 92.6211 19.9127 91.1308 19.9127Z" fill="#262626"></path>
<path d="M106.238 19.575V11.1375C106.238 8.8425 105.29 7.83 103.461 7.83C101.97 7.83 100.48 8.5725 99.3961 9.72V19.6425H97.6348V0.3375L99.3961 0C99.3961 0 99.3961 8.1675 99.3961 8.235C100.751 6.885 102.512 6.1425 103.935 6.1425C106.509 6.1425 108.067 7.7625 108.067 10.5975V19.575H106.238Z" fill="#262626"></path>
</svg>
				</a>
			</div>
			<div class="content-container">
				<ul class="mainNav">
					<li class="mainItem search" key="search">
						<button id="search-icon" aria-label="search">
							<svg role="img" width="17" height="16" viewbox="0 0 17 16" fill="none" xmlns="http://www.w3.org/2000/svg">
<path fill-rule="evenodd" clip-rule="evenodd" d="M11.7461 7C11.7461 9.48528 9.73137 11.5 7.24609 11.5C4.76081 11.5 2.74609 9.48528 2.74609 7C2.74609 4.51472 4.76081 2.5 7.24609 2.5C9.73137 2.5 11.7461 4.51472 11.7461 7ZM10.9253 11.7399C9.90931 12.5297 8.63263 13 7.24609 13C3.93239 13 1.24609 10.3137 1.24609 7C1.24609 3.68629 3.93239 1 7.24609 1C10.5598 1 13.2461 3.68629 13.2461 7C13.2461 8.38653 12.7758 9.66322 11.986 10.6792L15.2764 13.9697L14.2158 15.0303L10.9253 11.7399Z" fill="#262626"></path>
</svg>
						</button>
						<div class="search-border">
							<div id="inner-search-icon">
								<svg role="img" width="17" height="16" viewbox="0 0 17 16" fill="none" xmlns="http://www.w3.org/2000/svg">
<path fill-rule="evenodd" clip-rule="evenodd" d="M11.7461 7C11.7461 9.48528 9.73137 11.5 7.24609 11.5C4.76081 11.5 2.74609 9.48528 2.74609 7C2.74609 4.51472 4.76081 2.5 7.24609 2.5C9.73137 2.5 11.7461 4.51472 11.7461 7ZM10.9253 11.7399C9.90931 12.5297 8.63263 13 7.24609 13C3.93239 13 1.24609 10.3137 1.24609 7C1.24609 3.68629 3.93239 1 7.24609 1C10.5598 1 13.2461 3.68629 13.2461 7C13.2461 8.38653 12.7758 9.66322 11.986 10.6792L15.2764 13.9697L14.2158 15.0303L10.9253 11.7399Z" fill="#262626"></path>
</svg>
							</div>
								<input id="input" type="text" placeholder="Search" title="Search" autocomplete="off" role="combobox" aria-autocomplete="list" aria-expanded="false" aria-label="search input">
							
							<div id="close-search">X</div>
						</div>
					</li>
					<li class="mainItem menuIcon">
						<span class="hamburger"><svg role="img" width="22" height="18" viewbox="0 0 22 18" fill="none" xmlns="http://www.w3.org/2000/svg">
<path fill-rule="evenodd" clip-rule="evenodd" d="M21.5 2.125H0.5V0.625H21.5V2.125ZM21.5 17.625H0.5V16.125H21.5V17.625ZM0.5 9.75H21.5V8.25H0.5V9.75Z" fill="black"></path>
</svg>
</span>
						<span class="close"><svg role="img" width="22" height="22" viewbox="0 0 22 22" fill="none" xmlns="http://www.w3.org/2000/svg">
<path fill-rule="evenodd" clip-rule="evenodd" d="M11.0001 12.0607L20.2197 21.2803L21.2804 20.2197L12.0607 11L21.2804 1.78033L20.2197 0.719675L11.0001 9.93934L1.78039 0.719673L0.719727 1.78033L9.9394 11L0.719727 20.2197L1.78039 21.2803L11.0001 12.0607Z" fill="black"></path>
</svg>
</span>
					</li>
					<li class="navItems">
						<ul class="navItemsContainer">
																														<li class="mainItem home-menu">
									<a class="parentTitle" href="/" target="">
										<span>
											Home										</span>
									</a>
																	</li>
																							<li class="mainItem install-menu">
									<a class="parentTitle" href="/install/install-overview/" target="">
										<span>
											Install										</span>
									</a>
																			<div class="subitems-container">
											<div class="subitems-wrapper">
												<ul class="subItems">
																											<li class="subItem ">
															<a class="link" href="/install/install-overview/" target="">
																<p class="title">Overview</p>
																														</a>
														</li>
																											<li class="subItem ">
															<a class="link" href="/install/install-locally/" target="">
																<p class="title">Install Locally</p>
																														</a>
														</li>
																											<li class="subItem ">
															<a class="link" href="/install/install-mobile/" target="">
																<p class="title">Install Mobile</p>
																														</a>
														</li>
																											<li class="subItem ">
															<a class="link" href="/install/start-with-cloud-partners/" target="">
																<p class="title">Start with Cloud Partners</p>
																														</a>
														</li>
																											<li class="subItem ">
															<a class="link" href="/install/previous-versions/" target="">
																<p class="title">Previous PyTorch Versions</p>
																														</a>
														</li>
																									</ul>
											</div>
										</div>
																	</li>
																							<li class="mainItem features-menu">
									<a class="parentTitle" href="/features/" target="">
										<span>
											Features										</span>
									</a>
																	</li>
																							<li class="mainItem resources-menu">
									<a class="parentTitle" href="/resources/overview/" target="">
										<span>
											Resources										</span>
									</a>
																			<div class="subitems-container">
											<div class="subitems-wrapper">
												<ul class="subItems">
																											<li class="subItem ">
															<a class="link" href="/resources/overview/" target="">
																<p class="title">Overview</p>
																														</a>
														</li>
																											<li class="subItem ">
															<a class="link" href="/resources/blog/" target="">
																<p class="title">Blog</p>
																														</a>
														</li>
																											<li class="subItem ">
															<a class="link" href="/resources/education/" target="">
																<p class="title">Education</p>
																														</a>
														</li>
																											<li class="subItem ">
															<a class="link" href="/resources/localized-docs-tutorials/" target="">
																<p class="title">Localized Docs &#038; Tutorials</p>
																														</a>
														</li>
																											<li class="subItem ">
															<a class="link" href="/resources/enterprise-program/" target="">
																<p class="title">Enterprise Program</p>
																														</a>
														</li>
																									</ul>
											</div>
										</div>
																	</li>
																							<li class="mainItem docs-menu">
									<a class="parentTitle" href="https://pytorch.org/docs/stable/index.html" target="_blank">
										<span>
											Docs										</span>
									</a>
																	</li>
																							<li class="mainItem tutorials-menu">
									<a class="parentTitle" href="https://pytorch.org/tutorials/" target="_blank">
										<span>
											Tutorials										</span>
									</a>
																	</li>
																							<li class="mainItem community-menu">
									<a class="parentTitle" href="/community/overview/" target="">
										<span>
											Community										</span>
									</a>
																			<div class="subitems-container">
											<div class="subitems-wrapper">
												<ul class="subItems">
																											<li class="subItem ">
															<a class="link" href="/community/overview/" target="">
																<p class="title">Overview</p>
																														</a>
														</li>
																											<li class="subItem ">
															<a class="link" href="/community/case-studies/" target="">
																<p class="title">Case Studies</p>
																														</a>
														</li>
																											<li class="subItem ">
															<a class="link" href="/community/ecosystem-tools/" target="">
																<p class="title">Ecosystem Tools</p>
																														</a>
														</li>
																											<li class="subItem ">
															<a class="link" href="/community/events/" target="">
																<p class="title">Events</p>
																														</a>
														</li>
																									</ul>
											</div>
										</div>
																	</li>
														<li class="github mainItem">
								<div class="github-wrapper">
									<a href="https://github.com/pytorch/pytorch" target="_blank" class="parentTitle" aria-label="See Pytorch on GitHub">
										<svg role="img" width="25" height="24" viewbox="0 0 25 24" fill="none" xmlns="http://www.w3.org/2000/svg">
<path d="M23.0227 6.33146C21.9311 4.51257 20.4504 3.07256 18.5803 2.01109C16.7099 0.949571 14.6679 0.418945 12.453 0.418945C10.2384 0.418945 8.19578 0.949733 6.32575 2.01109C4.45545 3.07251 2.97484 4.51257 1.88325 6.33146C0.791831 8.15029 0.246094 10.1365 0.246094 12.2899C0.246094 14.8767 1.02214 17.2029 2.57462 19.2689C4.12694 21.3351 6.1323 22.7648 8.59054 23.5582C8.87669 23.6099 9.08851 23.5736 9.22624 23.4502C9.36403 23.3266 9.43284 23.1719 9.43284 22.9866C9.43284 22.9557 9.43011 22.6776 9.42482 22.152C9.41936 21.6263 9.4168 21.1677 9.4168 20.7765L9.05121 20.838C8.81812 20.8795 8.52407 20.8971 8.16906 20.8921C7.81422 20.8873 7.44584 20.8511 7.06445 20.7839C6.68288 20.7172 6.32798 20.5627 5.99947 20.3205C5.67113 20.0783 5.43803 19.7614 5.30025 19.37L5.14131 19.0143C5.03537 18.7775 4.86858 18.5145 4.64072 18.2261C4.41286 17.9375 4.18244 17.7418 3.94935 17.6388L3.83806 17.5613C3.76391 17.5098 3.6951 17.4477 3.63147 17.3757C3.5679 17.3036 3.5203 17.2315 3.48851 17.1593C3.45667 17.087 3.48305 17.0277 3.56795 16.9812C3.65285 16.9347 3.80628 16.9121 4.0289 16.9121L4.34667 16.9583C4.55861 16.9996 4.82076 17.123 5.13346 17.3292C5.44599 17.5353 5.70291 17.8032 5.90427 18.1328C6.14811 18.5554 6.44188 18.8774 6.78643 19.099C7.13069 19.3206 7.4778 19.4312 7.82741 19.4312C8.17702 19.4312 8.47898 19.4054 8.73339 19.3542C8.98753 19.3026 9.22596 19.2252 9.44859 19.1222C9.54395 18.4315 9.8036 17.9008 10.2273 17.5299C9.62339 17.4682 9.08044 17.3752 8.59817 17.2516C8.11617 17.1279 7.61809 16.927 7.10425 16.6485C6.59013 16.3704 6.16364 16.025 5.82466 15.613C5.48563 15.2008 5.20739 14.6596 4.99033 13.99C4.77316 13.3201 4.66455 12.5473 4.66455 11.6714C4.66455 10.4243 5.08319 9.36302 5.92031 8.48704C5.52816 7.54944 5.56518 6.49837 6.03148 5.33393C6.33878 5.24108 6.7945 5.31076 7.39841 5.54253C8.00244 5.77441 8.44468 5.97305 8.7256 6.13775C9.00651 6.30238 9.23159 6.4419 9.40116 6.55506C10.3868 6.28723 11.404 6.15328 12.4529 6.15328C13.5018 6.15328 14.5192 6.28723 15.5049 6.55506L16.1089 6.18425C16.5219 5.93683 17.0096 5.71009 17.5709 5.50398C18.1325 5.29798 18.562 5.24124 18.8588 5.33409C19.3354 6.49859 19.3779 7.54961 18.9857 8.4872C19.8227 9.36319 20.2415 10.4247 20.2415 11.6715C20.2415 12.5474 20.1325 13.3227 19.9157 13.9977C19.6986 14.6729 19.4179 15.2135 19.0737 15.6208C18.729 16.028 18.2998 16.3706 17.786 16.6487C17.272 16.927 16.7738 17.1278 16.2918 17.2516C15.8096 17.3754 15.2666 17.4684 14.6627 17.5302C15.2135 17.9937 15.4889 18.7254 15.4889 19.725V22.9862C15.4889 23.1715 15.5552 23.3261 15.6878 23.4497C15.8202 23.5731 16.0294 23.6095 16.3155 23.5578C18.7741 22.7644 20.7795 21.3347 22.3317 19.2685C23.8838 17.2024 24.6602 14.8763 24.6602 12.2895C24.6596 10.1363 24.1136 8.15029 23.0227 6.33146Z" fill="#262626"></path>
</svg>
									</a>
								</div>
							</li>
						</ul>
						
<div class="navItems-followContainer followMenu ">
			<div class="mainItem">Follow Us</div>
		<ul class="follow-list">
					<li class="followItem">
				<a aria-label="follow Menu  icon-twitter" href="https://twitter.com/pytorch" target="_blank" class=" icon-twitter">
					Twitter				</a>
			</li>
					<li class="followItem">
				<a aria-label="follow Menu  icon-facebook" href="https://www.facebook.com/pytorch" target="_blank" class=" icon-facebook">
					Facebook				</a>
			</li>
					<li class="followItem">
				<a aria-label="follow Menu  icon-youtube" href="https://www.youtube.com/pytorch" target="_blank" class=" icon-youtube">
					YouTube				</a>
			</li>
					<li class="followItem">
				<a aria-label="follow Menu  icon-linkedin" href="https://www.linkedin.com/company/pytorch" target="_blank" class=" icon-linkedin">
					Linkedin				</a>
			</li>
					<li class="followItem">
				<a aria-label="follow Menu  icon-medium" href="https://medium.com/pytorch" target="_blank" class=" icon-medium">
					Medium				</a>
			</li>
					<li class="followItem">
				<a aria-label="follow Menu  icon-github" href="https://github.com/pytorch/pytorch" target="_blank" class=" icon-github">
					GitHub				</a>
			</li>
			</ul>
</div>
					</li>
				</ul>
			</div>
		</div>
	</header>

	<main id="main" class="site-main" role="main">


<div class="Breadcrumbs">
	<div class="container breadcrumbs-lined">
		<ul class="list-container">
						<li class="breadcrumb-item breadcrumb-active">
				<a class="active-item" href="/blog">Blog</a>
			</li>
						<li class="breadcrumb-item">
				How Computational Graphs are Constructed in PyTorch			</li>
		</ul>
	</div>
</div>

<div class="BlogHeader ">
	<div class="container">
		<h2 class="title">How Computational Graphs are Constructed in PyTorch</h2>

		<div class="banner">
			
<img class="Image " src="/wp-content/uploads/2021/10/Blog_Default_Image_B.jpg" alt="">
		</div>

		<div class="foot">
			<div class="byline">
								<span class="date">August 31, 2021</span>
				<span class="author">by Preferred Networks</span>
			</div>

			
<div class="Share ">
  
  <div class="share-icons">
    
      </div>
</div>
		</div>


	</div>
</div>




<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">In the previous <a href="https://pytorch.org/blog/overview-of-pytorch-autograd-engine/">post</a> we went over the theoretical foundations of automatic differentiation and reviewed the implementation in PyTorch. In this post, we will be showing the parts of PyTorch involved in creating the graph and executing it. In order to understand the following contents, please read @ezyang’s wonderful <a href="http://blog.ezyang.com/2019/05/pytorch-internals/" target="_blank">blog post</a> about PyTorch internals.</p>
	</div>
</div>

<div class="">
<h2 class="HeadingBlock HeadingBlock is-style-secondary-heading  hasTopSpacing" id="block-d8023ffd-8aec-4883-ae5b-374e765ecd0b">
		
	Autograd components</h2>
	</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">First of all, let’s look at where the different components of autograd live:<br><br><a href="https://github.com/pytorch/pytorch/tree/release/1.9/tools/autograd" target="_blank">tools/autograd</a>: Here we can find the definition of the derivatives as we saw in the previous post <a href="https://github.com/pytorch/pytorch/blob/release/1.9/tools/autograd/derivatives.yaml" target="_blank">derivatives.yaml</a>, several python scripts and a folder called <a href="https://github.com/pytorch/pytorch/tree/release/1.9/tools/autograd/templates" target="_blank">templates</a>. These scripts and the templates are used at building time to generate the C++ code for the derivatives as specified in the yaml file. Also, the scripts here generate wrappers for the regular ATen functions so that the computational graph can be constructed.<br><br><a href="https://github.com/pytorch/pytorch/tree/release/1.9/torch/autograd" target="_blank">torch/autograd</a>: This folder is where the autograd components that can be used directly from python are located. In <a href="https://github.com/pytorch/pytorch/blob/release/1.9/torch/autograd/function.py" target="_blank">function.py</a> we find the actual definition of <code>torch.autograd.Function</code>, a class used by users to write their own differentiable functions in python as per the documentation. <a href="https://github.com/pytorch/pytorch/blob/release/1.9/torch/autograd/functional.py" target="_blank">functional.py</a> holds components for functionally computing the jacobian vector product, hessian, and other gradient related computations of a given function. The rest of the files have additional components such as gradient checkers, anomaly detection, and the autograd profiler.<br><br><a href="https://github.com/pytorch/pytorch/tree/release/1.9/torch/csrc/autograd" target="_blank">torch/csrc/autograd</a>: This is where the graph creation and execution-related code lives. All this code is written in C++, since it is a critical part that is required to be extremely performant. Here we have several files that implement the engine, metadata storage, and all the needed components. Alongside this, we have several files whose names start with <code>python_</code>, and their main responsibility is to allow python objects to be used in the autograd engine.</p>
	</div>
</div>

<div class="">
<h2 class="HeadingBlock HeadingBlock is-style-secondary-heading  hasTopSpacing" id="block-90e48d4a-3e69-4169-942f-429219159168">
		
	Graph Creation</h2>
	</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text"><a href="https://pytorch.org/blog/overview-of-pytorch-autograd-engine/">Previously</a>, we described the creation of a computational graph. Now, we will see how PyTorch creates these graphs with references to the actual codebase.</p>
	</div>
</div>


<div class="BlogImage BlogImage">
	<div class="container">
		<div class="imageCon">
			
<img class="Image image" src="/wp-content/uploads/2021/11/augmented_computational_graph.png" alt="">
		</div>
		<div class="descriptionCon">
					</div>
	</div>
</div>




<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">It all starts when in our python code, where we request a tensor to require the gradient.</p>
	</div>
</div>

<div class="code-block">
<pre class="wp-block-code"><code lang="bash" class="language-bash">&gt;&gt;&gt; x = torch.tensor([0.5, 0.75], requires_grad=True)</code></pre>
</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">When the <code>required_grad</code> flag is set in tensor creation, c10 will <a href="https://github.com/pytorch/pytorch/blob/e7cd59c7a061c78d8d0265e4308b5933e44f9176/c10/core/TensorImpl.cpp#L382-L406" target="_blank">allocate</a> an <code>AutogradMeta</code> object that is used to hold the graph information.</p>
	</div>
</div>

<div class="code-block">
<pre class="wp-block-code"><code lang="bash" class="language-bash">void TensorImpl::set_requires_grad(bool requires_grad) {
  ...
  if (!autograd_meta_)
    autograd_meta_ = impl::GetAutogradMetaFactory()-&gt;make();
    autograd_meta_-&gt;set_requires_grad(requires_grad, this);
}</code></pre>
</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">The <code>AutogradMeta</code> object is defined in <a href="https://github.com/pytorch/pytorch/blob/release/1.9/torch/csrc/autograd/variable.h#L190-L286" target="_blank">torch/csrc/autograd/variable.h</a> as follows:</p>
	</div>
</div>

<div class="code-block">
<pre class="wp-block-code"><code lang="bash" class="language-bash">struct TORCH_API AutogradMeta : public c10::AutogradMetaInterface {
  std::string name_;

  Variable grad_;
  std::shared_ptr&lt;Node&gt; grad_fn_;
  std::weak_ptr&lt;Node&gt; grad_accumulator_;
  // other fields and methods
  ...
};</code></pre>
</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">The most important fields in this structure are the computed gradient in <code>grad_</code> and a pointer to the function <code>grad_fn</code> that will be called by the engine to produce the actual gradient. Also, there is a gradient accumulator object that is used to add together all the different gradients where this tensor is involved as we will see in the graph execution.</p>
	</div>
</div>

<div class="">
<h3 class="HeadingBlock HeadingBlock is-style-subheading  hasTopSpacing" id="block-e3cbd470-bbda-44bb-b659-6eb0a2f3dce9">
		
	Graphs, Nodes and Edges.</h3>
	</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">Now, when we call a differentiable function that takes this tensor as an argument, the associated metadata will be populated. Let’s suppose that we call a regular torch function that is implemented in ATen. Let it be the multiplication as in our previous blog post example. The resulting tensor has a field called <code>grad_fn</code> that is essentially a pointer to the function that will be used to compute the gradient of that operation.</p>
	</div>
</div>

<div class="code-block">
<pre class="wp-block-code"><code lang="bash" class="language-bash">&gt;&gt;&gt; x = torch.tensor([0.5, 0.75], requires_grad=True)
&gt;&gt;&gt; v = x[0] * x[1]
&gt;&gt;&gt; v
tensor(0.3750, grad_fn=&lt;MulBackward0&gt;)</code></pre>
</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">Here we see that the tensors’ <code>grad_fn</code> has a <code>MulBackward0</code> value. This function is the same that was written in the <a href="https://github.com/pytorch/pytorch/blob/e7cd59c7a061c78d8d0265e4308b5933e44f9176/tools/autograd/derivatives.yaml#L840-L843" target="_blank">derivatives.yaml</a> file, and its C++ code was generated automatically by all the scripts in <code>tools/autograd</code>. It’s auto-generated source code can be seen in <code>torch/csrc/autograd/generated/Functions.cpp</code>.</p>
	</div>
</div>

<div class="code-block">
<pre class="wp-block-code"><code lang="bash" class="language-bash">variable_list MulBackward0::apply(variable_list&amp;&amp; grads) {
  std::lock_guard&lt;std::mutex&gt; lock(mutex_);

  IndexRangeGenerator gen;
  auto self_ix = gen.range(1);
  auto other_ix = gen.range(1);
  variable_list grad_inputs(gen.size());
  auto&amp; grad = grads[0];
  auto self = self_.unpack();
  auto other = other_.unpack();
  bool any_grad_defined = any_variable_defined(grads);
  if (should_compute_output({ other_ix })) {
    auto grad_result = any_grad_defined ? (mul_tensor_backward(grad, self, other_scalar_type)) : Tensor();
    copy_range(grad_inputs, other_ix, grad_result);
  }
  if (should_compute_output({ self_ix })) {
    auto grad_result = any_grad_defined ? (mul_tensor_backward(grad, other, self_scalar_type)) : Tensor();
    copy_range(grad_inputs, self_ix, grad_result);
  }
  return grad_inputs;
}</code></pre>
</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">The <code>grad_fn</code> objects inherit from the <a href="https://github.com/pytorch/pytorch/blob/e7cd59c7a061c78d8d0265e4308b5933e44f9176/torch/csrc/autograd/function.h#L535-L541" target="_blank"><code>TraceableFunction</code></a> class, a descendant of <code>Node</code> with just a property set to enable tracing for debugging and optimization purposes. A graph by definition has nodes and edges, so these functions are indeed the nodes of the computational graph that are linked together by using <code>Edge</code> objects to enable the graph traversal later on.<br><br>The <code>Node</code> definition can be found in the <a href="https://github.com/pytorch/pytorch/blob/e7cd59c7a061c78d8d0265e4308b5933e44f9176/torch/csrc/autograd/function.h#L50-L533" target="_blank">torch/csrc/autograd/function.h</a> file.</p>
	</div>
</div>

<div class="code-block">
<pre class="wp-block-code"><code lang="bash" class="language-bash">struct TORCH_API Node : std::enable_shared_from_this&lt;Node&gt; {
 ...
 /// Evaluates the function on the given inputs and returns the result of the
  /// function call.
  variable_list operator()(variable_list&amp;&amp; inputs) {
  ...
  }

protected:
  /// Performs the `Node`'s actual operation.
  virtual variable_list apply(variable_list&amp;&amp; inputs) = 0;
  …
  edge_list next_edges_;</code></pre>
</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">Essentially we see that it has an override of the <code>operator ()</code> that performs the call to the actual function, and a pure virtual function called <code>apply</code>. The automatically generated functions override this <code>apply</code> method as we saw in the <code>MulBackward0</code> example above. Finally, the node also has a list of edges to enable graph connectivity.<br><br>The <a href="https://github.com/pytorch/pytorch/blob/e7cd59c7a061c78d8d0265e4308b5933e44f9176/torch/csrc/autograd/edge.h#L14-L39" target="_blank">Edge</a> object is used to link <code>Node</code>s together and its implementation is straightforward.</p>
	</div>
</div>

<div class="code-block">
<pre class="wp-block-code"><code lang="bash" class="language-bash">struct Edge {
  ...
  /// The function this `Edge` points to.
  std::shared_ptr&lt;Node&gt; function;
  /// The identifier of a particular input to the function.
  uint32_t input_nr;
};</code></pre>
</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">It only requires a function pointer (the actual <code>grad_fn</code> objects that the edges link together), and an input number that acts as an id for the edge.</p>
	</div>
</div>

<div class="">
<h3 class="HeadingBlock HeadingBlock is-style-subheading  hasTopSpacing" id="block-3c17b3b3-56fa-4a86-ad8e-a6e0a071a9ed">
		
	Linking nodes together</h3>
	</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">When we invoke the product operation of two tensors, we enter into the realm of autogenerated code. All the scripts that we saw in <code>tools/autograd</code> fill a series of templates that wrap the differentiable functions in ATen. These functions have code to construct the backward graph during the forward pass.<br><br>The <a href="https://github.com/pytorch/pytorch/blob/release/1.9/tools/autograd/gen_variable_type.py" target="_blank">gen_variable_type.py</a> script is in charge of writing all this wrapping code. This script is called from the <a href="https://github.com/pytorch/pytorch/blob/release/1.9/tools/autograd/gen_autograd.py" target="_blank">tools/autograd/gen_autograd.py</a> during the pytorch build process and it will output the automatically generated function wrappers to <code>torch/csrc/autograd/generated/</code>.<br><br>Let’s take a look at how the tensor multiplication generated function looks like. The code has been simplified, but it can be found in the <code>torch/csrc/autograd/generated/VariableType_4.cpp</code> file when compiling pytorch from source.</p>
	</div>
</div>

<div class="code-block">
<pre class="wp-block-code"><code lang="bash" class="language-bash">at::Tensor mul_Tensor(c10::DispatchKeySet ks, const at::Tensor &amp; self, const at::Tensor &amp; other) {
  ...
  auto _any_requires_grad = compute_requires_grad( self, other );
  std::shared_ptr&lt;MulBackward0&gt; grad_fn;
  if (_any_requires_grad) {
    // Creates the link to the actual grad_fn and links the graph for backward traversal
    grad_fn = std::shared_ptr&lt;MulBackward0&gt;(new MulBackward0(), deleteNode);
    grad_fn-&gt;set_next_edges(collect_next_edges( self, other ));
    ...
  }
  …
  // Does the actual function call to ATen
  auto _tmp = ([&amp;]() {
    at::AutoDispatchBelowADInplaceOrView guard;
    return at::redispatch::mul(ks &amp; c10::after_autograd_keyset, self_, other_);
  })();

  auto result = std::move(_tmp);
    if (grad_fn) {
       // Connects the result to the graph
      set_history(flatten_tensor_args( result ), grad_fn);
  }
  ...
  return result;
}</code></pre>
</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">Let’s walk through the most important lines of this code. First of all, the <code>grad_fn</code> object is created with: ` grad_fn = std::shared_ptr(new MulBackward0(), deleteNode);`.<br><br>After the <code>grad_fn</code> object is created, the edges used to link the nodes together are created by using the <code>grad_fn-&gt;set_next_edges(collect_next_edges( self, other ));</code> calls.</p>
	</div>
</div>

<div class="code-block">
<pre class="wp-block-code"><code lang="bash" class="language-bash">struct MakeNextFunctionList : IterArgs&lt;MakeNextFunctionList&gt; {
  edge_list next_edges;
  using IterArgs&lt;MakeNextFunctionList&gt;::operator();
  void operator()(const Variable&amp; variable) {
    if (variable.defined()) {
      next_edges.push_back(impl::gradient_edge(variable));
    } else {
      next_edges.emplace_back();
    }
  }
  void operator()(const c10::optional&lt;Variable&gt;&amp; variable) {
    if (variable.has_value() &amp;&amp; variable-&gt;defined()) {
      next_edges.push_back(impl::gradient_edge(*variable));
    } else {
      next_edges.emplace_back();
    }
  }
};

template &lt;typename... Variables&gt;
edge_list collect_next_edges(Variables&amp;&amp;... variables) {
  detail::MakeNextFunctionList make;
  make.apply(std::forward&lt;Variables&gt;(variables)...);
  return std::move(make.next_edges);
}</code></pre>
</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">Given an input variable (it’s just a regular tensor), <a href="https://github.com/pytorch/pytorch/blob/e7cd59c7a061c78d8d0265e4308b5933e44f9176/torch/csrc/autograd/function.h#L597-L603" target="_blank"><code>collect_next_edges</code></a> will create an <code>Edge</code> object by calling <a href="https://github.com/pytorch/pytorch/blob/e7cd59c7a061c78d8d0265e4308b5933e44f9176/torch/csrc/autograd/variable.cpp#L228-L240." target="_blank"><code>impl::gradient_edge</code></a></p>
	</div>
</div>

<div class="code-block">
<pre class="wp-block-code"><code lang="bash" class="language-bash"> Edge gradient_edge(const Variable&amp; self) {
    // If grad_fn is null (as is the case for a leaf node), we instead
    // interpret the gradient function to be a gradient accumulator, which will
    // accumulate its inputs into the grad property of the variable. These
    // nodes get suppressed in some situations, see "suppress gradient
    // accumulation" below. Note that only variables which have `requires_grad =
    // True` can have gradient accumulators.
    if (const auto&amp; gradient = self.grad_fn()) {
      return Edge(gradient, self.output_nr());
    } else {
      return Edge(grad_accumulator(self), 0);
    }
  }</code></pre>
</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">To understand how edges work, let’s assume that an early executed function produced two output tensors, both with their <code>grad_fn</code> set, each tensor also has an <code>output_nr</code> property with the order in which they were returned. When creating the edges for the current <code>grad_fn</code>, an <code>Edge</code> object per input variable will be created. The edges will point to the variable’s grad_fn and will also track the <code>output_nr</code> to establish ids used when traversing the graph. In the case that the input variables are “leaf”, i.e. they were not produced by any differentiable function, they don’t have a <code>grad_fn</code> attribute set. A special function called a gradient accumulator is set by default as seen in the above code snippet.<br><br>After the edges are created, the <code>grad_fn</code> graph Node object that is being currently created will hold them using the <a href="https://github.com/pytorch/pytorch/blob/e7cd59c7a061c78d8d0265e4308b5933e44f9176/torch/csrc/autograd/function.h#L258-L263" target="_blank"><code>set_next_edges</code></a> function. This is what connects <code>grad_fn</code>s together, producing the computational graph.</p>
	</div>
</div>

<div class="code-block">
<pre class="wp-block-code"><code lang="bash" class="language-bash"> void set_next_edges(edge_list&amp;&amp; next_edges) {
    next_edges_ = std::move(next_edges);
    for(const auto&amp; next_edge : next_edges_) {
      update_topological_nr(next_edge);
    }
  }</code></pre>
</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">Now, the forward pass of the function will execute, and after the execution <code>set_history</code> will connect the output tensors to the <code>grad_fn</code> Node.</p>
	</div>
</div>

<div class="code-block">
<pre class="wp-block-code"><code lang="bash" class="language-bash">inline void set_history(
    at::Tensor&amp; variable,
    const std::shared_ptr&lt;Node&gt;&amp; grad_fn) {
  AT_ASSERT(grad_fn);
  if (variable.defined()) {
    // If the codegen triggers this, you most likely want to add your newly added function
    // to the DONT_REQUIRE_DERIVATIVE list in tools/autograd/gen_variable_type.py
    TORCH_INTERNAL_ASSERT(isDifferentiableType(variable.scalar_type()));
    auto output_nr =
        grad_fn-&gt;add_input_metadata(variable);
    impl::set_gradient_edge(variable, {grad_fn, output_nr});
  } else {
    grad_fn-&gt;add_input_metadata(Node::undefined_input());
  }
}</code></pre>
</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text"><a href="https://github.com/pytorch/pytorch/blob/e7cd59c7a061c78d8d0265e4308b5933e44f9176/torch/csrc/autograd/functions/utils.h#L58-L72" target="_blank"><code>set_history</code></a> calls <a href="https://github.com/pytorch/pytorch/blob/e7cd59c7a061c78d8d0265e4308b5933e44f9176/torch/csrc/autograd/variable.cpp#L242-L255" target="_blank"><code>set_gradient_edge</code></a>, which just copies the grad_fn and the <code>output_nr</code> to the <code>AutogradMeta</code> object that the tensor has.</p>
	</div>
</div>

<div class="code-block">
<pre class="wp-block-code"><code lang="bash" class="language-bash"> void set_gradient_edge(const Variable&amp; self, Edge edge) {
    auto* meta = materialize_autograd_meta(self);
    meta-&gt;grad_fn_ = std::move(edge.function);
    meta-&gt;output_nr_ = edge.input_nr;
    // For views, make sure this new grad_fn_ is not overwritten unless it is necessary
    // in the VariableHooks::grad_fn below.
    // This logic is only relevant for custom autograd Functions for which multiple
    // operations can happen on a given Tensor before its gradient edge is set when
    // exiting the custom Function.
    auto diff_view_meta = get_view_autograd_meta(self);
    if (diff_view_meta &amp;&amp; diff_view_meta-&gt;has_bw_view()) {
      diff_view_meta-&gt;set_attr_version(self._version());
    }
  }</code></pre>
</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">This tensor now will be the input to another function and the above steps will be all repeated. Check the animation below to see how the graph is created.</p>
	</div>
</div>


<div class="BlogImage BlogImage">
	<div class="container">
		<div class="imageCon">
			
<img class="Image image" src="/wp-content/uploads/2021/08/computational_graph_creation.gif" alt="">
		</div>
		<div class="descriptionCon">
					</div>
	</div>
</div>


<div class="">
<h3 class="HeadingBlock HeadingBlock is-style-subheading  hasTopSpacing" id="block-b3dce252-6626-46f5-a0b8-5e7cc68e79a8">
		
	Registering Python Functions in the graph</h3>
	</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">We have seen how autograd creates the graph for the functions included in ATen. However, when we define our differentiable functions in Python, they are also included in the graph!<br><br>An autograd python defined function looks like the following:</p>
	</div>
</div>

<div class="code-block">
<pre class="wp-block-code"><code lang="bash" class="language-bash">class Exp(torch.autograd.Function):
     @staticmethod
     def forward(ctx, i):
         result = i.exp()
         ctx.save_for_backward(result)
         return result

     @staticmethod
     def backward(ctx, grad_output):
         result, = ctx.saved_tensors
         return grad_output * result

# Call the function
Exp.apply(torch.tensor(0.5, requires_grad=True))
# Outputs: tensor(1.6487, grad_fn=&lt;ExpBackward&gt;)</code></pre>
</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">In the above snippet autograd detected our python function when creating the graph. All of this is possible thanks to the <a href="https://github.com/pytorch/pytorch/blob/release/1.9/torch/autograd/function.py#L106" target="_blank"><code>Function</code></a> class. Let’s take a look at what happens when we call <code>apply</code>.<br><br><code>apply</code> is defined in the <a href="https://github.com/pytorch/pytorch/blob/e7cd59c7a061c78d8d0265e4308b5933e44f9176/torch/csrc/autograd/python_function.cpp#L859-L908" target="_blank"><code>torch._C._FunctionBase</code></a> class, but this class is not present in the python source. <code>_FunctionBase</code> is defined in C++ by using the python C API to hook C functions together into a single python class. We are looking for a function named <a href="https://github.com/pytorch/pytorch/blob/e7cd59c7a061c78d8d0265e4308b5933e44f9176/torch/csrc/autograd/python_function.cpp#L577-L633" target="_blank"><code>THPFunction_apply</code></a>.</p>
	</div>
</div>

<div class="code-block">
<pre class="wp-block-code"><code lang="bash" class="language-bash">PyObject *THPFunction_apply(PyObject *cls, PyObject *inputs)
{
  
  // Generates the graph node
  THPObjectPtr backward_cls(PyObject_GetAttrString(cls, "_backward_cls"));
  if (!backward_cls) return nullptr;
  THPObjectPtr ctx_obj(PyObject_CallFunctionObjArgs(backward_cls, nullptr));
  if (!ctx_obj) return nullptr;
  THPFunction* ctx = (THPFunction*)ctx_obj.get();

  auto cdata = std::shared_ptr&lt;PyNode&gt;(new PyNode(std::move(ctx_obj)), deleteNode);
  ctx-&gt;cdata = cdata;

  // Prepare inputs and allocate context (grad fn)
  // Unpack inputs will collect the edges
  auto info_pair = unpack_input&lt;false&gt;(inputs);
  UnpackedInput&amp; unpacked_input = info_pair.first;
  InputFlags&amp; input_info = info_pair.second;

   // Initialize backward function (and ctx)
  bool is_executable = input_info.is_executable;
  cdata-&gt;set_next_edges(std::move(input_info.next_edges));
  ctx-&gt;needs_input_grad = input_info.needs_input_grad.release();
  ctx-&gt;is_variable_input = std::move(input_info.is_variable_input);

  // Prepend ctx to input_tuple, in preparation for static method call
  auto num_args = PyTuple_GET_SIZE(inputs);
  THPObjectPtr ctx_input_tuple(PyTuple_New(num_args + 1));
  if (!ctx_input_tuple) return nullptr;
  Py_INCREF(ctx);
  PyTuple_SET_ITEM(ctx_input_tuple.get(), 0, (PyObject*)ctx);
  for (int i = 0; i &lt; num_args; ++i) {
    PyObject *arg = PyTuple_GET_ITEM(unpacked_input.input_tuple.get(), i);
    Py_INCREF(arg);
    PyTuple_SET_ITEM(ctx_input_tuple.get(), i + 1, arg);
  }

  // Call forward
  THPObjectPtr tensor_outputs;
  {
    AutoGradMode grad_mode(false);
    THPObjectPtr forward_fn(PyObject_GetAttrString(cls, "forward"));
    if (!forward_fn) return nullptr;
    tensor_outputs = PyObject_CallObject(forward_fn, ctx_input_tuple);
    if (!tensor_outputs) return nullptr;
  }

  // Here is where the outputs gets the tensors tracked
  return process_outputs(cls, cdata, ctx, unpacked_input, inputs, std::move(tensor_outputs),
                         is_executable, node);
  END_HANDLE_TH_ERRORS
}</code></pre>
</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">Although this code is hard to read at first due to all the python API calls, it essentially does the same thing as the auto-generated forward functions that we saw for ATen:<br><br>Create a <code>grad_fn</code> object. Collect the edges to link the current <code>grad_fn</code> with the input tensors one. Execute the function <code>forward</code>. Assign the created <code>grad_fn</code> to the output tensors metadata.<br><br>The <code>grad_fn</code> object is created in:</p>
	</div>
</div>

<div class="code-block">
<pre class="wp-block-code"><code lang="python" class="language-python">  // Generates the graph node
  THPObjectPtr backward_cls(PyObject_GetAttrString(cls, "_backward_cls"));
  if (!backward_cls) return nullptr;
  THPObjectPtr ctx_obj(PyObject_CallFunctionObjArgs(backward_cls, nullptr));
  if (!ctx_obj) return nullptr;
  THPFunction* ctx = (THPFunction*)ctx_obj.get();

  auto cdata = std::shared_ptr&lt;PyNode&gt;(new PyNode(std::move(ctx_obj)), deleteNode);
  ctx-&gt;cdata = cdata;</code></pre>
</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">Basically, it asks the python API to get a pointer to the Python object that can execute the user-written function. Then it wraps it into a <a href="https://github.com/pytorch/pytorch/blob/e7cd59c7a061c78d8d0265e4308b5933e44f9176/torch/csrc/autograd/python_function.h#L24-L58" target="_blank"><code>PyNode</code></a> object that is a specialized <code>Node</code> object that calls the python interpreter with the provided python function when <code>apply</code> is executed during the forward pass. Note that in the code <code>cdata</code> is the actual <code>Node</code> object that is part of the graph. <code>ctx</code> is the object that is passed to the python <code>forward</code>/<code>backward</code> functions and it is used to store autograd related information by both, the user’s function and PyTorch.<br><br>As in the regular C++ functions we also call <code>collect_next_edges</code> to track the inputs <code>grad_fn</code> objects, but this is done in <a href="https://github.com/pytorch/pytorch/blob/e7cd59c7a061c78d8d0265e4308b5933e44f9176/torch/csrc/autograd/python_function.cpp#L413-L448" target="_blank"><code>unpack_input</code></a>:</p>
	</div>
</div>

<div class="code-block">
<pre class="wp-block-code"><code lang="cpp" class="language-cpp">template&lt;bool enforce_variables&gt;
std::pair&lt;UnpackedInput, InputFlags&gt; unpack_input(PyObject *args) {
  ...
  flags.next_edges = (flags.is_executable ? collect_next_edges(unpacked.input_vars) : edge_list());
  return std::make_pair(std::move(unpacked), std::move(flags));
}</code></pre>
</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">After this, the edges are assigned to the <code>grad_fn</code> by just doing <code>cdata-&gt;set_next_edges(std::move(input_info.next_edges));</code> and the forward function is called through the python interpreter C API.<br><br>Once the output tensors are returned from the forward pass, they are processed and converted to variables inside the <a href="https://github.com/pytorch/pytorch/blob/e7cd59c7a061c78d8d0265e4308b5933e44f9176/torch/csrc/autograd/python_function.cpp#L519-L562" target="_blank"><code>process_outputs</code></a> function.</p>
	</div>
</div>

<div class="code-block">
<pre class="wp-block-code"><code lang="bash" class="language-bash">PyObject* process_outputs(PyObject *op_obj, const std::shared_ptr&lt;PyNode&gt;&amp; cdata,
                          THPFunction* grad_fn, const UnpackedInput&amp; unpacked,
                          PyObject *inputs, THPObjectPtr&amp;&amp; raw_output, bool is_executable,
                          torch::jit::Node* node) {
  ...
  _wrap_outputs(cdata, grad_fn, unpacked.input_vars, raw_output, outputs, is_executable);
  _trace_post_record(node, op_obj, unpacked.input_vars, outputs, is_inplace, unpack_output);
  if (is_executable) {
    _save_variables(cdata, grad_fn);
  } ...
  return outputs.release();
}</code></pre>
</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">Here, <a href="https://github.com/pytorch/pytorch/blob/e7cd59c7a061c78d8d0265e4308b5933e44f9176/torch/csrc/autograd/python_function.cpp#L302-L346" target="_blank"><code>_wrap_outputs</code></a> is in charge of setting the forward outputs <code>grad_fn</code> to the newly created one. For this, it calls another <code>_wrap_outputs</code> function defined in a different <a href="https://github.com/pytorch/pytorch/blob/e7cd59c7a061c78d8d0265e4308b5933e44f9176/torch/csrc/autograd/custom_function.cpp#L28-L105" target="_blank">file</a>, so the process here gets a little confusing.</p>
	</div>
</div>

<div class="code-block">
<pre class="wp-block-code"><code lang="bash" class="language-bash">static void _wrap_outputs(const std::shared_ptr&lt;PyNode&gt;&amp; cdata, THPFunction *self,
    const variable_list &amp;input_vars, PyObject *raw_output, PyObject *outputs, bool is_executable)
{
  auto cdata_if_executable = is_executable ? cdata : nullptr;
 ...

  // Wrap only the tensor outputs.
  // This calls csrc/autograd/custom_function.cpp
  auto wrapped_outputs = _wrap_outputs(input_vars, non_differentiable, dirty_inputs, raw_output_vars, cdata_if_executable);
...
}</code></pre>
</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">The called <code>_wrap_outputs</code> is the one in charge of setting the autograd metadata in the output tensors:</p>
	</div>
</div>

<div class="code-block">
<pre class="wp-block-code"><code lang="bash" class="language-bash">std::vector&lt;c10::optional&lt;Variable&gt;&gt; _wrap_outputs(const variable_list &amp;input_vars,
  const std::unordered_set&lt;at::TensorImpl*&gt; &amp;non_differentiable,
  const std::unordered_set&lt;at::TensorImpl*&gt; &amp;dirty_inputs,
  const at::ArrayRef&lt;c10::optional&lt;Variable&gt;&gt; raw_outputs,
  const std::shared_ptr&lt;Node&gt; &amp;cdata) {


  std::unordered_set&lt;at::TensorImpl*&gt; inputs;
  …
  // Sets the grad_fn and output_nr of an output Variable.
  auto set_history = [&amp;](Variable&amp; var, uint32_t output_nr, bool is_input, bool is_modified,
                         bool is_differentiable) {
    // Lots of checks
    if (!is_differentiable) {
     ...
    } else if (is_input) {
      // An input has been returned, but it wasn't modified. Return it as a view
      // so that we can attach a new grad_fn to the Variable.
      // Run in no_grad mode to mimic the behavior of the forward.
      {
        AutoGradMode grad_mode(false);
        var = var.view_as(var);
      }
      impl::set_gradient_edge(var, {cdata, output_nr});
    } else if (cdata) {
      impl::set_gradient_edge(var, {cdata, output_nr});
    }
  };</code></pre>
</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">And this is where <code>set_gradient_edge</code> was called and this is how a user-written python function gets included in the computational graph with its associated backward function!</p>
	</div>
</div>

<div class="">
<h2 class="HeadingBlock HeadingBlock is-style-secondary-heading  hasTopSpacing" id="block-be21190e-2992-4452-9a7e-47db162ac256">
		
	Closing remarks</h2>
	</div>



<div class="blog-text-container  ">
	<div class="container">
				<p class="rich-text">This blog post is intended to be a code overview on how PyTorch constructs the actual computational graphs that we discussed in the previous post. The next entry will deal with how the autograd engine executes these graphs.</p>
	</div>
</div>	</main>

	<footer class="Footer">
		<div class="mainNav">
			<div class="logo">
				<a href="/" aria-label="Go to Pytorch home">
					<svg width="30" height="35" viewbox="0 0 30 35" fill="none" xmlns="http://www.w3.org/2000/svg" role="img">
<path d="M24.8384 10.3748L22.3344 12.8296C26.5077 16.9211 26.5077 23.5842 22.3344 27.6757C18.1612 31.7671 11.3647 31.7671 7.19148 27.6757C3.01823 23.5842 3.01823 16.9211 7.19148 12.8296L13.8687 6.28337L14.7033 5.34818V0.438477L4.56829 10.3748C-1.03579 15.869 -1.03579 24.6363 4.56829 30.1305C10.1724 35.6247 19.1151 35.6247 24.7191 30.1305C30.4424 24.6363 30.4424 15.7521 24.8384 10.3748Z" fill="#F05F42"></path>
<ellipse cx="19.8316" cy="7.80298" rx="1.90777" ry="1.87036" fill="#F05F42"></ellipse>
</svg>
				</a>
			</div>

			<ul class="footerNav">
													<li class="mainItem">
						<a href="#" target="" class="footer-item  ">
							PyTorch						</a>
													<ul>
																	<li class="subItem">
										<a href="/install/" target="" class=" ">
											Install										</a>
																			</li>
																	<li class="subItem">
										<a href="/features/" target="" class=" ">
											Features										</a>
																			</li>
																	<li class="subItem">
										<a href="/resources/" target="" class=" ">
											Resources										</a>
																			</li>
																	<li class="subItem">
										<a href="https://pytorch.org/docs/stable/index.html" target="" class="docs ">
											Docs										</a>
																			</li>
																	<li class="subItem">
										<a href="https://pytorch.org/tutorials/" target="" class="tutorials ">
											Tutorials										</a>
																			</li>
																	<li class="subItem">
										<a href="/community/" target="" class=" ">
											Community										</a>
																			</li>
																	<li class="subItem">
										<a href="https://github.com/pytorch/pytorch" target="" class=" ">
											Github										</a>
																			</li>
															</ul>
											</li>
									<li class="mainItem">
						<a href="#" target="" class="footer-item  ">
							Support						</a>
													<ul>
																	<li class="subItem">
										<a href="https://github.com/pytorch/pytorch/issues" target="_blank" class=" icon-github">
											Github Issues										</a>
																			</li>
																	<li class="subItem">
										<a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank" class=" ">
											Brand Guidelines										</a>
																			</li>
																	<li class="subItem">
										<a href="https://discuss.pytorch.org/" target="_blank" class=" ">
											Discuss										</a>
																			</li>
															</ul>
											</li>
								<li class="mainItem">
					
<div class="navItems-followContainer followMenu ">
			<div class="mainItem">Follow Us</div>
		<ul class="follow-list">
					<li class="followItem">
				<a aria-label="follow Menu  icon-twitter" href="https://twitter.com/pytorch" target="_blank" class=" icon-twitter">
					Twitter				</a>
			</li>
					<li class="followItem">
				<a aria-label="follow Menu  icon-facebook" href="https://www.facebook.com/pytorch" target="_blank" class=" icon-facebook">
					Facebook				</a>
			</li>
					<li class="followItem">
				<a aria-label="follow Menu  icon-youtube" href="https://www.youtube.com/pytorch" target="_blank" class=" icon-youtube">
					YouTube				</a>
			</li>
					<li class="followItem">
				<a aria-label="follow Menu  icon-linkedin" href="https://www.linkedin.com/company/pytorch" target="_blank" class=" icon-linkedin">
					Linkedin				</a>
			</li>
					<li class="followItem">
				<a aria-label="follow Menu  icon-medium" href="https://medium.com/pytorch" target="_blank" class=" icon-medium">
					Medium				</a>
			</li>
					<li class="followItem">
				<a aria-label="follow Menu  icon-github" href="https://github.com/pytorch/pytorch" target="_blank" class=" icon-github">
					GitHub				</a>
			</li>
			</ul>
</div>
				</li>
			</ul>
		</div>
		<div class="legalNav">
			<ul class="legalNavList">
													<li>
						<a href="/wp-content/uploads/2021/11/fb-tos-privacy-policy.pdf" target="" class=" ">
							Terms						</a>
					</li>
									<li>
						<a href="/wp-content/uploads/2021/11/fb-oss-privacy-policy.pdf" target="" class=" ">
							Privacy						</a>
					</li>
							</ul>
		</div>
	</footer>
</div>

<script id="pytorch-classic-js-js-extra">
var gridData = {"build":{"stable":"Stable (1.9.0)","nightly":"Preview (Nightly)","lts":"LTS (1.8.1)"},"os":{"mac":"MacOS","linux":"Linux","windows":"Windows"},"package":{"conda":"Conda","pip":"Pip","libtorch":"LibTorch","source":"Source"},"language":{"python":"Python","cplusplus":"C++\/Java"},"platform":{"cuda10.2":"CUDA 10.2","cuda11.1":"CUDA 11.1","rocm":"ROCm 4.2(beta)","cpu":"CPU"}};
var platformOSSupport = {"linux":["cuda10.2","rocm","cpu"],"mac":["cpu"],"windows":["cuda10.2","rocm","cpu"]};
var packageLanguageSupport = {"python":["pip","conda","source"],"cplusplus":["libtorch"]};
var commands = {"stable,conda,mac,cpu,python":"conda install pytorch torchvision torchaudio -c pytorch","nightly,conda,linux,cpu,python":"conda install pytorch torchvision torchaudio cpuonly -c pytorch-nightly","stable,libtorch,windows,rocm,cplusplus":"NOTE: ROCm is not available on Windows","stable,conda,windows,cpu,python":"conda install pytorch torchvision torchaudio cpuonly -c pytorch-nightly","stable,conda,windows,rocm,python":"NOTE: ROCm is not available on Windows","stable,pip,windows,rocm,python":"NOTE: ROCm is not available on Windows","stable,pip,windows,cpu,python":"pip3 install --pre torch torchvision torchaudio -f https:\/\/download.pytorch.org\/whl\/nightly\/cpu\/torch_nightly.html","stable,conda,windows,cuda10.2,python":"conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch-nightly","stable,conda,windows,cuda11.1,python":"NOTE: \\'conda-forge\\' channel is required for cudatoolkit 11.1\r\nconda install pytorch torchvision torchaudio cudatoolkit=11.1 -c pytorch-nightly -c conda-forge","stable,libtorch,mac,rocm,cplusplus":"NOTE: ROCm is not available on MacOS","stable,conda,mac,rocm,python":"NOTE: ROCm is not available on MacOS","stable,conda,linux,cpu,python":"conda install pytorch torchvision torchaudio cpuonly -c pytorch","stable,conda,linux,rocm,python":"NOTE: Conda packages are not currently available for ROCm, please use pip instead","stable,conda,linux,cuda10.2,python":"conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch","stable,conda,linux,cuda11.1,python":"NOTE: \\'nvidia\\' channel is required for cudatoolkit 11.1\r\nconda install pytorch torchvision torchaudio cudatoolkit=11.1 -c pytorch -c nvidia","lts,libtorch,windows,rocm,cplusplus":"NOTE: ROCm is not supported in LTS","lts,pip,mac,cpu,python":"# macOS is not currently supported for lts","lts,conda,mac,cuda10.2,python":"# macOS is not currently supported for lts","lts,conda,mac,cuda11.1,python":"# macOS is not currently supported for lts","lts,conda,mac,rocm,python":"# macOS is not currently supported for lts","lts,conda,mac,cpu,python":"# macOS is not currently supported for lts","stable,conda,mac,cuda10.2,python":"# MacOS Binaries dont support CUDA, install from source if CUDA is needed\r\nconda install pytorch torchvision torchaudio -c pytorch","lts,libtorch,mac,cpu,cplusplus":"# macOS is not currently supported for lts","lts,libtorch,mac,cuda10.2,cplusplus":"# macOS is not currently supported for lts","lts,libtorch,mac,cuda11.1,cplusplus":"# macOS is not currently supported for lts","lts,libtorch,mac,rocm,cplusplus":"# macOS is not currently supported for lts","lts,pip,windows,rocm,python":"NOTE: ROCm is not supported in LTS","stable,libtorch,linux,cpu,cplusplus":"Download here (Pre-cxx11 ABI):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/cpu\/libtorch-shared-with-deps-1.9.1%2Bcpu.zip\">https:\/\/download.pytorch.org\/libtorch\/cpu\/libtorch-shared-with-deps-1.9.1%2Bcpu.zip<\/a>\r\nDownload here (cxx11 ABI):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/cpu\/libtorch-cxx11-abi-shared-with-deps-1.9.1%2Bcpu.zip\">https:\/\/download.pytorch.org\/libtorch\/cpu\/libtorch-cxx11-abi-shared-with-deps-1.9.1%2Bcpu.zip<\/a>","stable,pip,linux,cpu,python":"pip3 install --pre torch torchvision torchaudio -f https:\/\/download.pytorch.org\/whl\/nightly\/cpu\/torch_nightly.html","stable,pip,linux,cuda11.1,python":"pip3 install torch==1.9.1+cu111 torchvision==0.10.1+cu111 torchaudio==0.9.1 -f https:\/\/download.pytorch.org\/whl\/torch_stable.html","stable,pip,linux,cuda10.2,python":"pip3 install torch torchvision torchaudio","stable,pip,linux,rocm,python":"pip3 install torch torchvision==0.10.1 -f https:\/\/download.pytorch.org\/whl\/rocm4.2\/torch_stable.html","stable,libtorch,linux,cuda10.2,cplusplus":"Download here (Pre-cxx11 ABI):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/cu102\/libtorch-shared-with-deps-1.9.1%2Bcu102.zip\">https:\/\/download.pytorch.org\/libtorch\/cu102\/libtorch-shared-with-deps-1.9.1%2Bcu102.zip<\/a>\r\nDownload here (cxx11 ABI):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/cu102\/libtorch-cxx11-abi-shared-with-deps-1.9.1%2Bcu102.zip\">https:\/\/download.pytorch.org\/libtorch\/cu102\/libtorch-cxx11-abi-shared-with-deps-1.9.1%2Bcu102.zip<\/a>","stable,libtorch,linux,cuda11.1,cplusplus":"Download here (Pre-cxx11 ABI):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/cu111\/libtorch-shared-with-deps-1.9.1%2Bcu111.zip\">https:\/\/download.pytorch.org\/libtorch\/cu111\/libtorch-shared-with-deps-1.9.1%2Bcu111.zip<\/a>\r\nDownload here (cxx11 ABI):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/cu111\/libtorch-cxx11-abi-shared-with-deps-1.9.1%2Bcu111.zip\">https:\/\/download.pytorch.org\/libtorch\/cu111\/libtorch-cxx11-abi-shared-with-deps-1.9.1%2Bcu111.zip<\/a>","stable,libtorch,linux,rocm,cplusplus":"LibTorch binaries are not available for ROCm, please build it from source","stable,pip,mac,cuda10.2,python":"# MacOS Binaries dont support CUDA, install from source if CUDA is needed\r\npip3 install torch torchvision torchaudio","stable,pip,mac,cuda11.1,python":"# MacOS Binaries dont support CUDA, install from source if CUDA is needed\r\npip3 install torch torchvision torchaudio","stable,pip,mac,rocm,python":"NOTE: ROCm is not available on MacOS","stable,pip,mac,cpu,python":"pip3 install torch torchvision torchaudio","stable,conda,mac,cuda11.1,python":"# MacOS Binaries dont support CUDA, install from source if CUDA is needed\r\nconda install pytorch torchvision torchaudio -c pytorch","stable,libtorch,mac,cpu,cplusplus":"Download here:\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/cpu\/libtorch-macos-1.9.1.zip\">https:\/\/download.pytorch.org\/libtorch\/cpu\/libtorch-macos-1.9.1.zip<\/a>","stable,libtorch,mac,cuda10.2,cplusplus":"MacOS binaries do not support CUDA. Download CPU libtorch here:\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/cpu\/libtorch-macos-1.9.1.zip\">https:\/\/download.pytorch.org\/libtorch\/cpu\/libtorch-macos-1.9.1.zip<\/a>","stable,libtorch,mac,cuda11.1,cplusplus":"MacOS binaries do not support CUDA. Download CPU libtorch here:\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/cpu\/libtorch-macos-1.9.1.zip\">https:\/\/download.pytorch.org\/libtorch\/cpu\/libtorch-macos-1.9.1.zip<\/a>","stable,libtorch,windows,cuda11.1,python":"Download here (Release version):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/cu111\/libtorch-win-shared-with-deps-1.9.1%2Bcu111.zip\">https:\/\/download.pytorch.org\/libtorch\/cu111\/libtorch-win-shared-with-deps-1.9.1%2Bcu111.zip<\/a>\r\nDownload here (Debug version):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/cu111\/libtorch-win-shared-with-deps-debug-1.9.1%2Bcu111.zip\">https:\/\/download.pytorch.org\/libtorch\/cu111\/libtorch-win-shared-with-deps-debug-1.9.1%2Bcu111.zip<\/a>","stable,libtorch,windows,cuda10.2,cplusplus":"Download here (Release version):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/nightly\/cu102\/libtorch-win-shared-with-deps-latest.zip\">https:\/\/download.pytorch.org\/libtorch\/nightly\/cu102\/libtorch-win-shared-with-deps-latest.zip<\/a>\r\nDownload here (Debug version):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/nightly\/cu102\/libtorch-win-shared-with-deps-debug-latest.zip\">https:\/\/download.pytorch.org\/libtorch\/nightly\/cu102\/libtorch-win-shared-with-deps-debug-latest.zip<\/a>","stable,libtorch,windows,cpu,cplusplus":"Download here (Release version):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/nightly\/cpu\/libtorch-win-shared-with-deps-latest.zip\">https:\/\/download.pytorch.org\/libtorch\/nightly\/cpu\/libtorch-win-shared-with-deps-latest.zip<\/a>\r\nDownload here (Debug version):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/nightly\/cpu\/libtorch-win-shared-with-deps-debug-latest.zip\">https:\/\/download.pytorch.org\/libtorch\/nightly\/cpu\/libtorch-win-shared-with-deps-debug-latest.zip<\/a>","stable,pip,windows,cuda11.1,python":"pip3 install --pre torch torchvision torchaudio -f https:\/\/download.pytorch.org\/whl\/nightly\/cu111\/torch_nightly.html","stable,pip,windows,cuda10.2,python":"pip3 install --pre torch torchvision torchaudio -f https:\/\/download.pytorch.org\/whl\/nightly\/cu102\/torch_nightly.html","stable,libtorch,windows,cuda11.1,cplusplus":"Download here (Release version):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/nightly\/cu111\/libtorch-win-shared-with-deps-latest.zip\">https:\/\/download.pytorch.org\/libtorch\/nightly\/cu111\/libtorch-win-shared-with-deps-latest.zip<\/a>\r\nDownload here (Debug version):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/nightly\/cu111\/libtorch-win-shared-with-deps-debug-latest.zip\">https:\/\/download.pytorch.org\/libtorch\/nightly\/cu111\/libtorch-win-shared-with-deps-debug-latest.zip<\/a>","lts,pip,linux,cpu,python":"pip3 install torch==1.8.2+cpu torchvision==0.9.2+cpu torchaudio==0.8.2 -f https:\/\/download.pytorch.org\/whl\/lts\/1.8\/torch_lts.html","lts,pip,linux,cuda10.2,python":"pip3 install torch==1.8.2+cu102 torchvision==0.9.2+cu102 torchaudio==0.8.2 -f https:\/\/download.pytorch.org\/whl\/lts\/1.8\/torch_lts.html","lts,pip,linux,cuda11.1,python":"pip3 install torch==1.8.2+cu111 torchvision==0.9.2+cu111 torchaudio==0.8.2 -f https:\/\/download.pytorch.org\/whl\/lts\/1.8\/torch_lts.html","lts,pip,linux,rocm,python":"NOTE: ROCm is not supported in LTS","lts,conda,linux,cuda10.2,python":"conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch-lts","lts,conda,linux,cuda11.1,python":"NOTE: \\'nvidia\\' channel is required for cudatoolkit 11.1\r\nconda install pytorch torchvision torchaudio cudatoolkit=11.1 -c pytorch-lts -c nvidia","lts,conda,linux,rocm,python":"NOTE: ROCm is not supported in LTS","lts,conda,linux,cpu,python":"conda install pytorch torchvision torchaudio cpuonly -c pytorch-lts","lts,libtorch,linux,cpu,cplusplus":"Download here (Pre-cxx11 ABI):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cpu\/libtorch-shared-with-deps-1.8.2%2Bcpu.zip\">https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cpu\/libtorch-shared-with-deps-1.8.2%2Bcpu.zip<\/a>\r\nDownload here (cxx11 ABI):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cpu\/libtorch-cxx11-abi-shared-with-deps-1.8.2%2Bcpu.zip\">https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cpu\/libtorch-cxx11-abi-shared-with-deps-1.8.2%2Bcpu.zip<\/a>","lts,libtorch,linux,cuda10.2,cplusplus":"Download here (Pre-cxx11 ABI):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu102\/libtorch-shared-with-deps-1.8.2%2Bcu102.zip\">https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu102\/libtorch-shared-with-deps-1.8.2%2Bcu102.zip<\/a>\r\nDownload here (cxx11 ABI):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu102\/libtorch-cxx11-abi-shared-with-deps-1.8.2%2Bcu102.zip\">https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu102\/libtorch-cxx11-abi-shared-with-deps-1.8.2%2Bcu102.zip<\/a>","lts,libtorch,linux,cuda11.1,cplusplus":"Download here (Pre-cxx11 ABI):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu111\/libtorch-shared-with-deps-1.8.2%2Bcu111.zip\">https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu111\/libtorch-shared-with-deps-1.8.2%2Bcu111.zip<\/a>\r\nDownload here (cxx11 ABI):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu111\/libtorch-cxx11-abi-shared-with-deps-1.8.2%2Bcu111.zip\">https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu111\/libtorch-cxx11-abi-shared-with-deps-1.8.2%2Bcu111.zip<\/a>","lts,libtorch,linux,rocm,python":"NOTE: ROCm is not supported in LTS","lts,pip,mac,cuda10.2,python":"# macOS is not currently supported for lts","lts,pip,mac,cuda11.1,python":"# macOS is not currently supported for lts","lts,pip,mac,rocm,python":"# macOS is not currently supported for lts","lts,pip,windows,cpu,python":"pip3 install torch==1.8.2+cpu torchvision==0.9.2+cpu torchaudio===0.8.2 -f https:\/\/download.pytorch.org\/whl\/lts\/1.8\/torch_lts.html","lts,pip,windows,cuda10.2,python":"pip3 install torch==1.8.2+cu102 torchvision==0.9.2+cu102 torchaudio===0.8.2 -f https:\/\/download.pytorch.org\/whl\/lts\/1.8\/torch_lts.html","lts,pip,windows,cuda11.1,python":"pip3 install torch==1.8.2+cu111 torchvision==0.9.2+cu111 torchaudio===0.8.2 -f https:\/\/download.pytorch.org\/whl\/lts\/1.8\/torch_lts.html","lts,conda,windows,cuda10.2,python":"conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch-lts","lts,conda,windows,cuda11.1,python":"NOTE: \\'conda-forge\\' channel is required for cudatoolkit 11.1\r\nconda install pytorch torchvision torchaudio cudatoolkit=11.1 -c pytorch-lts -c conda-forge","lts,conda,windows,cpu,python":"conda install pytorch torchvision torchaudio cpuonly -c pytorch-lts","lts,conda,windows,rocm,python":"NOTE: ROCm is not supported in LTS","lts,libtorch,windows,cpu,cplusplus":"Download here (Release version):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cpu\/libtorch-win-shared-with-deps-1.8.2%2Bcpu.zip\">https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cpu\/libtorch-win-shared-with-deps-1.8.2%2Bcpu.zip<\/a>\r\nDownload here (Debug version):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cpu\/libtorch-win-shared-with-deps-debug-1.8.2%2Bcpu.zip\">https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cpu\/libtorch-win-shared-with-deps-debug-1.8.2%2Bcpu.zip<\/a>","lts,libtorch,windows,cuda10.2,cplusplus":"Download here (Release version):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu102\/libtorch-win-shared-with-deps-1.8.2%2Bcu102.zip\">https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu102\/libtorch-win-shared-with-deps-1.8.2%2Bcu102.zip<\/a>\r\nDownload here (Debug version):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu102\/libtorch-win-shared-with-deps-debug-1.8.2%2Bcu102.zip\">https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu102\/libtorch-win-shared-with-deps-debug-1.8.2%2Bcu102.zip<\/a>","lts,libtorch,windows,cuda11.1,cplusplus":"Download here (Release version):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu111\/libtorch-win-shared-with-deps-1.8.2%2Bcu111.zip\">https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu111\/libtorch-win-shared-with-deps-1.8.2%2Bcu111.zip<\/a>\r\nDownload here (Debug version):\r\n<a href=\"https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu111\/libtorch-win-shared-with-deps-debug-1.8.2%2Bcu111.zip\">https:\/\/download.pytorch.org\/libtorch\/lts\/1.8\/cu111\/libtorch-win-shared-with-deps-debug-1.8.2%2Bcu111.zip<\/a>"};
</script>
<script src="/wp-content/themes/pytorch/assets/js/index.bundle.js?ver=1" id="pytorch-classic-js-js"></script>
<script src="/wp-content/themes/pytorch/assets/js/blog-header.bundle.js?ver=1" id="pytorch-blog-header-js"></script>
<script src="/wp-content/themes/pytorch/assets/js/blog-text.bundle.js?ver=1" id="pytorch-blog-text-js"></script>
<script src="/wp-content/themes/pytorch/assets/js/heading.bundle.js?ver=1" id="pytorch-heading-js"></script>
<script src="/wp-content/themes/pytorch/assets/js/blog-image.bundle.js?ver=1" id="pytorch-blog-image-js"></script>
<script id="mkaz-code-syntax-prism-js-js-extra">
var prism_settings = {"pluginUrl":"\/wp-content\/plugins\/code-syntax-block\/"};
</script>
<script src="/wp-content/plugins/code-syntax-block/assets/prism/prism.js?ver=1641826791" id="mkaz-code-syntax-prism-js-js"></script>
<script src="/wp-content/plugins/simply-static-pro/assets/fuse.js?ver=1.1" id="ssp-fuse-js"></script>
<script src="/wp-content/plugins/simply-static-pro/assets/ssp-search.js?ver=1.1" id="ssp-search-js"></script>
<script src="https://stats.wp.com/e-202203.js" defer></script>
<script>
	_stq = window._stq || [];
	_stq.push([ 'view', {v:'ext',j:'1:10.4',blog:'195752808',post:'3154',tz:'0',srv:'pytorch-org-preprod.go-vip.net'} ]);
	_stq.push([ 'clickTrackerInit', '195752808', '3154' ]);
</script>

</body>
</html>